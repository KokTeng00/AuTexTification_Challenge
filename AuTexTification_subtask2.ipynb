{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2047044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962c0f2f",
   "metadata": {
    "id": "962c0f2f"
   },
   "outputs": [],
   "source": [
    "#To set the seed for ensuring the generated result will be exactly same in every execution\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a772b875",
   "metadata": {
    "id": "a772b875"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#For reading the training dataset\n",
    "sub_2 = pd.read_csv('train_sub_2.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36343124",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1682279832713,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "06944301600455144405"
     },
     "user_tz": -120
    },
    "id": "36343124",
    "outputId": "a46fa279-8e71-480b-f02d-72a405f319bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6239</td>\n",
       "      <td>It was not until many years later that it coul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9255</td>\n",
       "      <td>Users can then pin these images to their profi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1674</td>\n",
       "      <td>The best songs are those that I can sing along...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5001</td>\n",
       "      <td>I found this book to be poorly written. It was...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20779</td>\n",
       "      <td>Regulates the application of the EU tariff quo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                               text  label\n",
       "0           0   6239  It was not until many years later that it coul...      0\n",
       "1           1   9255  Users can then pin these images to their profi...      5\n",
       "2           2   1674  The best songs are those that I can sing along...      1\n",
       "3           3   5001  I found this book to be poorly written. It was...      3\n",
       "4           4  20779  Regulates the application of the EU tariff quo...      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the dataset for the first five rows\n",
    "sub_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3aca86",
   "metadata": {
    "id": "4a3aca86"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#Transforming the 'label' variable, could easily process by machine\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "sub_2['label'] = label_encoder.fit_transform(sub_2['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "K3Z7eE13Sy1U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1682455027202,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "06944301600455144405"
     },
     "user_tz": -120
    },
    "id": "K3Z7eE13Sy1U",
    "outputId": "3c1ea2dd-795f-411a-c660-85a9e7f4f4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18156 2018 2242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#Splitting the data into train and test, and using the stratified methods to ensure the data is splitted distributed equally based on the dependent variable\n",
    "train, test = train_test_split(sub_2, test_size=0.10, stratify=sub_2['label']) \n",
    "train, validation = train_test_split(train, test_size=0.10, stratify=train['label']) \n",
    "\n",
    "print(len(train), len(validation), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d_VMGa0CavuH",
   "metadata": {
    "id": "d_VMGa0CavuH"
   },
   "outputs": [],
   "source": [
    "train_text = list(train['text'])\n",
    "train_label = list(train['label'])\n",
    "\n",
    "val_text = list(validation['text'])\n",
    "val_label = list(validation['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d17993",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "049cf58ced7d4de3b91fb560068484e7",
      "3e3af727ce5c4ba9bf6eee2eb15b4554",
      "e515a63d375f43c7bad13cf895c852ea",
      "551145663e114a568b52a6f8f3570f5a",
      "c716528474d447f9922325bcff07cd76",
      "52a5f0a6af714eeb8a03a1660343b4ba",
      "f877df11d8cd487c9749bed49d610be6",
      "87f0f368fc5847c6b2ef716e95e2c2ec",
      "3b7ef163b0454bec862383beaf5f934b",
      "2a4b6f41161e4b0389bba755d378a0ca",
      "e81842ec994747ae94177f7148a40bd3",
      "1513d7b20d1b422fb12d1b60e6139893",
      "2bf3aecdcdf040af9bc2d018c27afd83",
      "791b73691f4341e3b441f9eab848cbea",
      "3117a1108e114bae83974abaa5a5a4e1",
      "a7c12e557b2b462e8ae8dda33286e237",
      "7ab2c7d8e77141efb4bc2a7fca25213c",
      "68be652c886343a3b687fb46e55f0a91",
      "2d034bcd36c94d6494dfa7d2193c1fd2",
      "734924846d6b40b8b908ea4f39bcf6c5",
      "cb28334bb7c841c688b7579e197f371b",
      "03275844145244bab9918034dd18eb99",
      "24bb0a38d6bb4e83b5efdb48094b3a90",
      "2ed6b192b1b24bb99c8639ccfdbc4cbd",
      "06bbb6066cca406093bba34c46ec8579",
      "a2c8e1542a6a4eb09e21b63623acd8ce",
      "cf1a476b77bf4bedaa60612863e29fc1",
      "510115d67e6d4ea091b22349327d3fcc",
      "e6c67861c4d8459387a538684da5349c",
      "4555b7a0be314476820bdf220470aa48",
      "31b12bc7db8e4ebe8b3648416d4699e6",
      "860e3ee2ce7a46da94cb1309f284c91a",
      "45f8329a1ef947ca83225d51e6be94d4"
     ]
    },
    "executionInfo": {
     "elapsed": 2224,
     "status": "ok",
     "timestamp": 1682455043049,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "06944301600455144405"
     },
     "user_tz": -120
    },
    "id": "27d17993",
    "outputId": "b20f8f4b-9898-4a91-e1ef-e75c72552e2a"
   },
   "outputs": [],
   "source": [
    "#Set up the tokenizer from the BERT neural network\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "#bert-base-uncased means it will treat upper case and lower case same as 'english' and 'English'\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aUyfuoK_o77a",
   "metadata": {
    "id": "aUyfuoK_o77a"
   },
   "outputs": [],
   "source": [
    "token_counts = []\n",
    "\n",
    "#For finding the token length of the text after executing the process of tokenisation, then we could determine the maximum length of the tokenisation\n",
    "for text in train_text:\n",
    "  token_count = len(tokenizer.encode(text, max_length = 512, truncation = True))\n",
    "  token_counts.append(token_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8PNV6N7mlm-j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 906,
     "status": "ok",
     "timestamp": 1682079281015,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "16553334513796632904"
     },
     "user_tz": -120
    },
    "id": "8PNV6N7mlm-j",
    "outputId": "d3c7cefe-1f05-4d49-e953-c34b1f59fd6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 512.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#For plotting the histogram of the token length of the texts after executing the process of tokenisation\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.histplot(token_counts)\n",
    "plt.xlim([0, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GGGK9Md8r7-z",
   "metadata": {
    "id": "GGGK9Md8r7-z"
   },
   "source": [
    "Based on the result shown above, we could view the tokens' input_ids lengths are fallen within the range of (0, 128), which mean the input sentences's length are falling within these range. Therefore, we could set the maximum length for the tokenisation be 128, which could save more computation time and space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c21af9",
   "metadata": {},
   "source": [
    "# Translating Foreign Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a8a9f",
   "metadata": {},
   "source": [
    "###### Could uncomment it to run it (Due to it got poor performance compare to non-translating situation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ada9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!pip install pyicu\n",
    "!pip install pycld2\n",
    "!pip install polyglot\n",
    "!pip install morfessor\n",
    "!pip install googletrans==4.0.0rc1\n",
    "\n",
    "import chardet\n",
    "from polyglot.detect import Detector\n",
    "\n",
    "foreign_language = []\n",
    "\n",
    "for length_of_sub_2 in range(len(sub_2)):\n",
    "  text = sub_2['text'][length_of_sub_2]\n",
    "  try:\n",
    "    detector = Detector(text)\n",
    "    if (detector.language.confidence < 98.0):\n",
    "      foreign_language.append(length_of_sub_2)\n",
    "  except:\n",
    "    detect = chardet.detect(text.encode())\n",
    "    if (detect['confidence'] < 0.90):\n",
    "      foreign_language.append(length_of_sub_2)\n",
    "    else:\n",
    "      pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import nltk\n",
    "import time\n",
    "nltk.download(\"punkt\")\n",
    "from googletrans import Translator\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tk = WordPunctTokenizer()\n",
    "translator = Translator()\n",
    "\n",
    "for i in range (len(foreign_language) // 2):\n",
    "  text = sub_2['text'][foreign_language[i]]\n",
    "  translation = translator.translate(text, dest = 'en')\n",
    "  text = translation.text\n",
    "  time.sleep(0.5)\n",
    "  sub_2['text'][foreign_language[i]] = text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range (len(foreign_language) // 2, len(foreign_language)):\n",
    "  text = sub_2['text'][foreign_language[i]]\n",
    "  translation = translator.translate(text, dest = 'en')\n",
    "  text = translation.text\n",
    "  time.sleep(0.5)\n",
    "  sub_2['text'][foreign_language[i]] = text\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "foreign_language = []\n",
    "\n",
    "for length_of_sub_2 in range(len(sub_2)):\n",
    "  text = sub_2['text'][length_of_sub_2]\n",
    "  try:\n",
    "    detector = Detector(text)\n",
    "    if (detector.language.confidence < 98.0):\n",
    "      foreign_language.append(length_of_sub_2)\n",
    "  except:\n",
    "    detect = chardet.detect(text.encode())\n",
    "    if (detect['confidence'] < 0.90):\n",
    "      foreign_language.append(length_of_sub_2)\n",
    "    else:\n",
    "      pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range (len(foreign_language)//2):\n",
    "  text = sub_2['text'][foreign_language[i]]\n",
    "  tokens = tk.tokenize(text)\n",
    "  for length_of_token in range (len(tokens)):\n",
    "    translation = translator.translate(tokens[length_of_token], dest = 'en')\n",
    "    tokens[length_of_token] = translation.text\n",
    "    time.sleep(0.5)\n",
    "  text = ' '.join(tokens)\n",
    "  sub_2['text'][foreign_language[i]] = text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range (len(foreign_language)//2, len(foreign_language)):\n",
    "  text = sub_2['text'][foreign_language[i]]\n",
    "  tokens = tk.tokenize(text)\n",
    "  for length_of_token in range (len(tokens)):\n",
    "    translation = translator.translate(tokens[length_of_token], dest = 'en')\n",
    "    tokens[length_of_token] = translation.text\n",
    "    time.sleep(0.5)\n",
    "  text = ' '.join(tokens)\n",
    "  sub_2['text'][foreign_language[i]] = text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QKBBqGa4l9bm",
   "metadata": {
    "id": "QKBBqGa4l9bm"
   },
   "source": [
    "# Searching Hyperparameter for BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "W-Sh_K9iWVKJ",
   "metadata": {
    "id": "W-Sh_K9iWVKJ"
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "from emot.emo_unicode import EMOTICONS_EMO\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "class TextPreprocessor:\n",
    "    \n",
    "    @classmethod\n",
    "    def convert_emoticons(cls, text):\n",
    "        for emot in EMOTICONS_EMO:\n",
    "            text = text.replace(emot, EMOTICONS_EMO[emot].replace(\" \",\"_\"))\n",
    "        return text\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_text(cls, texts):\n",
    "        preprocessed_texts = []\n",
    "        for text in texts:\n",
    "            text = emoji.demojize(text)\n",
    "            text = cls.convert_emoticons(text)\n",
    "            preprocessed_texts.append(text)\n",
    "\n",
    "        return preprocessed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing on those sentence (Could uncomment it for running it)\n",
    "\"\"\"\n",
    "import emoji\n",
    "from nltk import pos_tag\n",
    "from torch import nn, optim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from emot.emo_unicode import EMOTICONS_EMO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "class TextPreprocessor:\n",
    "    tk = WordPunctTokenizer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    @classmethod\n",
    "    def convert_emoticons(cls, text):\n",
    "        for emot in EMOTICONS_EMO:\n",
    "            text = text.replace(emot, EMOTICONS_EMO[emot].replace(\" \",\"_\"))\n",
    "        return text\n",
    "\n",
    "    @classmethod\n",
    "    def get_wordnet_pos(cls, treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        elif treebank_tag.startswith('C'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('M'):\n",
    "            return 'v'\n",
    "        elif treebank_tag.startswith('I'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_text(cls, texts):\n",
    "        preprocessed_texts = []\n",
    "        for text in texts:\n",
    "            text = emoji.demojize(text)\n",
    "            text = cls.convert_emoticons(text)\n",
    "            tokens = cls.tk.tokenize(text)\n",
    "            tokens = [token for token in tokens if token not in cls.stop_words]\n",
    "            tokens = [token for token in tokens if token.isalnum()]\n",
    "            tokens = [token for token in tokens if not isinstance(token, str) or not token.isnumeric()]\n",
    "            pos_tags = pos_tag(tokens)\n",
    "            lemmatized_tokens = [cls.lemmatizer.lemmatize(token, pos = cls.get_wordnet_pos(tag)) if cls.get_wordnet_pos(tag) is not None else token for token, tag in pos_tags]\n",
    "            preprocessed_texts.append(lemmatized_tokens)\n",
    "\n",
    "        return preprocessed_texts\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Oy-kDzrx83d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "3b5831c1b5f84831929efe84bc552a1b",
      "39a09b66d84043de9b534a86f384888b",
      "37010ac369264c569a980d17ee8b3abc",
      "5753178222f247adb47282d02036220f",
      "046aed4bce304c208d5453d85fd490a1",
      "13d46ce151bf4c3aa8c163e30e7c8e90",
      "9297a4d93689473bb67fe0aa40a4f9b9",
      "65f72a9418404351a2fc648ac34a1362",
      "26d2a2a7b0f142bbb26da7d93a229f75",
      "ccd4d4a8e9654d35a5a9860fc342b023",
      "2cb25f576a35480ea6e8bc44b7ddf2a3",
      "9111adee7545499e86abed22cf5bf2a1",
      "0ba831affe7848c790320e49a4dfc62d",
      "1b5ee47ae268452baa976457bf0f2a10",
      "3db92071880f4138a273f0af3624e96c",
      "2f9cda80f9904af1b31a738c68c51b35",
      "53733cb797f3462bac57fae1d04d6d9b",
      "8875fba0741f48a5a6b5b10f20db4948",
      "4a1bd77f96e14c33954f5f161d073d2a",
      "db770085c2b84369a8e03b181e1ec8eb",
      "168a127492554c538c728f509377c3b7",
      "a91db20dca334177b3757ceb7bdb3ed7"
     ]
    },
    "executionInfo": {
     "elapsed": 82014,
     "status": "ok",
     "timestamp": 1682455191224,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "06944301600455144405"
     },
     "user_tz": -120
    },
    "id": "Oy-kDzrx83d2",
    "outputId": "4eeed5d8-8cc0-4fc2-c05e-138b57d014b7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2018 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "#train_text = TextPreprocessor.preprocess_text(train_text)\n",
    "#val_text = TextPreprocessor.preprocess_text(val_text)\n",
    "\n",
    "train = pd.DataFrame({'text': train_text, 'label': train_label})\n",
    "val = pd.DataFrame({'text': val_text, 'label': val_label})\n",
    "\n",
    "train = datasets.Dataset.from_pandas(train)\n",
    "val = datasets.Dataset.from_pandas(val)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME) \n",
    "\n",
    "def preprocess(examples):   \n",
    "# This will tokenize the text, add padding or truncate the text to the max length of 128     \n",
    "    return tokenizer(examples['text'],truncation=True, padding='max_length',max_length=128)   \n",
    "\n",
    "train = train.map(preprocess, batched=True)\n",
    "val = val.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lCOeD6IHYK-n",
   "metadata": {
    "id": "lCOeD6IHYK-n",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-06 11:13:47,286]\u001b[0m A new study created in memory with name: no-name-92cc2196-127c-4531-a46e-7a29e9daf40a\u001b[0m\n",
      "/tmp/ipykernel_103616/2041105136.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", low=1e-6, high=1e-4)\n",
      "/tmp/ipykernel_103616/2041105136.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", low=1e-6, high=1e-4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/wifo3tp01/miniconda3/envs/authentication/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8656, 'learning_rate': 1.654030791850368e-08, 'epoch': 0.06}\n",
      "{'loss': 1.8445, 'learning_rate': 3.308061583700736e-08, 'epoch': 0.13}\n",
      "{'loss': 1.8728, 'learning_rate': 4.962092375551104e-08, 'epoch': 0.19}\n",
      "{'loss': 1.8582, 'learning_rate': 6.616123167401473e-08, 'epoch': 0.25}\n",
      "{'loss': 1.8598, 'learning_rate': 8.27015395925184e-08, 'epoch': 0.32}\n",
      "{'loss': 1.8511, 'learning_rate': 9.924184751102208e-08, 'epoch': 0.38}\n",
      "{'loss': 1.8473, 'learning_rate': 1.1578215542952577e-07, 'epoch': 0.44}\n",
      "{'loss': 1.8214, 'learning_rate': 1.3232246334802945e-07, 'epoch': 0.51}\n",
      "{'loss': 1.8435, 'learning_rate': 1.4886277126653312e-07, 'epoch': 0.57}\n",
      "{'loss': 1.8535, 'learning_rate': 1.654030791850368e-07, 'epoch': 0.63}\n",
      "{'loss': 1.8575, 'learning_rate': 1.8194338710354046e-07, 'epoch': 0.7}\n",
      "{'loss': 1.8505, 'learning_rate': 1.9848369502204416e-07, 'epoch': 0.76}\n",
      "{'loss': 1.8484, 'learning_rate': 2.1502400294054783e-07, 'epoch': 0.82}\n",
      "{'loss': 1.8262, 'learning_rate': 2.3156431085905153e-07, 'epoch': 0.89}\n",
      "{'loss': 1.8451, 'learning_rate': 2.481046187775552e-07, 'epoch': 0.95}\n",
      "{'eval_loss': 1.8351160287857056, 'eval_runtime': 3.4434, 'eval_samples_per_second': 651.106, 'eval_steps_per_second': 2.614, 'epoch': 1.0}\n",
      "{'loss': 1.846, 'learning_rate': 2.646449266960589e-07, 'epoch': 1.01}\n",
      "{'loss': 1.8241, 'learning_rate': 2.8118523461456255e-07, 'epoch': 1.08}\n",
      "{'loss': 1.8361, 'learning_rate': 2.9772554253306624e-07, 'epoch': 1.14}\n",
      "{'loss': 1.8328, 'learning_rate': 3.1426585045156994e-07, 'epoch': 1.2}\n",
      "{'loss': 1.83, 'learning_rate': 3.308061583700736e-07, 'epoch': 1.27}\n",
      "{'loss': 1.8301, 'learning_rate': 3.473464662885773e-07, 'epoch': 1.33}\n",
      "{'loss': 1.8216, 'learning_rate': 3.6388677420708093e-07, 'epoch': 1.39}\n",
      "{'loss': 1.8266, 'learning_rate': 3.8042708212558463e-07, 'epoch': 1.46}\n",
      "{'loss': 1.8044, 'learning_rate': 3.969673900440883e-07, 'epoch': 1.52}\n",
      "{'loss': 1.8145, 'learning_rate': 4.13507697962592e-07, 'epoch': 1.58}\n",
      "{'loss': 1.8073, 'learning_rate': 4.3004800588109567e-07, 'epoch': 1.65}\n",
      "{'loss': 1.8136, 'learning_rate': 4.4658831379959937e-07, 'epoch': 1.71}\n",
      "{'loss': 1.7926, 'learning_rate': 4.6312862171810306e-07, 'epoch': 1.77}\n",
      "{'loss': 1.7969, 'learning_rate': 4.796689296366068e-07, 'epoch': 1.84}\n",
      "{'loss': 1.7914, 'learning_rate': 4.962092375551104e-07, 'epoch': 1.9}\n",
      "{'loss': 1.8044, 'learning_rate': 5.12749545473614e-07, 'epoch': 1.96}\n",
      "{'eval_loss': 1.7851769924163818, 'eval_runtime': 3.476, 'eval_samples_per_second': 644.999, 'eval_steps_per_second': 2.589, 'epoch': 2.0}\n",
      "{'loss': 1.7884, 'learning_rate': 5.292898533921178e-07, 'epoch': 2.03}\n",
      "{'loss': 1.7837, 'learning_rate': 5.458301613106214e-07, 'epoch': 2.09}\n",
      "{'loss': 1.7829, 'learning_rate': 5.623704692291251e-07, 'epoch': 2.15}\n",
      "{'loss': 1.8029, 'learning_rate': 5.789107771476288e-07, 'epoch': 2.22}\n",
      "{'loss': 1.7738, 'learning_rate': 5.954510850661325e-07, 'epoch': 2.28}\n",
      "{'loss': 1.7805, 'learning_rate': 6.119913929846361e-07, 'epoch': 2.34}\n",
      "{'loss': 1.7734, 'learning_rate': 6.285317009031399e-07, 'epoch': 2.41}\n",
      "{'loss': 1.7658, 'learning_rate': 6.450720088216435e-07, 'epoch': 2.47}\n",
      "{'loss': 1.7694, 'learning_rate': 6.616123167401472e-07, 'epoch': 2.53}\n",
      "{'loss': 1.775, 'learning_rate': 6.781526246586509e-07, 'epoch': 2.59}\n",
      "{'loss': 1.7701, 'learning_rate': 6.946929325771546e-07, 'epoch': 2.66}\n",
      "{'loss': 1.7696, 'learning_rate': 7.112332404956583e-07, 'epoch': 2.72}\n",
      "{'loss': 1.7637, 'learning_rate': 7.277735484141619e-07, 'epoch': 2.78}\n",
      "{'loss': 1.7684, 'learning_rate': 7.443138563326656e-07, 'epoch': 2.85}\n",
      "{'loss': 1.7647, 'learning_rate': 7.608541642511693e-07, 'epoch': 2.91}\n",
      "{'loss': 1.7556, 'learning_rate': 7.77394472169673e-07, 'epoch': 2.97}\n",
      "{'eval_loss': 1.7562483549118042, 'eval_runtime': 3.475, 'eval_samples_per_second': 645.181, 'eval_steps_per_second': 2.59, 'epoch': 3.0}\n",
      "{'loss': 1.7695, 'learning_rate': 7.939347800881767e-07, 'epoch': 3.04}\n",
      "{'loss': 1.757, 'learning_rate': 8.104750880066803e-07, 'epoch': 3.1}\n",
      "{'loss': 1.7472, 'learning_rate': 8.27015395925184e-07, 'epoch': 3.16}\n",
      "{'loss': 1.7539, 'learning_rate': 8.435557038436877e-07, 'epoch': 3.23}\n",
      "{'loss': 1.7487, 'learning_rate': 8.600960117621913e-07, 'epoch': 3.29}\n",
      "{'loss': 1.7434, 'learning_rate': 8.766363196806951e-07, 'epoch': 3.35}\n",
      "{'loss': 1.7367, 'learning_rate': 8.931766275991987e-07, 'epoch': 3.42}\n",
      "{'loss': 1.7621, 'learning_rate': 9.097169355177025e-07, 'epoch': 3.48}\n",
      "{'loss': 1.7542, 'learning_rate': 9.262572434362061e-07, 'epoch': 3.54}\n",
      "{'loss': 1.7444, 'learning_rate': 9.427975513547098e-07, 'epoch': 3.61}\n",
      "{'loss': 1.7439, 'learning_rate': 9.593378592732135e-07, 'epoch': 3.67}\n",
      "{'loss': 1.7473, 'learning_rate': 9.758781671917172e-07, 'epoch': 3.73}\n",
      "{'loss': 1.733, 'learning_rate': 9.924184751102208e-07, 'epoch': 3.8}\n",
      "{'loss': 1.7287, 'learning_rate': 1.0089587830287245e-06, 'epoch': 3.86}\n",
      "{'loss': 1.7236, 'learning_rate': 1.025499090947228e-06, 'epoch': 3.92}\n",
      "{'loss': 1.737, 'learning_rate': 1.0420393988657317e-06, 'epoch': 3.99}\n",
      "{'eval_loss': 1.7271026372909546, 'eval_runtime': 3.4797, 'eval_samples_per_second': 644.312, 'eval_steps_per_second': 2.586, 'epoch': 4.0}\n",
      "{'loss': 1.7463, 'learning_rate': 1.0585797067842356e-06, 'epoch': 4.05}\n",
      "{'loss': 1.7221, 'learning_rate': 1.0751200147027392e-06, 'epoch': 4.11}\n",
      "{'loss': 1.7223, 'learning_rate': 1.091660322621243e-06, 'epoch': 4.18}\n",
      "{'loss': 1.7312, 'learning_rate': 1.1082006305397465e-06, 'epoch': 4.24}\n",
      "{'loss': 1.7146, 'learning_rate': 1.1247409384582502e-06, 'epoch': 4.3}\n",
      "{'loss': 1.7188, 'learning_rate': 1.141281246376754e-06, 'epoch': 4.37}\n",
      "{'loss': 1.7139, 'learning_rate': 1.1578215542952577e-06, 'epoch': 4.43}\n",
      "{'loss': 1.7157, 'learning_rate': 1.1743618622137613e-06, 'epoch': 4.49}\n",
      "{'loss': 1.7181, 'learning_rate': 1.190902170132265e-06, 'epoch': 4.56}\n",
      "{'loss': 1.7006, 'learning_rate': 1.2074424780507686e-06, 'epoch': 4.62}\n",
      "{'loss': 1.7082, 'learning_rate': 1.2239827859692723e-06, 'epoch': 4.68}\n",
      "{'loss': 1.7039, 'learning_rate': 1.2405230938877761e-06, 'epoch': 4.75}\n",
      "{'loss': 1.6949, 'learning_rate': 1.2570634018062798e-06, 'epoch': 4.81}\n",
      "{'loss': 1.6887, 'learning_rate': 1.2736037097247834e-06, 'epoch': 4.87}\n",
      "{'loss': 1.6914, 'learning_rate': 1.290144017643287e-06, 'epoch': 4.94}\n",
      "{'loss': 1.69, 'learning_rate': 1.3066843255617907e-06, 'epoch': 5.0}\n",
      "{'eval_loss': 1.6907604932785034, 'eval_runtime': 3.4796, 'eval_samples_per_second': 644.336, 'eval_steps_per_second': 2.587, 'epoch': 5.0}\n",
      "{'loss': 1.7052, 'learning_rate': 1.3232246334802943e-06, 'epoch': 5.06}\n",
      "{'loss': 1.6737, 'learning_rate': 1.3397649413987982e-06, 'epoch': 5.13}\n",
      "{'loss': 1.6885, 'learning_rate': 1.3563052493173018e-06, 'epoch': 5.19}\n",
      "{'loss': 1.6958, 'learning_rate': 1.3728455572358055e-06, 'epoch': 5.25}\n",
      "{'loss': 1.6648, 'learning_rate': 1.3893858651543091e-06, 'epoch': 5.32}\n",
      "{'loss': 1.675, 'learning_rate': 1.4059261730728128e-06, 'epoch': 5.38}\n",
      "{'loss': 1.654, 'learning_rate': 1.4224664809913166e-06, 'epoch': 5.44}\n",
      "{'loss': 1.668, 'learning_rate': 1.4390067889098203e-06, 'epoch': 5.51}\n",
      "{'loss': 1.6607, 'learning_rate': 1.4555470968283237e-06, 'epoch': 5.57}\n",
      "{'loss': 1.6554, 'learning_rate': 1.4720874047468276e-06, 'epoch': 5.63}\n",
      "{'loss': 1.654, 'learning_rate': 1.4886277126653312e-06, 'epoch': 5.7}\n",
      "{'loss': 1.6461, 'learning_rate': 1.5051680205838349e-06, 'epoch': 5.76}\n",
      "{'loss': 1.651, 'learning_rate': 1.5217083285023385e-06, 'epoch': 5.82}\n",
      "{'loss': 1.6407, 'learning_rate': 1.5382486364208424e-06, 'epoch': 5.89}\n",
      "{'loss': 1.6534, 'learning_rate': 1.554788944339346e-06, 'epoch': 5.95}\n",
      "{'eval_loss': 1.6443688869476318, 'eval_runtime': 3.4815, 'eval_samples_per_second': 643.983, 'eval_steps_per_second': 2.585, 'epoch': 6.0}\n",
      "{'loss': 1.6419, 'learning_rate': 1.5713292522578497e-06, 'epoch': 6.01}\n",
      "{'loss': 1.6366, 'learning_rate': 1.5878695601763533e-06, 'epoch': 6.08}\n",
      "{'loss': 1.6375, 'learning_rate': 1.604409868094857e-06, 'epoch': 6.14}\n",
      "{'loss': 1.607, 'learning_rate': 1.6209501760133606e-06, 'epoch': 6.2}\n",
      "{'loss': 1.6122, 'learning_rate': 1.6374904839318644e-06, 'epoch': 6.27}\n",
      "{'loss': 1.6143, 'learning_rate': 1.654030791850368e-06, 'epoch': 6.33}\n",
      "{'loss': 1.6298, 'learning_rate': 1.6705710997688717e-06, 'epoch': 6.39}\n",
      "{'loss': 1.6062, 'learning_rate': 1.6871114076873754e-06, 'epoch': 6.46}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6135, 'learning_rate': 1.703651715605879e-06, 'epoch': 6.52}\n",
      "{'loss': 1.6076, 'learning_rate': 1.7201920235243827e-06, 'epoch': 6.58}\n",
      "{'loss': 1.5894, 'learning_rate': 1.7367323314428865e-06, 'epoch': 6.65}\n",
      "{'loss': 1.5891, 'learning_rate': 1.7532726393613902e-06, 'epoch': 6.71}\n",
      "{'loss': 1.5742, 'learning_rate': 1.7698129472798938e-06, 'epoch': 6.77}\n",
      "{'loss': 1.5778, 'learning_rate': 1.7863532551983975e-06, 'epoch': 6.84}\n",
      "{'loss': 1.5807, 'learning_rate': 1.8028935631169011e-06, 'epoch': 6.9}\n",
      "{'loss': 1.5662, 'learning_rate': 1.819433871035405e-06, 'epoch': 6.96}\n",
      "{'eval_loss': 1.5639469623565674, 'eval_runtime': 3.4794, 'eval_samples_per_second': 644.361, 'eval_steps_per_second': 2.587, 'epoch': 7.0}\n",
      "{'loss': 1.5727, 'learning_rate': 1.8359741789539086e-06, 'epoch': 7.03}\n",
      "{'loss': 1.5777, 'learning_rate': 1.8525144868724123e-06, 'epoch': 7.09}\n",
      "{'loss': 1.5403, 'learning_rate': 1.869054794790916e-06, 'epoch': 7.15}\n",
      "{'loss': 1.5417, 'learning_rate': 1.8855951027094195e-06, 'epoch': 7.22}\n",
      "{'loss': 1.5358, 'learning_rate': 1.902135410627923e-06, 'epoch': 7.28}\n",
      "{'loss': 1.5516, 'learning_rate': 1.918675718546427e-06, 'epoch': 7.34}\n",
      "{'loss': 1.5286, 'learning_rate': 1.9352160264649305e-06, 'epoch': 7.41}\n",
      "{'loss': 1.514, 'learning_rate': 1.9517563343834343e-06, 'epoch': 7.47}\n",
      "{'loss': 1.5115, 'learning_rate': 1.9682966423019378e-06, 'epoch': 7.53}\n",
      "{'loss': 1.5041, 'learning_rate': 1.9848369502204416e-06, 'epoch': 7.59}\n",
      "{'loss': 1.5152, 'learning_rate': 2.0013772581389455e-06, 'epoch': 7.66}\n",
      "{'loss': 1.504, 'learning_rate': 2.017917566057449e-06, 'epoch': 7.72}\n",
      "{'loss': 1.5028, 'learning_rate': 2.0344578739759528e-06, 'epoch': 7.78}\n",
      "{'loss': 1.5051, 'learning_rate': 2.050998181894456e-06, 'epoch': 7.85}\n",
      "{'loss': 1.4913, 'learning_rate': 2.06753848981296e-06, 'epoch': 7.91}\n",
      "{'loss': 1.4556, 'learning_rate': 2.0840787977314635e-06, 'epoch': 7.97}\n",
      "{'eval_loss': 1.476601004600525, 'eval_runtime': 3.4787, 'eval_samples_per_second': 644.494, 'eval_steps_per_second': 2.587, 'epoch': 8.0}\n",
      "{'loss': 1.4822, 'learning_rate': 2.1006191056499674e-06, 'epoch': 8.04}\n",
      "{'loss': 1.4588, 'learning_rate': 2.117159413568471e-06, 'epoch': 8.1}\n",
      "{'loss': 1.4725, 'learning_rate': 2.1336997214869746e-06, 'epoch': 8.16}\n",
      "{'loss': 1.4473, 'learning_rate': 2.1502400294054785e-06, 'epoch': 8.23}\n",
      "{'loss': 1.4605, 'learning_rate': 2.166780337323982e-06, 'epoch': 8.29}\n",
      "{'loss': 1.4697, 'learning_rate': 2.183320645242486e-06, 'epoch': 8.35}\n",
      "{'loss': 1.4622, 'learning_rate': 2.1998609531609896e-06, 'epoch': 8.42}\n",
      "{'loss': 1.433, 'learning_rate': 2.216401261079493e-06, 'epoch': 8.48}\n",
      "{'loss': 1.4273, 'learning_rate': 2.232941568997997e-06, 'epoch': 8.54}\n",
      "{'loss': 1.4086, 'learning_rate': 2.2494818769165004e-06, 'epoch': 8.61}\n",
      "{'loss': 1.4377, 'learning_rate': 2.2660221848350042e-06, 'epoch': 8.67}\n",
      "{'loss': 1.4248, 'learning_rate': 2.282562492753508e-06, 'epoch': 8.73}\n",
      "{'loss': 1.393, 'learning_rate': 2.2991028006720115e-06, 'epoch': 8.8}\n",
      "{'loss': 1.3805, 'learning_rate': 2.3156431085905154e-06, 'epoch': 8.86}\n",
      "{'loss': 1.4043, 'learning_rate': 2.332183416509019e-06, 'epoch': 8.92}\n",
      "{'loss': 1.3919, 'learning_rate': 2.3487237244275227e-06, 'epoch': 8.99}\n",
      "{'eval_loss': 1.3918670415878296, 'eval_runtime': 3.4797, 'eval_samples_per_second': 644.309, 'eval_steps_per_second': 2.586, 'epoch': 9.0}\n",
      "{'loss': 1.3637, 'learning_rate': 2.365264032346026e-06, 'epoch': 9.05}\n",
      "{'loss': 1.3751, 'learning_rate': 2.38180434026453e-06, 'epoch': 9.11}\n",
      "{'loss': 1.3677, 'learning_rate': 2.398344648183034e-06, 'epoch': 9.18}\n",
      "{'loss': 1.347, 'learning_rate': 2.4148849561015372e-06, 'epoch': 9.24}\n",
      "{'loss': 1.3583, 'learning_rate': 2.431425264020041e-06, 'epoch': 9.3}\n",
      "{'loss': 1.3736, 'learning_rate': 2.4479655719385445e-06, 'epoch': 9.37}\n",
      "{'loss': 1.3647, 'learning_rate': 2.4645058798570484e-06, 'epoch': 9.43}\n",
      "{'loss': 1.3738, 'learning_rate': 2.4810461877755522e-06, 'epoch': 9.49}\n",
      "{'loss': 1.3146, 'learning_rate': 2.4975864956940557e-06, 'epoch': 9.56}\n",
      "{'loss': 1.3315, 'learning_rate': 2.5141268036125595e-06, 'epoch': 9.62}\n",
      "{'loss': 1.3226, 'learning_rate': 2.530667111531063e-06, 'epoch': 9.68}\n",
      "{'loss': 1.3033, 'learning_rate': 2.547207419449567e-06, 'epoch': 9.75}\n",
      "{'loss': 1.3492, 'learning_rate': 2.5637477273680707e-06, 'epoch': 9.81}\n",
      "{'loss': 1.3047, 'learning_rate': 2.580288035286574e-06, 'epoch': 9.87}\n",
      "{'loss': 1.3108, 'learning_rate': 2.596828343205078e-06, 'epoch': 9.94}\n",
      "{'loss': 1.3164, 'learning_rate': 2.6133686511235814e-06, 'epoch': 10.0}\n",
      "{'eval_loss': 1.3393328189849854, 'eval_runtime': 3.4786, 'eval_samples_per_second': 644.508, 'eval_steps_per_second': 2.587, 'epoch': 10.0}\n",
      "{'loss': 1.293, 'learning_rate': 2.6299089590420853e-06, 'epoch': 10.06}\n",
      "{'loss': 1.2995, 'learning_rate': 2.6464492669605887e-06, 'epoch': 10.13}\n",
      "{'loss': 1.292, 'learning_rate': 2.6629895748790926e-06, 'epoch': 10.19}\n",
      "{'loss': 1.2604, 'learning_rate': 2.6795298827975964e-06, 'epoch': 10.25}\n",
      "{'loss': 1.2854, 'learning_rate': 2.6960701907161e-06, 'epoch': 10.32}\n",
      "{'loss': 1.2921, 'learning_rate': 2.7126104986346037e-06, 'epoch': 10.38}\n",
      "{'loss': 1.2768, 'learning_rate': 2.729150806553107e-06, 'epoch': 10.44}\n",
      "{'loss': 1.2824, 'learning_rate': 2.745691114471611e-06, 'epoch': 10.51}\n",
      "{'loss': 1.2727, 'learning_rate': 2.762231422390115e-06, 'epoch': 10.57}\n",
      "{'loss': 1.2795, 'learning_rate': 2.7787717303086183e-06, 'epoch': 10.63}\n",
      "{'loss': 1.2582, 'learning_rate': 2.795312038227122e-06, 'epoch': 10.7}\n",
      "{'loss': 1.2665, 'learning_rate': 2.8118523461456256e-06, 'epoch': 10.76}\n",
      "{'loss': 1.2639, 'learning_rate': 2.828392654064129e-06, 'epoch': 10.82}\n",
      "{'loss': 1.2696, 'learning_rate': 2.8449329619826333e-06, 'epoch': 10.89}\n",
      "{'loss': 1.2627, 'learning_rate': 2.8614732699011367e-06, 'epoch': 10.95}\n",
      "{'eval_loss': 1.2540440559387207, 'eval_runtime': 3.4787, 'eval_samples_per_second': 644.494, 'eval_steps_per_second': 2.587, 'epoch': 11.0}\n",
      "{'loss': 1.2775, 'learning_rate': 2.8780135778196406e-06, 'epoch': 11.01}\n",
      "{'loss': 1.2568, 'learning_rate': 2.894553885738144e-06, 'epoch': 11.08}\n",
      "{'loss': 1.2195, 'learning_rate': 2.9110941936566474e-06, 'epoch': 11.14}\n",
      "{'loss': 1.2395, 'learning_rate': 2.9276345015751513e-06, 'epoch': 11.2}\n",
      "{'loss': 1.2233, 'learning_rate': 2.944174809493655e-06, 'epoch': 11.27}\n",
      "{'loss': 1.2204, 'learning_rate': 2.960715117412159e-06, 'epoch': 11.33}\n",
      "{'loss': 1.219, 'learning_rate': 2.9772554253306624e-06, 'epoch': 11.39}\n",
      "{'loss': 1.2048, 'learning_rate': 2.925022874009072e-06, 'epoch': 11.46}\n",
      "{'loss': 1.2148, 'learning_rate': 2.8727903226874813e-06, 'epoch': 11.52}\n",
      "{'loss': 1.2124, 'learning_rate': 2.8205577713658907e-06, 'epoch': 11.58}\n",
      "{'loss': 1.2104, 'learning_rate': 2.7683252200443e-06, 'epoch': 11.65}\n",
      "{'loss': 1.1965, 'learning_rate': 2.7160926687227095e-06, 'epoch': 11.71}\n",
      "{'loss': 1.203, 'learning_rate': 2.663860117401119e-06, 'epoch': 11.77}\n",
      "{'loss': 1.2, 'learning_rate': 2.6116275660795283e-06, 'epoch': 11.84}\n",
      "{'loss': 1.2087, 'learning_rate': 2.5593950147579377e-06, 'epoch': 11.9}\n",
      "{'loss': 1.2041, 'learning_rate': 2.507162463436347e-06, 'epoch': 11.96}\n",
      "{'eval_loss': 1.229068636894226, 'eval_runtime': 3.4777, 'eval_samples_per_second': 644.678, 'eval_steps_per_second': 2.588, 'epoch': 12.0}\n",
      "{'loss': 1.194, 'learning_rate': 2.454929912114757e-06, 'epoch': 12.03}\n",
      "{'loss': 1.1923, 'learning_rate': 2.402697360793166e-06, 'epoch': 12.09}\n",
      "{'loss': 1.175, 'learning_rate': 2.3504648094715758e-06, 'epoch': 12.15}\n",
      "{'loss': 1.1772, 'learning_rate': 2.2982322581499848e-06, 'epoch': 12.22}\n",
      "{'loss': 1.1852, 'learning_rate': 2.2459997068283946e-06, 'epoch': 12.28}\n",
      "{'loss': 1.1737, 'learning_rate': 2.193767155506804e-06, 'epoch': 12.34}\n",
      "{'loss': 1.1701, 'learning_rate': 2.1415346041852134e-06, 'epoch': 12.41}\n",
      "{'loss': 1.1789, 'learning_rate': 2.089302052863623e-06, 'epoch': 12.47}\n",
      "{'loss': 1.1375, 'learning_rate': 2.0370695015420322e-06, 'epoch': 12.53}\n",
      "{'loss': 1.1692, 'learning_rate': 1.9848369502204416e-06, 'epoch': 12.59}\n",
      "{'loss': 1.1979, 'learning_rate': 1.932604398898851e-06, 'epoch': 12.66}\n",
      "{'loss': 1.1395, 'learning_rate': 1.8803718475772604e-06, 'epoch': 12.72}\n",
      "{'loss': 1.16, 'learning_rate': 1.82813929625567e-06, 'epoch': 12.78}\n",
      "{'loss': 1.169, 'learning_rate': 1.7759067449340793e-06, 'epoch': 12.85}\n",
      "{'loss': 1.152, 'learning_rate': 1.7236741936124889e-06, 'epoch': 12.91}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1594, 'learning_rate': 1.671441642290898e-06, 'epoch': 12.97}\n",
      "{'eval_loss': 1.196020483970642, 'eval_runtime': 3.4721, 'eval_samples_per_second': 645.717, 'eval_steps_per_second': 2.592, 'epoch': 13.0}\n",
      "{'loss': 1.1623, 'learning_rate': 1.6192090909693077e-06, 'epoch': 13.04}\n",
      "{'loss': 1.1136, 'learning_rate': 1.566976539647717e-06, 'epoch': 13.1}\n",
      "{'loss': 1.1456, 'learning_rate': 1.5147439883261265e-06, 'epoch': 13.16}\n",
      "{'loss': 1.1374, 'learning_rate': 1.462511437004536e-06, 'epoch': 13.23}\n",
      "{'loss': 1.1348, 'learning_rate': 1.4102788856829453e-06, 'epoch': 13.29}\n",
      "{'loss': 1.116, 'learning_rate': 1.3580463343613547e-06, 'epoch': 13.35}\n",
      "{'loss': 1.1567, 'learning_rate': 1.3058137830397641e-06, 'epoch': 13.42}\n",
      "{'loss': 1.1371, 'learning_rate': 1.2535812317181736e-06, 'epoch': 13.48}\n",
      "{'loss': 1.1313, 'learning_rate': 1.201348680396583e-06, 'epoch': 13.54}\n",
      "{'loss': 1.1349, 'learning_rate': 1.1491161290749924e-06, 'epoch': 13.61}\n",
      "{'loss': 1.1258, 'learning_rate': 1.096883577753402e-06, 'epoch': 13.67}\n",
      "{'loss': 1.1495, 'learning_rate': 1.0446510264318114e-06, 'epoch': 13.73}\n",
      "{'loss': 1.1379, 'learning_rate': 9.924184751102208e-07, 'epoch': 13.8}\n",
      "{'loss': 1.13, 'learning_rate': 9.401859237886302e-07, 'epoch': 13.86}\n",
      "{'loss': 1.1405, 'learning_rate': 8.879533724670396e-07, 'epoch': 13.92}\n",
      "{'loss': 1.1142, 'learning_rate': 8.35720821145449e-07, 'epoch': 13.99}\n",
      "{'eval_loss': 1.1711809635162354, 'eval_runtime': 3.4665, 'eval_samples_per_second': 646.767, 'eval_steps_per_second': 2.596, 'epoch': 14.0}\n",
      "{'loss': 1.1437, 'learning_rate': 7.834882698238584e-07, 'epoch': 14.05}\n",
      "{'loss': 1.1033, 'learning_rate': 7.31255718502268e-07, 'epoch': 14.11}\n",
      "{'loss': 1.1055, 'learning_rate': 6.790231671806774e-07, 'epoch': 14.18}\n",
      "{'loss': 1.1223, 'learning_rate': 6.267906158590868e-07, 'epoch': 14.24}\n",
      "{'loss': 1.1113, 'learning_rate': 5.745580645374962e-07, 'epoch': 14.3}\n",
      "{'loss': 1.1129, 'learning_rate': 5.223255132159057e-07, 'epoch': 14.37}\n",
      "{'loss': 1.113, 'learning_rate': 4.700929618943151e-07, 'epoch': 14.43}\n",
      "{'loss': 1.1406, 'learning_rate': 4.178604105727245e-07, 'epoch': 14.49}\n",
      "{'loss': 1.145, 'learning_rate': 3.65627859251134e-07, 'epoch': 14.56}\n",
      "{'loss': 1.1371, 'learning_rate': 3.133953079295434e-07, 'epoch': 14.62}\n",
      "{'loss': 1.0998, 'learning_rate': 2.6116275660795285e-07, 'epoch': 14.68}\n",
      "{'loss': 1.1017, 'learning_rate': 2.0893020528636226e-07, 'epoch': 14.75}\n",
      "{'loss': 1.0981, 'learning_rate': 1.566976539647717e-07, 'epoch': 14.81}\n",
      "{'loss': 1.082, 'learning_rate': 1.0446510264318113e-07, 'epoch': 14.87}\n",
      "{'loss': 1.1178, 'learning_rate': 5.2232551321590565e-08, 'epoch': 14.94}\n",
      "{'loss': 1.1369, 'learning_rate': 0.0, 'epoch': 15.0}\n",
      "{'eval_loss': 1.1652449369430542, 'eval_runtime': 3.4775, 'eval_samples_per_second': 644.709, 'eval_steps_per_second': 2.588, 'epoch': 15.0}\n",
      "{'train_runtime': 1380.147, 'train_samples_per_second': 219.259, 'train_steps_per_second': 0.859, 'train_loss': 1.491165949825496, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-06 11:36:52,675]\u001b[0m Trial 0 finished with value: 1.1652449369430542 and parameters: {'learning_rate': 2.9772554253306624e-06, 'weight_decay': 1.0485738199546166e-05, 'num_train_epochs': 15, 'eval_steps': 329, 'warmup_steps': 900}. Best is trial 0 with value: 1.1652449369430542.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1652449369430542, 'eval_runtime': 3.466, 'eval_samples_per_second': 646.85, 'eval_steps_per_second': 2.597, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103616/2041105136.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", low=1e-6, high=1e-4)\n",
      "/tmp/ipykernel_103616/2041105136.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", low=1e-6, high=1e-4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/wifo3tp01/miniconda3/envs/authentication/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8236, 'learning_rate': 2.933460510850224e-08, 'epoch': 0.06}\n",
      "{'loss': 1.8081, 'learning_rate': 5.866921021700448e-08, 'epoch': 0.13}\n",
      "{'loss': 1.8127, 'learning_rate': 8.800381532550672e-08, 'epoch': 0.19}\n",
      "{'loss': 1.8117, 'learning_rate': 1.1733842043400897e-07, 'epoch': 0.25}\n",
      "{'loss': 1.8112, 'learning_rate': 1.466730255425112e-07, 'epoch': 0.32}\n",
      "{'loss': 1.8245, 'learning_rate': 1.7600763065101343e-07, 'epoch': 0.38}\n",
      "{'loss': 1.8148, 'learning_rate': 2.0534223575951567e-07, 'epoch': 0.44}\n",
      "{'loss': 1.8126, 'learning_rate': 2.3467684086801793e-07, 'epoch': 0.51}\n",
      "{'loss': 1.8186, 'learning_rate': 2.6401144597652014e-07, 'epoch': 0.57}\n",
      "{'loss': 1.8128, 'learning_rate': 2.933460510850224e-07, 'epoch': 0.63}\n",
      "{'loss': 1.8191, 'learning_rate': 3.2268065619352466e-07, 'epoch': 0.7}\n",
      "{'loss': 1.807, 'learning_rate': 3.5201526130202687e-07, 'epoch': 0.76}\n",
      "{'loss': 1.8057, 'learning_rate': 3.8134986641052913e-07, 'epoch': 0.82}\n",
      "{'loss': 1.8134, 'learning_rate': 4.1068447151903134e-07, 'epoch': 0.89}\n",
      "{'loss': 1.8071, 'learning_rate': 4.400190766275336e-07, 'epoch': 0.95}\n",
      "{'eval_loss': 1.8005331754684448, 'eval_runtime': 3.4765, 'eval_samples_per_second': 644.896, 'eval_steps_per_second': 2.589, 'epoch': 1.0}\n",
      "{'loss': 1.7898, 'learning_rate': 4.6935368173603586e-07, 'epoch': 1.01}\n",
      "{'loss': 1.805, 'learning_rate': 4.986882868445381e-07, 'epoch': 1.08}\n",
      "{'loss': 1.8065, 'learning_rate': 5.280228919530403e-07, 'epoch': 1.14}\n",
      "{'loss': 1.7941, 'learning_rate': 5.573574970615425e-07, 'epoch': 1.2}\n",
      "{'loss': 1.7857, 'learning_rate': 5.866921021700448e-07, 'epoch': 1.27}\n",
      "{'loss': 1.7972, 'learning_rate': 6.16026707278547e-07, 'epoch': 1.33}\n",
      "{'loss': 1.8025, 'learning_rate': 6.453613123870493e-07, 'epoch': 1.39}\n",
      "{'loss': 1.8018, 'learning_rate': 6.746959174955514e-07, 'epoch': 1.46}\n",
      "{'loss': 1.7983, 'learning_rate': 7.040305226040537e-07, 'epoch': 1.52}\n",
      "{'loss': 1.7973, 'learning_rate': 7.333651277125559e-07, 'epoch': 1.58}\n",
      "{'loss': 1.7891, 'learning_rate': 7.626997328210583e-07, 'epoch': 1.65}\n",
      "{'loss': 1.7934, 'learning_rate': 7.920343379295605e-07, 'epoch': 1.71}\n",
      "{'loss': 1.789, 'learning_rate': 8.213689430380627e-07, 'epoch': 1.77}\n",
      "{'loss': 1.7878, 'learning_rate': 8.507035481465649e-07, 'epoch': 1.84}\n",
      "{'loss': 1.7928, 'learning_rate': 8.800381532550672e-07, 'epoch': 1.9}\n",
      "{'loss': 1.788, 'learning_rate': 9.093727583635694e-07, 'epoch': 1.96}\n",
      "{'eval_loss': 1.7816394567489624, 'eval_runtime': 3.4784, 'eval_samples_per_second': 644.548, 'eval_steps_per_second': 2.587, 'epoch': 2.0}\n",
      "{'loss': 1.7855, 'learning_rate': 9.387073634720717e-07, 'epoch': 2.03}\n",
      "{'loss': 1.7786, 'learning_rate': 9.680419685805738e-07, 'epoch': 2.09}\n",
      "{'loss': 1.7806, 'learning_rate': 9.973765736890761e-07, 'epoch': 2.15}\n",
      "{'loss': 1.7857, 'learning_rate': 1.0267111787975785e-06, 'epoch': 2.22}\n",
      "{'loss': 1.778, 'learning_rate': 1.0560457839060806e-06, 'epoch': 2.28}\n",
      "{'loss': 1.7717, 'learning_rate': 1.0853803890145829e-06, 'epoch': 2.34}\n",
      "{'loss': 1.7812, 'learning_rate': 1.114714994123085e-06, 'epoch': 2.41}\n",
      "{'loss': 1.7754, 'learning_rate': 1.1440495992315873e-06, 'epoch': 2.47}\n",
      "{'loss': 1.7677, 'learning_rate': 1.1733842043400896e-06, 'epoch': 2.53}\n",
      "{'loss': 1.7718, 'learning_rate': 1.202718809448592e-06, 'epoch': 2.59}\n",
      "{'loss': 1.7591, 'learning_rate': 1.232053414557094e-06, 'epoch': 2.66}\n",
      "{'loss': 1.7624, 'learning_rate': 1.2613880196655963e-06, 'epoch': 2.72}\n",
      "{'loss': 1.7602, 'learning_rate': 1.2907226247740986e-06, 'epoch': 2.78}\n",
      "{'loss': 1.766, 'learning_rate': 1.320057229882601e-06, 'epoch': 2.85}\n",
      "{'loss': 1.7559, 'learning_rate': 1.3493918349911028e-06, 'epoch': 2.91}\n",
      "{'loss': 1.7609, 'learning_rate': 1.3787264400996052e-06, 'epoch': 2.97}\n",
      "{'eval_loss': 1.74822998046875, 'eval_runtime': 3.472, 'eval_samples_per_second': 645.737, 'eval_steps_per_second': 2.592, 'epoch': 3.0}\n",
      "{'loss': 1.7525, 'learning_rate': 1.4080610452081075e-06, 'epoch': 3.04}\n",
      "{'loss': 1.7624, 'learning_rate': 1.4373956503166098e-06, 'epoch': 3.1}\n",
      "{'loss': 1.7436, 'learning_rate': 1.4667302554251119e-06, 'epoch': 3.16}\n",
      "{'loss': 1.7373, 'learning_rate': 1.4960648605336142e-06, 'epoch': 3.23}\n",
      "{'loss': 1.7461, 'learning_rate': 1.5253994656421165e-06, 'epoch': 3.29}\n",
      "{'loss': 1.7384, 'learning_rate': 1.5547340707506188e-06, 'epoch': 3.35}\n",
      "{'loss': 1.74, 'learning_rate': 1.584068675859121e-06, 'epoch': 3.42}\n",
      "{'loss': 1.7296, 'learning_rate': 1.6134032809676232e-06, 'epoch': 3.48}\n",
      "{'loss': 1.73, 'learning_rate': 1.6427378860761254e-06, 'epoch': 3.54}\n",
      "{'loss': 1.717, 'learning_rate': 1.6720724911846277e-06, 'epoch': 3.61}\n",
      "{'loss': 1.721, 'learning_rate': 1.7014070962931298e-06, 'epoch': 3.67}\n",
      "{'loss': 1.7176, 'learning_rate': 1.730741701401632e-06, 'epoch': 3.73}\n",
      "{'loss': 1.7245, 'learning_rate': 1.7600763065101344e-06, 'epoch': 3.8}\n",
      "{'loss': 1.7104, 'learning_rate': 1.7894109116186367e-06, 'epoch': 3.86}\n",
      "{'loss': 1.6934, 'learning_rate': 1.8187455167271388e-06, 'epoch': 3.92}\n",
      "{'loss': 1.7067, 'learning_rate': 1.8480801218356411e-06, 'epoch': 3.99}\n",
      "{'eval_loss': 1.7039660215377808, 'eval_runtime': 3.4789, 'eval_samples_per_second': 644.46, 'eval_steps_per_second': 2.587, 'epoch': 4.0}\n",
      "{'loss': 1.7118, 'learning_rate': 1.8774147269441434e-06, 'epoch': 4.05}\n",
      "{'loss': 1.6982, 'learning_rate': 1.9067493320526458e-06, 'epoch': 4.11}\n",
      "{'loss': 1.6851, 'learning_rate': 1.9360839371611476e-06, 'epoch': 4.18}\n",
      "{'loss': 1.7073, 'learning_rate': 1.96541854226965e-06, 'epoch': 4.24}\n",
      "{'loss': 1.6793, 'learning_rate': 1.9947531473781523e-06, 'epoch': 4.3}\n",
      "{'loss': 1.6826, 'learning_rate': 2.0240877524866546e-06, 'epoch': 4.37}\n",
      "{'loss': 1.6707, 'learning_rate': 2.053422357595157e-06, 'epoch': 4.43}\n",
      "{'loss': 1.6835, 'learning_rate': 2.0827569627036592e-06, 'epoch': 4.49}\n",
      "{'loss': 1.6666, 'learning_rate': 2.112091567812161e-06, 'epoch': 4.56}\n",
      "{'loss': 1.6582, 'learning_rate': 2.1414261729206634e-06, 'epoch': 4.62}\n",
      "{'loss': 1.6463, 'learning_rate': 2.1707607780291657e-06, 'epoch': 4.68}\n",
      "{'loss': 1.6686, 'learning_rate': 2.200095383137668e-06, 'epoch': 4.75}\n",
      "{'loss': 1.6457, 'learning_rate': 2.22942998824617e-06, 'epoch': 4.81}\n",
      "{'loss': 1.6392, 'learning_rate': 2.2587645933546723e-06, 'epoch': 4.87}\n",
      "{'loss': 1.6483, 'learning_rate': 2.2880991984631746e-06, 'epoch': 4.94}\n",
      "{'loss': 1.6426, 'learning_rate': 2.317433803571677e-06, 'epoch': 5.0}\n",
      "{'eval_loss': 1.6448535919189453, 'eval_runtime': 3.4814, 'eval_samples_per_second': 644.001, 'eval_steps_per_second': 2.585, 'epoch': 5.0}\n",
      "{'loss': 1.6365, 'learning_rate': 2.346768408680179e-06, 'epoch': 5.06}\n",
      "{'loss': 1.6098, 'learning_rate': 2.3672012194087644e-06, 'epoch': 5.13}\n",
      "{'loss': 1.6324, 'learning_rate': 2.3520268526176828e-06, 'epoch': 5.19}\n",
      "{'loss': 1.6248, 'learning_rate': 2.336852485826601e-06, 'epoch': 5.25}\n",
      "{'loss': 1.592, 'learning_rate': 2.321678119035519e-06, 'epoch': 5.32}\n",
      "{'loss': 1.6067, 'learning_rate': 2.306503752244437e-06, 'epoch': 5.38}\n",
      "{'loss': 1.587, 'learning_rate': 2.2913293854533555e-06, 'epoch': 5.44}\n",
      "{'loss': 1.5876, 'learning_rate': 2.2761550186622735e-06, 'epoch': 5.51}\n",
      "{'loss': 1.5612, 'learning_rate': 2.260980651871192e-06, 'epoch': 5.57}\n",
      "{'loss': 1.5624, 'learning_rate': 2.2458062850801102e-06, 'epoch': 5.63}\n",
      "{'loss': 1.5694, 'learning_rate': 2.2306319182890282e-06, 'epoch': 5.7}\n",
      "{'loss': 1.552, 'learning_rate': 2.215457551497946e-06, 'epoch': 5.76}\n",
      "{'loss': 1.5602, 'learning_rate': 2.2002831847068646e-06, 'epoch': 5.82}\n",
      "{'loss': 1.5588, 'learning_rate': 2.185108817915783e-06, 'epoch': 5.89}\n",
      "{'loss': 1.5546, 'learning_rate': 2.169934451124701e-06, 'epoch': 5.95}\n",
      "{'eval_loss': 1.537848711013794, 'eval_runtime': 3.4805, 'eval_samples_per_second': 644.158, 'eval_steps_per_second': 2.586, 'epoch': 6.0}\n",
      "{'loss': 1.5322, 'learning_rate': 2.154760084333619e-06, 'epoch': 6.01}\n",
      "{'loss': 1.5215, 'learning_rate': 2.1395857175425373e-06, 'epoch': 6.08}\n",
      "{'loss': 1.5139, 'learning_rate': 2.1244113507514553e-06, 'epoch': 6.14}\n",
      "{'loss': 1.4964, 'learning_rate': 2.1092369839603737e-06, 'epoch': 6.2}\n",
      "{'loss': 1.5019, 'learning_rate': 2.0940626171692916e-06, 'epoch': 6.27}\n",
      "{'loss': 1.4751, 'learning_rate': 2.07888825037821e-06, 'epoch': 6.33}\n",
      "{'loss': 1.4967, 'learning_rate': 2.063713883587128e-06, 'epoch': 6.39}\n",
      "{'loss': 1.467, 'learning_rate': 2.0485395167960464e-06, 'epoch': 6.46}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4724, 'learning_rate': 2.0333651500049648e-06, 'epoch': 6.52}\n",
      "{'loss': 1.4603, 'learning_rate': 2.0181907832138827e-06, 'epoch': 6.58}\n",
      "{'loss': 1.4571, 'learning_rate': 2.0030164164228007e-06, 'epoch': 6.65}\n",
      "{'loss': 1.4493, 'learning_rate': 1.9878420496317187e-06, 'epoch': 6.71}\n",
      "{'loss': 1.4236, 'learning_rate': 1.972667682840637e-06, 'epoch': 6.77}\n",
      "{'loss': 1.4236, 'learning_rate': 1.9574933160495554e-06, 'epoch': 6.84}\n",
      "{'loss': 1.4266, 'learning_rate': 1.9423189492584734e-06, 'epoch': 6.9}\n",
      "{'loss': 1.3885, 'learning_rate': 1.927144582467392e-06, 'epoch': 6.96}\n",
      "{'eval_loss': 1.4189547300338745, 'eval_runtime': 3.4707, 'eval_samples_per_second': 645.979, 'eval_steps_per_second': 2.593, 'epoch': 7.0}\n",
      "{'loss': 1.4245, 'learning_rate': 1.9119702156763098e-06, 'epoch': 7.03}\n",
      "{'loss': 1.4123, 'learning_rate': 1.896795848885228e-06, 'epoch': 7.09}\n",
      "{'loss': 1.3717, 'learning_rate': 1.8816214820941461e-06, 'epoch': 7.15}\n",
      "{'loss': 1.3725, 'learning_rate': 1.8664471153030645e-06, 'epoch': 7.22}\n",
      "{'loss': 1.3826, 'learning_rate': 1.8512727485119825e-06, 'epoch': 7.28}\n",
      "{'loss': 1.3843, 'learning_rate': 1.8360983817209007e-06, 'epoch': 7.34}\n",
      "{'loss': 1.3488, 'learning_rate': 1.820924014929819e-06, 'epoch': 7.41}\n",
      "{'loss': 1.3474, 'learning_rate': 1.805749648138737e-06, 'epoch': 7.47}\n",
      "{'loss': 1.3523, 'learning_rate': 1.7905752813476552e-06, 'epoch': 7.53}\n",
      "{'loss': 1.3131, 'learning_rate': 1.7754009145565734e-06, 'epoch': 7.59}\n",
      "{'loss': 1.3396, 'learning_rate': 1.7602265477654918e-06, 'epoch': 7.66}\n",
      "{'loss': 1.3315, 'learning_rate': 1.7450521809744098e-06, 'epoch': 7.72}\n",
      "{'loss': 1.3301, 'learning_rate': 1.729877814183328e-06, 'epoch': 7.78}\n",
      "{'loss': 1.3422, 'learning_rate': 1.7147034473922463e-06, 'epoch': 7.85}\n",
      "{'loss': 1.3342, 'learning_rate': 1.6995290806011643e-06, 'epoch': 7.91}\n",
      "{'loss': 1.2925, 'learning_rate': 1.6843547138100825e-06, 'epoch': 7.97}\n",
      "{'eval_loss': 1.33101224899292, 'eval_runtime': 3.4715, 'eval_samples_per_second': 645.824, 'eval_steps_per_second': 2.593, 'epoch': 8.0}\n",
      "{'loss': 1.3263, 'learning_rate': 1.6691803470190007e-06, 'epoch': 8.04}\n",
      "{'loss': 1.2997, 'learning_rate': 1.6540059802279188e-06, 'epoch': 8.1}\n",
      "{'loss': 1.3018, 'learning_rate': 1.638831613436837e-06, 'epoch': 8.16}\n",
      "{'loss': 1.2904, 'learning_rate': 1.6236572466457552e-06, 'epoch': 8.23}\n",
      "{'loss': 1.2962, 'learning_rate': 1.6084828798546736e-06, 'epoch': 8.29}\n",
      "{'loss': 1.3031, 'learning_rate': 1.5933085130635916e-06, 'epoch': 8.35}\n",
      "{'loss': 1.2879, 'learning_rate': 1.5781341462725097e-06, 'epoch': 8.42}\n",
      "{'loss': 1.2684, 'learning_rate': 1.5629597794814277e-06, 'epoch': 8.48}\n",
      "{'loss': 1.2676, 'learning_rate': 1.547785412690346e-06, 'epoch': 8.54}\n",
      "{'loss': 1.2531, 'learning_rate': 1.5326110458992643e-06, 'epoch': 8.61}\n",
      "{'loss': 1.288, 'learning_rate': 1.5174366791081825e-06, 'epoch': 8.67}\n",
      "{'loss': 1.2547, 'learning_rate': 1.5022623123171006e-06, 'epoch': 8.73}\n",
      "{'loss': 1.2524, 'learning_rate': 1.4870879455260188e-06, 'epoch': 8.8}\n",
      "{'loss': 1.2369, 'learning_rate': 1.471913578734937e-06, 'epoch': 8.86}\n",
      "{'loss': 1.2754, 'learning_rate': 1.456739211943855e-06, 'epoch': 8.92}\n",
      "{'loss': 1.2551, 'learning_rate': 1.4415648451527733e-06, 'epoch': 8.99}\n",
      "{'eval_loss': 1.2939287424087524, 'eval_runtime': 3.4715, 'eval_samples_per_second': 645.835, 'eval_steps_per_second': 2.593, 'epoch': 9.0}\n",
      "{'loss': 1.2226, 'learning_rate': 1.4263904783616915e-06, 'epoch': 9.05}\n",
      "{'loss': 1.2581, 'learning_rate': 1.4112161115706095e-06, 'epoch': 9.11}\n",
      "{'loss': 1.2314, 'learning_rate': 1.3960417447795279e-06, 'epoch': 9.18}\n",
      "{'loss': 1.2202, 'learning_rate': 1.380867377988446e-06, 'epoch': 9.24}\n",
      "{'loss': 1.2399, 'learning_rate': 1.365693011197364e-06, 'epoch': 9.3}\n",
      "{'loss': 1.247, 'learning_rate': 1.3505186444062822e-06, 'epoch': 9.37}\n",
      "{'loss': 1.2476, 'learning_rate': 1.3353442776152006e-06, 'epoch': 9.43}\n",
      "{'loss': 1.2413, 'learning_rate': 1.3201699108241188e-06, 'epoch': 9.49}\n",
      "{'loss': 1.1897, 'learning_rate': 1.3049955440330368e-06, 'epoch': 9.56}\n",
      "{'loss': 1.2049, 'learning_rate': 1.2898211772419551e-06, 'epoch': 9.62}\n",
      "{'loss': 1.2099, 'learning_rate': 1.2746468104508733e-06, 'epoch': 9.68}\n",
      "{'loss': 1.2012, 'learning_rate': 1.2594724436597913e-06, 'epoch': 9.75}\n",
      "{'loss': 1.24, 'learning_rate': 1.2442980768687095e-06, 'epoch': 9.81}\n",
      "{'loss': 1.2112, 'learning_rate': 1.2291237100776279e-06, 'epoch': 9.87}\n",
      "{'loss': 1.1875, 'learning_rate': 1.2139493432865458e-06, 'epoch': 9.94}\n",
      "{'loss': 1.2221, 'learning_rate': 1.198774976495464e-06, 'epoch': 10.0}\n",
      "{'eval_loss': 1.2509689331054688, 'eval_runtime': 3.4801, 'eval_samples_per_second': 644.241, 'eval_steps_per_second': 2.586, 'epoch': 10.0}\n",
      "{'loss': 1.186, 'learning_rate': 1.1836006097043822e-06, 'epoch': 10.06}\n",
      "{'loss': 1.1708, 'learning_rate': 1.1684262429133006e-06, 'epoch': 10.13}\n",
      "{'loss': 1.1879, 'learning_rate': 1.1532518761222186e-06, 'epoch': 10.19}\n",
      "{'loss': 1.1591, 'learning_rate': 1.1380775093311367e-06, 'epoch': 10.25}\n",
      "{'loss': 1.2065, 'learning_rate': 1.1229031425400551e-06, 'epoch': 10.32}\n",
      "{'loss': 1.2101, 'learning_rate': 1.107728775748973e-06, 'epoch': 10.38}\n",
      "{'loss': 1.1965, 'learning_rate': 1.0925544089578915e-06, 'epoch': 10.44}\n",
      "{'loss': 1.2174, 'learning_rate': 1.0773800421668095e-06, 'epoch': 10.51}\n",
      "{'loss': 1.2043, 'learning_rate': 1.0622056753757276e-06, 'epoch': 10.57}\n",
      "{'loss': 1.2026, 'learning_rate': 1.0470313085846458e-06, 'epoch': 10.63}\n",
      "{'loss': 1.17, 'learning_rate': 1.031856941793564e-06, 'epoch': 10.7}\n",
      "{'loss': 1.1817, 'learning_rate': 1.0166825750024824e-06, 'epoch': 10.76}\n",
      "{'loss': 1.1879, 'learning_rate': 1.0015082082114003e-06, 'epoch': 10.82}\n",
      "{'loss': 1.1876, 'learning_rate': 9.863338414203185e-07, 'epoch': 10.89}\n",
      "{'loss': 1.1904, 'learning_rate': 9.711594746292367e-07, 'epoch': 10.95}\n",
      "{'eval_loss': 1.2435667514801025, 'eval_runtime': 3.469, 'eval_samples_per_second': 646.293, 'eval_steps_per_second': 2.594, 'epoch': 11.0}\n",
      "{'loss': 1.2011, 'learning_rate': 9.559851078381549e-07, 'epoch': 11.01}\n",
      "{'loss': 1.2069, 'learning_rate': 9.408107410470731e-07, 'epoch': 11.08}\n",
      "{'loss': 1.1672, 'learning_rate': 9.256363742559912e-07, 'epoch': 11.14}\n",
      "{'loss': 1.1785, 'learning_rate': 9.104620074649095e-07, 'epoch': 11.2}\n",
      "{'loss': 1.1584, 'learning_rate': 8.952876406738276e-07, 'epoch': 11.27}\n",
      "{'loss': 1.15, 'learning_rate': 8.801132738827459e-07, 'epoch': 11.33}\n",
      "{'loss': 1.1389, 'learning_rate': 8.64938907091664e-07, 'epoch': 11.39}\n",
      "{'loss': 1.154, 'learning_rate': 8.497645403005821e-07, 'epoch': 11.46}\n",
      "{'loss': 1.1466, 'learning_rate': 8.345901735095003e-07, 'epoch': 11.52}\n",
      "{'loss': 1.1646, 'learning_rate': 8.194158067184185e-07, 'epoch': 11.58}\n",
      "{'loss': 1.177, 'learning_rate': 8.042414399273368e-07, 'epoch': 11.65}\n",
      "{'loss': 1.1526, 'learning_rate': 7.890670731362549e-07, 'epoch': 11.71}\n",
      "{'loss': 1.1686, 'learning_rate': 7.73892706345173e-07, 'epoch': 11.77}\n",
      "{'loss': 1.1482, 'learning_rate': 7.587183395540912e-07, 'epoch': 11.84}\n",
      "{'loss': 1.1536, 'learning_rate': 7.435439727630094e-07, 'epoch': 11.9}\n",
      "{'loss': 1.1738, 'learning_rate': 7.283696059719275e-07, 'epoch': 11.96}\n",
      "{'eval_loss': 1.220253586769104, 'eval_runtime': 3.4727, 'eval_samples_per_second': 645.601, 'eval_steps_per_second': 2.592, 'epoch': 12.0}\n",
      "{'loss': 1.1483, 'learning_rate': 7.131952391808458e-07, 'epoch': 12.03}\n",
      "{'loss': 1.1612, 'learning_rate': 6.980208723897639e-07, 'epoch': 12.09}\n",
      "{'loss': 1.1436, 'learning_rate': 6.82846505598682e-07, 'epoch': 12.15}\n",
      "{'loss': 1.1524, 'learning_rate': 6.676721388076003e-07, 'epoch': 12.22}\n",
      "{'loss': 1.1399, 'learning_rate': 6.524977720165184e-07, 'epoch': 12.28}\n",
      "{'loss': 1.1408, 'learning_rate': 6.373234052254367e-07, 'epoch': 12.34}\n",
      "{'loss': 1.1525, 'learning_rate': 6.221490384343547e-07, 'epoch': 12.41}\n",
      "{'loss': 1.1594, 'learning_rate': 6.069746716432729e-07, 'epoch': 12.47}\n",
      "{'loss': 1.1148, 'learning_rate': 5.918003048521911e-07, 'epoch': 12.53}\n",
      "{'loss': 1.1396, 'learning_rate': 5.766259380611093e-07, 'epoch': 12.59}\n",
      "{'loss': 1.1764, 'learning_rate': 5.614515712700276e-07, 'epoch': 12.66}\n",
      "{'loss': 1.1236, 'learning_rate': 5.462772044789457e-07, 'epoch': 12.72}\n",
      "{'loss': 1.1574, 'learning_rate': 5.311028376878638e-07, 'epoch': 12.78}\n",
      "{'loss': 1.148, 'learning_rate': 5.15928470896782e-07, 'epoch': 12.85}\n",
      "{'loss': 1.1428, 'learning_rate': 5.007541041057002e-07, 'epoch': 12.91}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1317, 'learning_rate': 4.855797373146184e-07, 'epoch': 12.97}\n",
      "{'eval_loss': 1.2093795537948608, 'eval_runtime': 3.4724, 'eval_samples_per_second': 645.662, 'eval_steps_per_second': 2.592, 'epoch': 13.0}\n",
      "{'loss': 1.1462, 'learning_rate': 4.7040537052353653e-07, 'epoch': 13.04}\n",
      "{'loss': 1.1106, 'learning_rate': 4.5523100373245477e-07, 'epoch': 13.1}\n",
      "{'loss': 1.1183, 'learning_rate': 4.4005663694137295e-07, 'epoch': 13.16}\n",
      "{'loss': 1.1188, 'learning_rate': 4.2488227015029107e-07, 'epoch': 13.23}\n",
      "{'loss': 1.1494, 'learning_rate': 4.0970790335920925e-07, 'epoch': 13.29}\n",
      "{'loss': 1.1075, 'learning_rate': 3.9453353656812743e-07, 'epoch': 13.35}\n",
      "{'loss': 1.157, 'learning_rate': 3.793591697770456e-07, 'epoch': 13.42}\n",
      "{'loss': 1.1349, 'learning_rate': 3.6418480298596374e-07, 'epoch': 13.48}\n",
      "{'loss': 1.129, 'learning_rate': 3.4901043619488197e-07, 'epoch': 13.54}\n",
      "{'loss': 1.1411, 'learning_rate': 3.3383606940380015e-07, 'epoch': 13.61}\n",
      "{'loss': 1.1332, 'learning_rate': 3.1866170261271833e-07, 'epoch': 13.67}\n",
      "{'loss': 1.1551, 'learning_rate': 3.0348733582163646e-07, 'epoch': 13.73}\n",
      "{'loss': 1.1316, 'learning_rate': 2.8831296903055464e-07, 'epoch': 13.8}\n",
      "{'loss': 1.1475, 'learning_rate': 2.7313860223947287e-07, 'epoch': 13.86}\n",
      "{'loss': 1.1383, 'learning_rate': 2.57964235448391e-07, 'epoch': 13.92}\n",
      "{'loss': 1.1256, 'learning_rate': 2.427898686573092e-07, 'epoch': 13.99}\n",
      "{'eval_loss': 1.197228193283081, 'eval_runtime': 3.4818, 'eval_samples_per_second': 643.911, 'eval_steps_per_second': 2.585, 'epoch': 14.0}\n",
      "{'loss': 1.1425, 'learning_rate': 2.2761550186622738e-07, 'epoch': 14.05}\n",
      "{'loss': 1.1238, 'learning_rate': 2.1244113507514554e-07, 'epoch': 14.11}\n",
      "{'loss': 1.1146, 'learning_rate': 1.9726676828406372e-07, 'epoch': 14.18}\n",
      "{'loss': 1.1331, 'learning_rate': 1.8209240149298187e-07, 'epoch': 14.24}\n",
      "{'loss': 1.1111, 'learning_rate': 1.6691803470190008e-07, 'epoch': 14.3}\n",
      "{'loss': 1.1291, 'learning_rate': 1.5174366791081823e-07, 'epoch': 14.37}\n",
      "{'loss': 1.127, 'learning_rate': 1.3656930111973644e-07, 'epoch': 14.43}\n",
      "{'loss': 1.1478, 'learning_rate': 1.213949343286546e-07, 'epoch': 14.49}\n",
      "{'loss': 1.1614, 'learning_rate': 1.0622056753757277e-07, 'epoch': 14.56}\n",
      "{'loss': 1.1319, 'learning_rate': 9.104620074649093e-08, 'epoch': 14.62}\n",
      "{'loss': 1.1086, 'learning_rate': 7.587183395540911e-08, 'epoch': 14.68}\n",
      "{'loss': 1.1107, 'learning_rate': 6.06974671643273e-08, 'epoch': 14.75}\n",
      "{'loss': 1.1106, 'learning_rate': 4.552310037324547e-08, 'epoch': 14.81}\n",
      "{'loss': 1.0829, 'learning_rate': 3.034873358216365e-08, 'epoch': 14.87}\n",
      "{'loss': 1.1167, 'learning_rate': 1.5174366791081824e-08, 'epoch': 14.94}\n",
      "{'loss': 1.1427, 'learning_rate': 0.0, 'epoch': 15.0}\n",
      "{'eval_loss': 1.194946050643921, 'eval_runtime': 3.4713, 'eval_samples_per_second': 645.863, 'eval_steps_per_second': 2.593, 'epoch': 15.0}\n",
      "{'train_runtime': 1380.8765, 'train_samples_per_second': 219.143, 'train_steps_per_second': 0.858, 'train_loss': 1.4288987622482363, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-06 11:59:58,080]\u001b[0m Trial 1 finished with value: 1.194946050643921 and parameters: {'learning_rate': 2.370236092766981e-06, 'weight_decay': 3.167548004156325e-06, 'num_train_epochs': 15, 'eval_steps': 916, 'warmup_steps': 404}. Best is trial 0 with value: 1.1652449369430542.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.194946050643921, 'eval_runtime': 3.4729, 'eval_samples_per_second': 645.563, 'eval_steps_per_second': 2.591, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103616/2041105136.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", low=1e-6, high=1e-4)\n",
      "/tmp/ipykernel_103616/2041105136.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", low=1e-6, high=1e-4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/wifo3tp01/miniconda3/envs/authentication/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8236, 'learning_rate': 3.1296503914339525e-08, 'epoch': 0.06}\n",
      "{'loss': 1.8081, 'learning_rate': 6.259300782867905e-08, 'epoch': 0.13}\n",
      "{'loss': 1.8126, 'learning_rate': 9.388951174301857e-08, 'epoch': 0.19}\n",
      "{'loss': 1.8117, 'learning_rate': 1.251860156573581e-07, 'epoch': 0.25}\n",
      "{'loss': 1.8111, 'learning_rate': 1.5648251957169762e-07, 'epoch': 0.32}\n",
      "{'loss': 1.8244, 'learning_rate': 1.8777902348603715e-07, 'epoch': 0.38}\n",
      "{'loss': 1.8146, 'learning_rate': 2.1907552740037665e-07, 'epoch': 0.44}\n",
      "{'loss': 1.8124, 'learning_rate': 2.503720313147162e-07, 'epoch': 0.51}\n",
      "{'loss': 1.8184, 'learning_rate': 2.8166853522905575e-07, 'epoch': 0.57}\n",
      "{'loss': 1.8125, 'learning_rate': 3.1296503914339525e-07, 'epoch': 0.63}\n",
      "{'loss': 1.8188, 'learning_rate': 3.4426154305773474e-07, 'epoch': 0.7}\n",
      "{'loss': 1.8066, 'learning_rate': 3.755580469720743e-07, 'epoch': 0.76}\n",
      "{'loss': 1.8052, 'learning_rate': 4.068545508864138e-07, 'epoch': 0.82}\n",
      "{'loss': 1.8128, 'learning_rate': 4.381510548007533e-07, 'epoch': 0.89}\n",
      "{'loss': 1.8068, 'learning_rate': 4.694475587150929e-07, 'epoch': 0.95}\n",
      "{'eval_loss': 1.7999690771102905, 'eval_runtime': 3.4834, 'eval_samples_per_second': 643.621, 'eval_steps_per_second': 2.584, 'epoch': 1.0}\n",
      "{'loss': 1.7895, 'learning_rate': 5.007440626294324e-07, 'epoch': 1.01}\n",
      "{'loss': 1.8044, 'learning_rate': 5.320405665437719e-07, 'epoch': 1.08}\n",
      "{'loss': 1.8059, 'learning_rate': 5.633370704581115e-07, 'epoch': 1.14}\n",
      "{'loss': 1.7936, 'learning_rate': 5.94633574372451e-07, 'epoch': 1.2}\n",
      "{'loss': 1.7852, 'learning_rate': 6.259300782867905e-07, 'epoch': 1.27}\n",
      "{'loss': 1.7963, 'learning_rate': 6.5722658220113e-07, 'epoch': 1.33}\n",
      "{'loss': 1.8016, 'learning_rate': 6.885230861154695e-07, 'epoch': 1.39}\n",
      "{'loss': 1.8008, 'learning_rate': 7.19819590029809e-07, 'epoch': 1.46}\n",
      "{'loss': 1.7973, 'learning_rate': 7.511160939441486e-07, 'epoch': 1.52}\n",
      "{'loss': 1.7963, 'learning_rate': 7.824125978584881e-07, 'epoch': 1.58}\n",
      "{'loss': 1.7882, 'learning_rate': 8.137091017728276e-07, 'epoch': 1.65}\n",
      "{'loss': 1.7922, 'learning_rate': 8.450056056871671e-07, 'epoch': 1.71}\n",
      "{'loss': 1.7877, 'learning_rate': 8.763021096015066e-07, 'epoch': 1.77}\n",
      "{'loss': 1.7868, 'learning_rate': 9.075986135158463e-07, 'epoch': 1.84}\n",
      "{'loss': 1.7914, 'learning_rate': 9.388951174301858e-07, 'epoch': 1.9}\n",
      "{'loss': 1.7866, 'learning_rate': 9.701916213445252e-07, 'epoch': 1.96}\n",
      "{'eval_loss': 1.7802073955535889, 'eval_runtime': 3.4853, 'eval_samples_per_second': 643.272, 'eval_steps_per_second': 2.582, 'epoch': 2.0}\n",
      "{'loss': 1.784, 'learning_rate': 1.0014881252588648e-06, 'epoch': 2.03}\n",
      "{'loss': 1.7771, 'learning_rate': 1.0327846291732042e-06, 'epoch': 2.09}\n",
      "{'loss': 1.779, 'learning_rate': 1.0640811330875438e-06, 'epoch': 2.15}\n",
      "{'loss': 1.7838, 'learning_rate': 1.0953776370018834e-06, 'epoch': 2.22}\n",
      "{'loss': 1.7763, 'learning_rate': 1.126674140916223e-06, 'epoch': 2.28}\n",
      "{'loss': 1.7697, 'learning_rate': 1.1579706448305624e-06, 'epoch': 2.34}\n",
      "{'loss': 1.7788, 'learning_rate': 1.189267148744902e-06, 'epoch': 2.41}\n",
      "{'loss': 1.7731, 'learning_rate': 1.2205636526592414e-06, 'epoch': 2.47}\n",
      "{'loss': 1.7648, 'learning_rate': 1.251860156573581e-06, 'epoch': 2.53}\n",
      "{'loss': 1.7692, 'learning_rate': 1.2831566604879206e-06, 'epoch': 2.59}\n",
      "{'loss': 1.7557, 'learning_rate': 1.31445316440226e-06, 'epoch': 2.66}\n",
      "{'loss': 1.7599, 'learning_rate': 1.3457496683165996e-06, 'epoch': 2.72}\n",
      "{'loss': 1.757, 'learning_rate': 1.377046172230939e-06, 'epoch': 2.78}\n",
      "{'loss': 1.7625, 'learning_rate': 1.4083426761452786e-06, 'epoch': 2.85}\n",
      "{'loss': 1.7524, 'learning_rate': 1.439639180059618e-06, 'epoch': 2.91}\n",
      "{'loss': 1.7564, 'learning_rate': 1.4709356839739576e-06, 'epoch': 2.97}\n",
      "{'eval_loss': 1.7443941831588745, 'eval_runtime': 3.4809, 'eval_samples_per_second': 644.083, 'eval_steps_per_second': 2.586, 'epoch': 3.0}\n",
      "{'loss': 1.7483, 'learning_rate': 1.5022321878882972e-06, 'epoch': 3.04}\n",
      "{'loss': 1.758, 'learning_rate': 1.5335286918026366e-06, 'epoch': 3.1}\n",
      "{'loss': 1.739, 'learning_rate': 1.5648251957169762e-06, 'epoch': 3.16}\n",
      "{'loss': 1.7334, 'learning_rate': 1.5961216996313156e-06, 'epoch': 3.23}\n",
      "{'loss': 1.7422, 'learning_rate': 1.6274182035456552e-06, 'epoch': 3.29}\n",
      "{'loss': 1.7326, 'learning_rate': 1.658714707459995e-06, 'epoch': 3.35}\n",
      "{'loss': 1.7352, 'learning_rate': 1.6900112113743342e-06, 'epoch': 3.42}\n",
      "{'loss': 1.7246, 'learning_rate': 1.721307715288674e-06, 'epoch': 3.48}\n",
      "{'loss': 1.7253, 'learning_rate': 1.7526042192030132e-06, 'epoch': 3.54}\n",
      "{'loss': 1.7125, 'learning_rate': 1.783900723117353e-06, 'epoch': 3.61}\n",
      "{'loss': 1.7155, 'learning_rate': 1.8151972270316926e-06, 'epoch': 3.67}\n",
      "{'loss': 1.7112, 'learning_rate': 1.846493730946032e-06, 'epoch': 3.73}\n",
      "{'loss': 1.7171, 'learning_rate': 1.8777902348603716e-06, 'epoch': 3.8}\n",
      "{'loss': 1.7033, 'learning_rate': 1.9090867387747108e-06, 'epoch': 3.86}\n",
      "{'loss': 1.6867, 'learning_rate': 1.9403832426890504e-06, 'epoch': 3.92}\n",
      "{'loss': 1.6992, 'learning_rate': 1.97167974660339e-06, 'epoch': 3.99}\n",
      "{'eval_loss': 1.6975466012954712, 'eval_runtime': 3.4799, 'eval_samples_per_second': 644.27, 'eval_steps_per_second': 2.586, 'epoch': 4.0}\n",
      "{'loss': 1.7059, 'learning_rate': 2.0029762505177296e-06, 'epoch': 4.05}\n",
      "{'loss': 1.6911, 'learning_rate': 2.034272754432069e-06, 'epoch': 4.11}\n",
      "{'loss': 1.6767, 'learning_rate': 2.0655692583464084e-06, 'epoch': 4.18}\n",
      "{'loss': 1.6976, 'learning_rate': 2.096865762260748e-06, 'epoch': 4.24}\n",
      "{'loss': 1.6684, 'learning_rate': 2.1281622661750876e-06, 'epoch': 4.3}\n",
      "{'loss': 1.6759, 'learning_rate': 2.159458770089427e-06, 'epoch': 4.37}\n",
      "{'loss': 1.6592, 'learning_rate': 2.1907552740037668e-06, 'epoch': 4.43}\n",
      "{'loss': 1.673, 'learning_rate': 2.222051777918106e-06, 'epoch': 4.49}\n",
      "{'loss': 1.6558, 'learning_rate': 2.253348281832446e-06, 'epoch': 4.56}\n",
      "{'loss': 1.6478, 'learning_rate': 2.284644785746785e-06, 'epoch': 4.62}\n",
      "{'loss': 1.635, 'learning_rate': 2.3159412896611248e-06, 'epoch': 4.68}\n",
      "{'loss': 1.6579, 'learning_rate': 2.3472377935754644e-06, 'epoch': 4.75}\n",
      "{'loss': 1.6328, 'learning_rate': 2.378534297489804e-06, 'epoch': 4.81}\n",
      "{'loss': 1.6273, 'learning_rate': 2.4098308014041436e-06, 'epoch': 4.87}\n",
      "{'loss': 1.6347, 'learning_rate': 2.4411273053184828e-06, 'epoch': 4.94}\n",
      "{'loss': 1.6255, 'learning_rate': 2.4724238092328224e-06, 'epoch': 5.0}\n",
      "{'eval_loss': 1.6267094612121582, 'eval_runtime': 3.4793, 'eval_samples_per_second': 644.383, 'eval_steps_per_second': 2.587, 'epoch': 5.0}\n",
      "{'loss': 1.62, 'learning_rate': 2.503720313147162e-06, 'epoch': 5.06}\n",
      "{'loss': 1.5907, 'learning_rate': 2.5350168170615016e-06, 'epoch': 5.13}\n",
      "{'loss': 1.6167, 'learning_rate': 2.566313320975841e-06, 'epoch': 5.19}\n",
      "{'loss': 1.6033, 'learning_rate': 2.5976098248901808e-06, 'epoch': 5.25}\n",
      "{'loss': 1.5726, 'learning_rate': 2.62890632880452e-06, 'epoch': 5.32}\n",
      "{'loss': 1.5866, 'learning_rate': 2.6602028327188596e-06, 'epoch': 5.38}\n",
      "{'loss': 1.5646, 'learning_rate': 2.691499336633199e-06, 'epoch': 5.44}\n",
      "{'loss': 1.5633, 'learning_rate': 2.7227958405475388e-06, 'epoch': 5.51}\n",
      "{'loss': 1.5344, 'learning_rate': 2.754092344461878e-06, 'epoch': 5.57}\n",
      "{'loss': 1.5333, 'learning_rate': 2.7853888483762176e-06, 'epoch': 5.63}\n",
      "{'loss': 1.5373, 'learning_rate': 2.816685352290557e-06, 'epoch': 5.7}\n",
      "{'loss': 1.5217, 'learning_rate': 2.8479818562048968e-06, 'epoch': 5.76}\n",
      "{'loss': 1.525, 'learning_rate': 2.879278360119236e-06, 'epoch': 5.82}\n",
      "{'loss': 1.5216, 'learning_rate': 2.910574864033576e-06, 'epoch': 5.89}\n",
      "{'loss': 1.5078, 'learning_rate': 2.941871367947915e-06, 'epoch': 5.95}\n",
      "{'eval_loss': 1.4862217903137207, 'eval_runtime': 3.4797, 'eval_samples_per_second': 644.313, 'eval_steps_per_second': 2.586, 'epoch': 6.0}\n",
      "{'loss': 1.4903, 'learning_rate': 2.9731678718622548e-06, 'epoch': 6.01}\n",
      "{'loss': 1.4691, 'learning_rate': 3.0044643757765944e-06, 'epoch': 6.08}\n",
      "{'loss': 1.4535, 'learning_rate': 3.035760879690934e-06, 'epoch': 6.14}\n",
      "{'loss': 1.434, 'learning_rate': 3.067057383605273e-06, 'epoch': 6.2}\n",
      "{'loss': 1.4422, 'learning_rate': 3.0983538875196128e-06, 'epoch': 6.27}\n",
      "{'loss': 1.4105, 'learning_rate': 3.1296503914339524e-06, 'epoch': 6.33}\n",
      "{'loss': 1.4242, 'learning_rate': 3.160946895348292e-06, 'epoch': 6.39}\n",
      "{'loss': 1.4007, 'learning_rate': 3.192243399262631e-06, 'epoch': 6.46}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3965, 'learning_rate': 3.223539903176971e-06, 'epoch': 6.52}\n",
      "{'loss': 1.3836, 'learning_rate': 3.2548364070913103e-06, 'epoch': 6.58}\n",
      "{'loss': 1.3817, 'learning_rate': 3.28613291100565e-06, 'epoch': 6.65}\n",
      "{'loss': 1.3728, 'learning_rate': 3.31742941491999e-06, 'epoch': 6.71}\n",
      "{'loss': 1.3483, 'learning_rate': 3.348725918834329e-06, 'epoch': 6.77}\n",
      "{'loss': 1.3462, 'learning_rate': 3.3800224227486683e-06, 'epoch': 6.84}\n",
      "{'loss': 1.3475, 'learning_rate': 3.411318926663008e-06, 'epoch': 6.9}\n",
      "{'loss': 1.3069, 'learning_rate': 3.442615430577348e-06, 'epoch': 6.96}\n",
      "{'eval_loss': 1.3541245460510254, 'eval_runtime': 3.4778, 'eval_samples_per_second': 644.658, 'eval_steps_per_second': 2.588, 'epoch': 7.0}\n",
      "{'loss': 1.3472, 'learning_rate': 3.473911934491687e-06, 'epoch': 7.03}\n",
      "{'loss': 1.3162, 'learning_rate': 3.5052084384060263e-06, 'epoch': 7.09}\n",
      "{'loss': 1.2732, 'learning_rate': 3.5365049423203664e-06, 'epoch': 7.15}\n",
      "{'loss': 1.282, 'learning_rate': 3.567801446234706e-06, 'epoch': 7.22}\n",
      "{'loss': 1.2823, 'learning_rate': 3.599097950149045e-06, 'epoch': 7.28}\n",
      "{'loss': 1.3033, 'learning_rate': 3.630394454063385e-06, 'epoch': 7.34}\n",
      "{'loss': 1.2496, 'learning_rate': 3.6616909579777244e-06, 'epoch': 7.41}\n",
      "{'loss': 1.2467, 'learning_rate': 3.692987461892064e-06, 'epoch': 7.47}\n",
      "{'loss': 1.2481, 'learning_rate': 3.724283965806403e-06, 'epoch': 7.53}\n",
      "{'loss': 1.2087, 'learning_rate': 3.755580469720743e-06, 'epoch': 7.59}\n",
      "{'loss': 1.2299, 'learning_rate': 3.7868769736350823e-06, 'epoch': 7.66}\n",
      "{'loss': 1.2285, 'learning_rate': 3.8181734775494215e-06, 'epoch': 7.72}\n",
      "{'loss': 1.2248, 'learning_rate': 3.849469981463762e-06, 'epoch': 7.78}\n",
      "{'loss': 1.2392, 'learning_rate': 3.880766485378101e-06, 'epoch': 7.85}\n",
      "{'loss': 1.2224, 'learning_rate': 3.91206298929244e-06, 'epoch': 7.91}\n",
      "{'loss': 1.1777, 'learning_rate': 3.94335949320678e-06, 'epoch': 7.97}\n",
      "{'eval_loss': 1.2266823053359985, 'eval_runtime': 3.4685, 'eval_samples_per_second': 646.393, 'eval_steps_per_second': 2.595, 'epoch': 8.0}\n",
      "{'loss': 1.2069, 'learning_rate': 3.9746559971211195e-06, 'epoch': 8.04}\n",
      "{'loss': 1.1669, 'learning_rate': 4.005952501035459e-06, 'epoch': 8.1}\n",
      "{'loss': 1.1798, 'learning_rate': 4.037249004949799e-06, 'epoch': 8.16}\n",
      "{'loss': 1.1623, 'learning_rate': 4.068545508864138e-06, 'epoch': 8.23}\n",
      "{'loss': 1.172, 'learning_rate': 4.099842012778478e-06, 'epoch': 8.29}\n",
      "{'loss': 1.1843, 'learning_rate': 4.131138516692817e-06, 'epoch': 8.35}\n",
      "{'loss': 1.1679, 'learning_rate': 4.162435020607157e-06, 'epoch': 8.42}\n",
      "{'loss': 1.1397, 'learning_rate': 4.193731524521496e-06, 'epoch': 8.48}\n",
      "{'loss': 1.1469, 'learning_rate': 4.2250280284358355e-06, 'epoch': 8.54}\n",
      "{'loss': 1.1194, 'learning_rate': 4.256324532350175e-06, 'epoch': 8.61}\n",
      "{'loss': 1.1552, 'learning_rate': 4.287621036264515e-06, 'epoch': 8.67}\n",
      "{'loss': 1.1139, 'learning_rate': 4.318917540178854e-06, 'epoch': 8.73}\n",
      "{'loss': 1.1198, 'learning_rate': 4.350214044093194e-06, 'epoch': 8.8}\n",
      "{'loss': 1.0932, 'learning_rate': 4.3815105480075336e-06, 'epoch': 8.86}\n",
      "{'loss': 1.1481, 'learning_rate': 4.412807051921873e-06, 'epoch': 8.92}\n",
      "{'loss': 1.1159, 'learning_rate': 4.444103555836212e-06, 'epoch': 8.99}\n",
      "{'eval_loss': 1.1650296449661255, 'eval_runtime': 3.4817, 'eval_samples_per_second': 643.938, 'eval_steps_per_second': 2.585, 'epoch': 9.0}\n",
      "{'loss': 1.0815, 'learning_rate': 4.475400059750552e-06, 'epoch': 9.05}\n",
      "{'loss': 1.1113, 'learning_rate': 4.506696563664892e-06, 'epoch': 9.11}\n",
      "{'loss': 1.079, 'learning_rate': 4.537993067579231e-06, 'epoch': 9.18}\n",
      "{'loss': 1.0824, 'learning_rate': 4.56928957149357e-06, 'epoch': 9.24}\n",
      "{'loss': 1.0824, 'learning_rate': 4.60058607540791e-06, 'epoch': 9.3}\n",
      "{'loss': 1.1012, 'learning_rate': 4.6318825793222495e-06, 'epoch': 9.37}\n",
      "{'loss': 1.1028, 'learning_rate': 4.663179083236589e-06, 'epoch': 9.43}\n",
      "{'loss': 1.0867, 'learning_rate': 4.694475587150929e-06, 'epoch': 9.49}\n",
      "{'loss': 1.036, 'learning_rate': 4.725772091065268e-06, 'epoch': 9.56}\n",
      "{'loss': 1.052, 'learning_rate': 4.757068594979608e-06, 'epoch': 9.62}\n",
      "{'loss': 1.0641, 'learning_rate': 4.7883650988939476e-06, 'epoch': 9.68}\n",
      "{'loss': 1.0301, 'learning_rate': 4.819661602808287e-06, 'epoch': 9.75}\n",
      "{'loss': 1.0975, 'learning_rate': 4.850958106722626e-06, 'epoch': 9.81}\n",
      "{'loss': 1.0472, 'learning_rate': 4.8822546106369655e-06, 'epoch': 9.87}\n",
      "{'loss': 1.0167, 'learning_rate': 4.913551114551305e-06, 'epoch': 9.94}\n",
      "{'loss': 1.0674, 'learning_rate': 4.944847618465645e-06, 'epoch': 10.0}\n",
      "{'eval_loss': 1.1631299257278442, 'eval_runtime': 3.4694, 'eval_samples_per_second': 646.227, 'eval_steps_per_second': 2.594, 'epoch': 10.0}\n",
      "{'loss': 1.0121, 'learning_rate': 4.976144122379984e-06, 'epoch': 10.06}\n",
      "{'loss': 0.9963, 'learning_rate': 5.007440626294324e-06, 'epoch': 10.13}\n",
      "{'loss': 0.9995, 'learning_rate': 5.0387371302086635e-06, 'epoch': 10.19}\n",
      "{'loss': 0.9719, 'learning_rate': 5.070033634123003e-06, 'epoch': 10.25}\n",
      "{'loss': 1.0367, 'learning_rate': 5.101330138037342e-06, 'epoch': 10.32}\n",
      "{'loss': 1.037, 'learning_rate': 5.132626641951682e-06, 'epoch': 10.38}\n",
      "{'loss': 1.0258, 'learning_rate': 5.163923145866021e-06, 'epoch': 10.44}\n",
      "{'loss': 1.0334, 'learning_rate': 5.133063743961659e-06, 'epoch': 10.51}\n",
      "{'loss': 1.0373, 'learning_rate': 5.060767071511495e-06, 'epoch': 10.57}\n",
      "{'loss': 1.0345, 'learning_rate': 4.988470399061331e-06, 'epoch': 10.63}\n",
      "{'loss': 0.9896, 'learning_rate': 4.916173726611166e-06, 'epoch': 10.7}\n",
      "{'loss': 0.999, 'learning_rate': 4.843877054161002e-06, 'epoch': 10.76}\n",
      "{'loss': 1.0089, 'learning_rate': 4.771580381710838e-06, 'epoch': 10.82}\n",
      "{'loss': 1.0012, 'learning_rate': 4.699283709260674e-06, 'epoch': 10.89}\n",
      "{'loss': 1.0026, 'learning_rate': 4.626987036810509e-06, 'epoch': 10.95}\n",
      "{'eval_loss': 1.1141101121902466, 'eval_runtime': 3.4791, 'eval_samples_per_second': 644.414, 'eval_steps_per_second': 2.587, 'epoch': 11.0}\n",
      "{'loss': 1.0335, 'learning_rate': 4.554690364360346e-06, 'epoch': 11.01}\n",
      "{'loss': 1.0189, 'learning_rate': 4.482393691910181e-06, 'epoch': 11.08}\n",
      "{'loss': 0.9692, 'learning_rate': 4.410097019460017e-06, 'epoch': 11.14}\n",
      "{'loss': 0.9834, 'learning_rate': 4.3378003470098526e-06, 'epoch': 11.2}\n",
      "{'loss': 0.9658, 'learning_rate': 4.2655036745596885e-06, 'epoch': 11.27}\n",
      "{'loss': 0.9381, 'learning_rate': 4.193207002109524e-06, 'epoch': 11.33}\n",
      "{'loss': 0.9349, 'learning_rate': 4.1209103296593596e-06, 'epoch': 11.39}\n",
      "{'loss': 0.9565, 'learning_rate': 4.0486136572091955e-06, 'epoch': 11.46}\n",
      "{'loss': 0.9489, 'learning_rate': 3.9763169847590314e-06, 'epoch': 11.52}\n",
      "{'loss': 0.9777, 'learning_rate': 3.904020312308867e-06, 'epoch': 11.58}\n",
      "{'loss': 0.98, 'learning_rate': 3.831723639858703e-06, 'epoch': 11.65}\n",
      "{'loss': 0.9556, 'learning_rate': 3.759426967408539e-06, 'epoch': 11.71}\n",
      "{'loss': 0.9735, 'learning_rate': 3.6871302949583744e-06, 'epoch': 11.77}\n",
      "{'loss': 0.9375, 'learning_rate': 3.6148336225082103e-06, 'epoch': 11.84}\n",
      "{'loss': 0.961, 'learning_rate': 3.542536950058046e-06, 'epoch': 11.9}\n",
      "{'loss': 0.969, 'learning_rate': 3.470240277607882e-06, 'epoch': 11.96}\n",
      "{'eval_loss': 1.0784199237823486, 'eval_runtime': 3.4777, 'eval_samples_per_second': 644.687, 'eval_steps_per_second': 2.588, 'epoch': 12.0}\n",
      "{'loss': 0.9574, 'learning_rate': 3.3979436051577173e-06, 'epoch': 12.03}\n",
      "{'loss': 0.9588, 'learning_rate': 3.3256469327075537e-06, 'epoch': 12.09}\n",
      "{'loss': 0.9223, 'learning_rate': 3.2533502602573896e-06, 'epoch': 12.15}\n",
      "{'loss': 0.9192, 'learning_rate': 3.181053587807225e-06, 'epoch': 12.22}\n",
      "{'loss': 0.9226, 'learning_rate': 3.108756915357061e-06, 'epoch': 12.28}\n",
      "{'loss': 0.9274, 'learning_rate': 3.0364602429068966e-06, 'epoch': 12.34}\n",
      "{'loss': 0.9352, 'learning_rate': 2.9641635704567326e-06, 'epoch': 12.41}\n",
      "{'loss': 0.9483, 'learning_rate': 2.891866898006568e-06, 'epoch': 12.47}\n",
      "{'loss': 0.8917, 'learning_rate': 2.819570225556404e-06, 'epoch': 12.53}\n",
      "{'loss': 0.9394, 'learning_rate': 2.74727355310624e-06, 'epoch': 12.59}\n",
      "{'loss': 0.9817, 'learning_rate': 2.674976880656076e-06, 'epoch': 12.66}\n",
      "{'loss': 0.8966, 'learning_rate': 2.6026802082059115e-06, 'epoch': 12.72}\n",
      "{'loss': 0.9449, 'learning_rate': 2.5303835357557474e-06, 'epoch': 12.78}\n",
      "{'loss': 0.94, 'learning_rate': 2.458086863305583e-06, 'epoch': 12.85}\n",
      "{'loss': 0.9316, 'learning_rate': 2.385790190855419e-06, 'epoch': 12.91}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9228, 'learning_rate': 2.3134935184052544e-06, 'epoch': 12.97}\n",
      "{'eval_loss': 1.1188983917236328, 'eval_runtime': 3.4693, 'eval_samples_per_second': 646.24, 'eval_steps_per_second': 2.594, 'epoch': 13.0}\n",
      "{'loss': 0.9462, 'learning_rate': 2.2411968459550903e-06, 'epoch': 13.04}\n",
      "{'loss': 0.8921, 'learning_rate': 2.1689001735049263e-06, 'epoch': 13.1}\n",
      "{'loss': 0.9043, 'learning_rate': 2.096603501054762e-06, 'epoch': 13.16}\n",
      "{'loss': 0.892, 'learning_rate': 2.0243068286045978e-06, 'epoch': 13.23}\n",
      "{'loss': 0.9197, 'learning_rate': 1.9520101561544337e-06, 'epoch': 13.29}\n",
      "{'loss': 0.875, 'learning_rate': 1.8797134837042694e-06, 'epoch': 13.35}\n",
      "{'loss': 0.9395, 'learning_rate': 1.8074168112541052e-06, 'epoch': 13.42}\n",
      "{'loss': 0.9102, 'learning_rate': 1.735120138803941e-06, 'epoch': 13.48}\n",
      "{'loss': 0.9087, 'learning_rate': 1.6628234663537768e-06, 'epoch': 13.54}\n",
      "{'loss': 0.9132, 'learning_rate': 1.5905267939036126e-06, 'epoch': 13.61}\n",
      "{'loss': 0.9139, 'learning_rate': 1.5182301214534483e-06, 'epoch': 13.67}\n",
      "{'loss': 0.9282, 'learning_rate': 1.445933449003284e-06, 'epoch': 13.73}\n",
      "{'loss': 0.9222, 'learning_rate': 1.37363677655312e-06, 'epoch': 13.8}\n",
      "{'loss': 0.9146, 'learning_rate': 1.3013401041029557e-06, 'epoch': 13.86}\n",
      "{'loss': 0.9113, 'learning_rate': 1.2290434316527915e-06, 'epoch': 13.92}\n",
      "{'loss': 0.9153, 'learning_rate': 1.1567467592026272e-06, 'epoch': 13.99}\n",
      "{'eval_loss': 1.0713750123977661, 'eval_runtime': 3.4794, 'eval_samples_per_second': 644.371, 'eval_steps_per_second': 2.587, 'epoch': 14.0}\n",
      "{'loss': 0.9098, 'learning_rate': 1.0844500867524631e-06, 'epoch': 14.05}\n",
      "{'loss': 0.9018, 'learning_rate': 1.0121534143022989e-06, 'epoch': 14.11}\n",
      "{'loss': 0.8814, 'learning_rate': 9.398567418521347e-07, 'epoch': 14.18}\n",
      "{'loss': 0.9085, 'learning_rate': 8.675600694019705e-07, 'epoch': 14.24}\n",
      "{'loss': 0.8733, 'learning_rate': 7.952633969518063e-07, 'epoch': 14.3}\n",
      "{'loss': 0.8883, 'learning_rate': 7.22966724501642e-07, 'epoch': 14.37}\n",
      "{'loss': 0.8892, 'learning_rate': 6.506700520514779e-07, 'epoch': 14.43}\n",
      "{'loss': 0.9126, 'learning_rate': 5.783733796013136e-07, 'epoch': 14.49}\n",
      "{'loss': 0.9192, 'learning_rate': 5.060767071511494e-07, 'epoch': 14.56}\n",
      "{'loss': 0.8967, 'learning_rate': 4.337800347009852e-07, 'epoch': 14.62}\n",
      "{'loss': 0.8792, 'learning_rate': 3.61483362250821e-07, 'epoch': 14.68}\n",
      "{'loss': 0.8723, 'learning_rate': 2.891866898006568e-07, 'epoch': 14.75}\n",
      "{'loss': 0.8833, 'learning_rate': 2.168900173504926e-07, 'epoch': 14.81}\n",
      "{'loss': 0.8565, 'learning_rate': 1.445933449003284e-07, 'epoch': 14.87}\n",
      "{'loss': 0.883, 'learning_rate': 7.22966724501642e-08, 'epoch': 14.94}\n",
      "{'loss': 0.9011, 'learning_rate': 0.0, 'epoch': 15.0}\n",
      "{'eval_loss': 1.0825443267822266, 'eval_runtime': 3.4788, 'eval_samples_per_second': 644.475, 'eval_steps_per_second': 2.587, 'epoch': 15.0}\n",
      "{'train_runtime': 1381.5878, 'train_samples_per_second': 219.031, 'train_steps_per_second': 0.858, 'train_loss': 1.325991511043114, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-06 12:23:04,100]\u001b[0m Trial 2 finished with value: 1.0825443267822266 and parameters: {'learning_rate': 5.176441747431757e-06, 'weight_decay': 1.3491514769839438e-06, 'num_train_epochs': 15, 'eval_steps': 828, 'warmup_steps': 827}. Best is trial 2 with value: 1.0825443267822266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0825443267822266, 'eval_runtime': 3.4681, 'eval_samples_per_second': 646.454, 'eval_steps_per_second': 2.595, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103616/2041105136.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", low=1e-6, high=1e-4)\n",
      "/tmp/ipykernel_103616/2041105136.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", low=1e-6, high=1e-4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/wifo3tp01/miniconda3/envs/authentication/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8235, 'learning_rate': 1.392437064683907e-07, 'epoch': 0.06}\n",
      "{'loss': 1.8077, 'learning_rate': 2.784874129367814e-07, 'epoch': 0.13}\n",
      "{'loss': 1.8114, 'learning_rate': 4.177311194051721e-07, 'epoch': 0.19}\n",
      "{'loss': 1.8093, 'learning_rate': 5.569748258735628e-07, 'epoch': 0.25}\n",
      "{'loss': 1.8073, 'learning_rate': 6.962185323419534e-07, 'epoch': 0.32}\n",
      "{'loss': 1.8179, 'learning_rate': 8.354622388103441e-07, 'epoch': 0.38}\n",
      "{'loss': 1.8069, 'learning_rate': 9.747059452787349e-07, 'epoch': 0.44}\n",
      "{'loss': 1.8051, 'learning_rate': 1.1139496517471257e-06, 'epoch': 0.51}\n",
      "{'loss': 1.8102, 'learning_rate': 1.2531933582155163e-06, 'epoch': 0.57}\n",
      "{'loss': 1.8016, 'learning_rate': 1.3924370646839069e-06, 'epoch': 0.63}\n",
      "{'loss': 1.8073, 'learning_rate': 1.5316807711522975e-06, 'epoch': 0.7}\n",
      "{'loss': 1.7916, 'learning_rate': 1.6709244776206883e-06, 'epoch': 0.76}\n",
      "{'loss': 1.7893, 'learning_rate': 1.8101681840890791e-06, 'epoch': 0.82}\n",
      "{'loss': 1.7921, 'learning_rate': 1.9494118905574697e-06, 'epoch': 0.89}\n",
      "{'loss': 1.7898, 'learning_rate': 2.08865559702586e-06, 'epoch': 0.95}\n",
      "{'eval_loss': 1.7785462141036987, 'eval_runtime': 3.4814, 'eval_samples_per_second': 643.985, 'eval_steps_per_second': 2.585, 'epoch': 1.0}\n",
      "{'loss': 1.7704, 'learning_rate': 2.2278993034942513e-06, 'epoch': 1.01}\n",
      "{'loss': 1.7793, 'learning_rate': 2.3671430099626417e-06, 'epoch': 1.08}\n",
      "{'loss': 1.7769, 'learning_rate': 2.5063867164310326e-06, 'epoch': 1.14}\n",
      "{'loss': 1.7636, 'learning_rate': 2.6456304228994234e-06, 'epoch': 1.2}\n",
      "{'loss': 1.7553, 'learning_rate': 2.7848741293678138e-06, 'epoch': 1.27}\n",
      "{'loss': 1.7548, 'learning_rate': 2.9241178358362046e-06, 'epoch': 1.33}\n",
      "{'loss': 1.7565, 'learning_rate': 3.063361542304595e-06, 'epoch': 1.39}\n",
      "{'loss': 1.7537, 'learning_rate': 3.2026052487729858e-06, 'epoch': 1.46}\n",
      "{'loss': 1.7412, 'learning_rate': 3.3418489552413766e-06, 'epoch': 1.52}\n",
      "{'loss': 1.7408, 'learning_rate': 3.481092661709767e-06, 'epoch': 1.58}\n",
      "{'loss': 1.7393, 'learning_rate': 3.6203363681781582e-06, 'epoch': 1.65}\n",
      "{'loss': 1.7238, 'learning_rate': 3.759580074646549e-06, 'epoch': 1.71}\n",
      "{'loss': 1.7223, 'learning_rate': 3.8988237811149394e-06, 'epoch': 1.77}\n",
      "{'loss': 1.717, 'learning_rate': 4.03806748758333e-06, 'epoch': 1.84}\n",
      "{'loss': 1.702, 'learning_rate': 4.17731119405172e-06, 'epoch': 1.9}\n",
      "{'loss': 1.705, 'learning_rate': 4.316554900520112e-06, 'epoch': 1.96}\n",
      "{'eval_loss': 1.685645580291748, 'eval_runtime': 3.4793, 'eval_samples_per_second': 644.386, 'eval_steps_per_second': 2.587, 'epoch': 2.0}\n",
      "{'loss': 1.6951, 'learning_rate': 4.455798606988503e-06, 'epoch': 2.03}\n",
      "{'loss': 1.6863, 'learning_rate': 4.595042313456893e-06, 'epoch': 2.09}\n",
      "{'loss': 1.6707, 'learning_rate': 4.7342860199252835e-06, 'epoch': 2.15}\n",
      "{'loss': 1.6705, 'learning_rate': 4.873529726393674e-06, 'epoch': 2.22}\n",
      "{'loss': 1.6606, 'learning_rate': 5.012773432862065e-06, 'epoch': 2.28}\n",
      "{'loss': 1.645, 'learning_rate': 5.152017139330456e-06, 'epoch': 2.34}\n",
      "{'loss': 1.6406, 'learning_rate': 5.291260845798847e-06, 'epoch': 2.41}\n",
      "{'loss': 1.6245, 'learning_rate': 5.430504552267237e-06, 'epoch': 2.47}\n",
      "{'loss': 1.6034, 'learning_rate': 5.5697482587356275e-06, 'epoch': 2.53}\n",
      "{'loss': 1.5952, 'learning_rate': 5.708991965204018e-06, 'epoch': 2.59}\n",
      "{'loss': 1.5712, 'learning_rate': 5.848235671672409e-06, 'epoch': 2.66}\n",
      "{'loss': 1.5594, 'learning_rate': 5.9874793781408e-06, 'epoch': 2.72}\n",
      "{'loss': 1.5303, 'learning_rate': 6.12672308460919e-06, 'epoch': 2.78}\n",
      "{'loss': 1.5347, 'learning_rate': 6.265966791077581e-06, 'epoch': 2.85}\n",
      "{'loss': 1.4859, 'learning_rate': 6.4052104975459716e-06, 'epoch': 2.91}\n",
      "{'loss': 1.4907, 'learning_rate': 6.544454204014362e-06, 'epoch': 2.97}\n",
      "{'eval_loss': 1.4472335577011108, 'eval_runtime': 3.4787, 'eval_samples_per_second': 644.493, 'eval_steps_per_second': 2.587, 'epoch': 3.0}\n",
      "{'loss': 1.4589, 'learning_rate': 6.683697910482753e-06, 'epoch': 3.04}\n",
      "{'loss': 1.4183, 'learning_rate': 6.822941616951145e-06, 'epoch': 3.1}\n",
      "{'loss': 1.4052, 'learning_rate': 6.962185323419534e-06, 'epoch': 3.16}\n",
      "{'loss': 1.3769, 'learning_rate': 7.101429029887926e-06, 'epoch': 3.23}\n",
      "{'loss': 1.3554, 'learning_rate': 7.2406727363563164e-06, 'epoch': 3.29}\n",
      "{'loss': 1.3476, 'learning_rate': 7.379916442824707e-06, 'epoch': 3.35}\n",
      "{'loss': 1.3272, 'learning_rate': 7.519160149293098e-06, 'epoch': 3.42}\n",
      "{'loss': 1.2979, 'learning_rate': 7.658403855761487e-06, 'epoch': 3.48}\n",
      "{'loss': 1.299, 'learning_rate': 7.797647562229879e-06, 'epoch': 3.54}\n",
      "{'loss': 1.2678, 'learning_rate': 7.936891268698269e-06, 'epoch': 3.61}\n",
      "{'loss': 1.2445, 'learning_rate': 8.07613497516666e-06, 'epoch': 3.67}\n",
      "{'loss': 1.2623, 'learning_rate': 8.215378681635052e-06, 'epoch': 3.73}\n",
      "{'loss': 1.2597, 'learning_rate': 8.35462238810344e-06, 'epoch': 3.8}\n",
      "{'loss': 1.2252, 'learning_rate': 8.493866094571832e-06, 'epoch': 3.86}\n",
      "{'loss': 1.1867, 'learning_rate': 8.633109801040224e-06, 'epoch': 3.92}\n",
      "{'loss': 1.2077, 'learning_rate': 8.772353507508614e-06, 'epoch': 3.99}\n",
      "{'eval_loss': 1.2288901805877686, 'eval_runtime': 3.4788, 'eval_samples_per_second': 644.479, 'eval_steps_per_second': 2.587, 'epoch': 4.0}\n",
      "{'loss': 1.2231, 'learning_rate': 8.911597213977005e-06, 'epoch': 4.05}\n",
      "{'loss': 1.1487, 'learning_rate': 9.050840920445395e-06, 'epoch': 4.11}\n",
      "{'loss': 1.1498, 'learning_rate': 9.190084626913785e-06, 'epoch': 4.18}\n",
      "{'loss': 1.1816, 'learning_rate': 9.329328333382177e-06, 'epoch': 4.24}\n",
      "{'loss': 1.1435, 'learning_rate': 9.468572039850567e-06, 'epoch': 4.3}\n",
      "{'loss': 1.1425, 'learning_rate': 9.607815746318959e-06, 'epoch': 4.37}\n",
      "{'loss': 1.1382, 'learning_rate': 9.747059452787349e-06, 'epoch': 4.43}\n",
      "{'loss': 1.1114, 'learning_rate': 9.886303159255739e-06, 'epoch': 4.49}\n",
      "{'loss': 1.1005, 'learning_rate': 1.002554686572413e-05, 'epoch': 4.56}\n",
      "{'loss': 1.0798, 'learning_rate': 1.016479057219252e-05, 'epoch': 4.62}\n",
      "{'loss': 1.069, 'learning_rate': 1.0304034278660912e-05, 'epoch': 4.68}\n",
      "{'loss': 1.0911, 'learning_rate': 1.0443277985129302e-05, 'epoch': 4.75}\n",
      "{'loss': 1.0791, 'learning_rate': 1.0582521691597693e-05, 'epoch': 4.81}\n",
      "{'loss': 1.106, 'learning_rate': 1.0721765398066083e-05, 'epoch': 4.87}\n",
      "{'loss': 1.0707, 'learning_rate': 1.0861009104534473e-05, 'epoch': 4.94}\n",
      "{'loss': 1.0652, 'learning_rate': 1.1000252811002865e-05, 'epoch': 5.0}\n",
      "{'eval_loss': 1.1432878971099854, 'eval_runtime': 3.4792, 'eval_samples_per_second': 644.395, 'eval_steps_per_second': 2.587, 'epoch': 5.0}\n",
      "{'loss': 1.0338, 'learning_rate': 1.1139496517471255e-05, 'epoch': 5.06}\n",
      "{'loss': 0.9874, 'learning_rate': 1.1278740223939647e-05, 'epoch': 5.13}\n",
      "{'loss': 1.0374, 'learning_rate': 1.1417983930408037e-05, 'epoch': 5.19}\n",
      "{'loss': 1.031, 'learning_rate': 1.1557227636876427e-05, 'epoch': 5.25}\n",
      "{'loss': 0.9939, 'learning_rate': 1.1696471343344818e-05, 'epoch': 5.32}\n",
      "{'loss': 1.0133, 'learning_rate': 1.1835715049813208e-05, 'epoch': 5.38}\n",
      "{'loss': 1.0034, 'learning_rate': 1.19749587562816e-05, 'epoch': 5.44}\n",
      "{'loss': 1.065, 'learning_rate': 1.211420246274999e-05, 'epoch': 5.51}\n",
      "{'loss': 1.0072, 'learning_rate': 1.225344616921838e-05, 'epoch': 5.57}\n",
      "{'loss': 1.0027, 'learning_rate': 1.2392689875686772e-05, 'epoch': 5.63}\n",
      "{'loss': 1.0039, 'learning_rate': 1.2531933582155161e-05, 'epoch': 5.7}\n",
      "{'loss': 1.0027, 'learning_rate': 1.2671177288623553e-05, 'epoch': 5.76}\n",
      "{'loss': 0.9952, 'learning_rate': 1.2810420995091943e-05, 'epoch': 5.82}\n",
      "{'loss': 1.027, 'learning_rate': 1.2949664701560335e-05, 'epoch': 5.89}\n",
      "{'loss': 0.9958, 'learning_rate': 1.3088908408028725e-05, 'epoch': 5.95}\n",
      "{'eval_loss': 1.1083617210388184, 'eval_runtime': 3.4807, 'eval_samples_per_second': 644.122, 'eval_steps_per_second': 2.586, 'epoch': 6.0}\n",
      "{'loss': 0.9795, 'learning_rate': 1.3228152114497115e-05, 'epoch': 6.01}\n",
      "{'loss': 0.9409, 'learning_rate': 1.3367395820965506e-05, 'epoch': 6.08}\n",
      "{'loss': 0.9504, 'learning_rate': 1.3506639527433896e-05, 'epoch': 6.14}\n",
      "{'loss': 0.9182, 'learning_rate': 1.364588323390229e-05, 'epoch': 6.2}\n",
      "{'loss': 0.9439, 'learning_rate': 1.378512694037068e-05, 'epoch': 6.27}\n",
      "{'loss': 0.9254, 'learning_rate': 1.3924370646839068e-05, 'epoch': 6.33}\n",
      "{'loss': 0.9929, 'learning_rate': 1.4063614353307461e-05, 'epoch': 6.39}\n",
      "{'loss': 0.9625, 'learning_rate': 1.4202858059775851e-05, 'epoch': 6.46}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9525, 'learning_rate': 1.4342101766244243e-05, 'epoch': 6.52}\n",
      "{'loss': 0.9157, 'learning_rate': 1.4481345472712633e-05, 'epoch': 6.58}\n",
      "{'loss': 0.9061, 'learning_rate': 1.4620589179181023e-05, 'epoch': 6.65}\n",
      "{'loss': 0.9202, 'learning_rate': 1.4759832885649415e-05, 'epoch': 6.71}\n",
      "{'loss': 0.9202, 'learning_rate': 1.4899076592117804e-05, 'epoch': 6.77}\n",
      "{'loss': 0.9045, 'learning_rate': 1.5038320298586196e-05, 'epoch': 6.84}\n",
      "{'loss': 0.9655, 'learning_rate': 1.5177564005054586e-05, 'epoch': 6.9}\n",
      "{'loss': 0.9061, 'learning_rate': 1.5316807711522974e-05, 'epoch': 6.96}\n",
      "{'eval_loss': 1.0931090116500854, 'eval_runtime': 3.4716, 'eval_samples_per_second': 645.806, 'eval_steps_per_second': 2.592, 'epoch': 7.0}\n",
      "{'loss': 0.9237, 'learning_rate': 1.5456051417991368e-05, 'epoch': 7.03}\n",
      "{'loss': 0.8866, 'learning_rate': 1.5595295124459758e-05, 'epoch': 7.09}\n",
      "{'loss': 0.876, 'learning_rate': 1.5734538830928148e-05, 'epoch': 7.15}\n",
      "{'loss': 0.8695, 'learning_rate': 1.5873782537396538e-05, 'epoch': 7.22}\n",
      "{'loss': 0.8785, 'learning_rate': 1.6013026243864928e-05, 'epoch': 7.28}\n",
      "{'loss': 0.8895, 'learning_rate': 1.615226995033332e-05, 'epoch': 7.34}\n",
      "{'loss': 0.8353, 'learning_rate': 1.629151365680171e-05, 'epoch': 7.41}\n",
      "{'loss': 0.856, 'learning_rate': 1.6430757363270104e-05, 'epoch': 7.47}\n",
      "{'loss': 0.8515, 'learning_rate': 1.657000106973849e-05, 'epoch': 7.53}\n",
      "{'loss': 0.8413, 'learning_rate': 1.670924477620688e-05, 'epoch': 7.59}\n",
      "{'loss': 0.8243, 'learning_rate': 1.6848488482675274e-05, 'epoch': 7.66}\n",
      "{'loss': 0.8684, 'learning_rate': 1.6987732189143664e-05, 'epoch': 7.72}\n",
      "{'loss': 0.9062, 'learning_rate': 1.7126975895612058e-05, 'epoch': 7.78}\n",
      "{'loss': 0.907, 'learning_rate': 1.7266219602080448e-05, 'epoch': 7.85}\n",
      "{'loss': 0.8748, 'learning_rate': 1.7405463308548834e-05, 'epoch': 7.91}\n",
      "{'loss': 0.8334, 'learning_rate': 1.7544707015017227e-05, 'epoch': 7.97}\n",
      "{'eval_loss': 1.147639513015747, 'eval_runtime': 3.477, 'eval_samples_per_second': 644.81, 'eval_steps_per_second': 2.588, 'epoch': 8.0}\n",
      "{'loss': 0.8281, 'learning_rate': 1.7683950721485617e-05, 'epoch': 8.04}\n",
      "{'loss': 0.8472, 'learning_rate': 1.782319442795401e-05, 'epoch': 8.1}\n",
      "{'loss': 0.8111, 'learning_rate': 1.79624381344224e-05, 'epoch': 8.16}\n",
      "{'loss': 0.7946, 'learning_rate': 1.810168184089079e-05, 'epoch': 8.23}\n",
      "{'loss': 0.8032, 'learning_rate': 1.824092554735918e-05, 'epoch': 8.29}\n",
      "{'loss': 0.8158, 'learning_rate': 1.838016925382757e-05, 'epoch': 8.35}\n",
      "{'loss': 0.814, 'learning_rate': 1.8519412960295964e-05, 'epoch': 8.42}\n",
      "{'loss': 0.8047, 'learning_rate': 1.8658656666764354e-05, 'epoch': 8.48}\n",
      "{'loss': 0.8255, 'learning_rate': 1.8797900373232744e-05, 'epoch': 8.54}\n",
      "{'loss': 0.7902, 'learning_rate': 1.8937144079701134e-05, 'epoch': 8.61}\n",
      "{'loss': 0.8052, 'learning_rate': 1.9076387786169524e-05, 'epoch': 8.67}\n",
      "{'loss': 0.8225, 'learning_rate': 1.9215631492637917e-05, 'epoch': 8.73}\n",
      "{'loss': 0.855, 'learning_rate': 1.9354875199106307e-05, 'epoch': 8.8}\n",
      "{'loss': 0.7766, 'learning_rate': 1.9494118905574697e-05, 'epoch': 8.86}\n",
      "{'loss': 0.8011, 'learning_rate': 1.9633362612043087e-05, 'epoch': 8.92}\n",
      "{'loss': 0.7977, 'learning_rate': 1.9772606318511477e-05, 'epoch': 8.99}\n",
      "{'eval_loss': 1.0009702444076538, 'eval_runtime': 3.48, 'eval_samples_per_second': 644.259, 'eval_steps_per_second': 2.586, 'epoch': 9.0}\n",
      "{'loss': 0.7745, 'learning_rate': 1.991185002497987e-05, 'epoch': 9.05}\n",
      "{'loss': 0.7498, 'learning_rate': 1.999998918877229e-05, 'epoch': 9.11}\n",
      "{'loss': 0.7066, 'learning_rate': 1.988371018186082e-05, 'epoch': 9.18}\n",
      "{'loss': 0.76, 'learning_rate': 1.9767431174949354e-05, 'epoch': 9.24}\n",
      "{'loss': 0.7247, 'learning_rate': 1.965115216803789e-05, 'epoch': 9.3}\n",
      "{'loss': 0.7529, 'learning_rate': 1.953487316112642e-05, 'epoch': 9.37}\n",
      "{'loss': 0.7337, 'learning_rate': 1.9418594154214956e-05, 'epoch': 9.43}\n",
      "{'loss': 0.7375, 'learning_rate': 1.9302315147303486e-05, 'epoch': 9.49}\n",
      "{'loss': 0.725, 'learning_rate': 1.9186036140392022e-05, 'epoch': 9.56}\n",
      "{'loss': 0.714, 'learning_rate': 1.906975713348055e-05, 'epoch': 9.62}\n",
      "{'loss': 0.7231, 'learning_rate': 1.8953478126569088e-05, 'epoch': 9.68}\n",
      "{'loss': 0.7005, 'learning_rate': 1.883719911965762e-05, 'epoch': 9.75}\n",
      "{'loss': 0.804, 'learning_rate': 1.8720920112746154e-05, 'epoch': 9.81}\n",
      "{'loss': 0.7644, 'learning_rate': 1.8604641105834687e-05, 'epoch': 9.87}\n",
      "{'loss': 0.7252, 'learning_rate': 1.848836209892322e-05, 'epoch': 9.94}\n",
      "{'loss': 0.7502, 'learning_rate': 1.8372083092011752e-05, 'epoch': 10.0}\n",
      "{'eval_loss': 1.1644577980041504, 'eval_runtime': 3.4826, 'eval_samples_per_second': 643.773, 'eval_steps_per_second': 2.584, 'epoch': 10.0}\n",
      "{'loss': 0.6712, 'learning_rate': 1.8255804085100285e-05, 'epoch': 10.06}\n",
      "{'loss': 0.6406, 'learning_rate': 1.813952507818882e-05, 'epoch': 10.13}\n",
      "{'loss': 0.6626, 'learning_rate': 1.8023246071277355e-05, 'epoch': 10.19}\n",
      "{'loss': 0.625, 'learning_rate': 1.7906967064365884e-05, 'epoch': 10.25}\n",
      "{'loss': 0.6802, 'learning_rate': 1.779068805745442e-05, 'epoch': 10.32}\n",
      "{'loss': 0.6839, 'learning_rate': 1.7674409050542953e-05, 'epoch': 10.38}\n",
      "{'loss': 0.6905, 'learning_rate': 1.7558130043631486e-05, 'epoch': 10.44}\n",
      "{'loss': 0.6626, 'learning_rate': 1.744185103672002e-05, 'epoch': 10.51}\n",
      "{'loss': 0.6795, 'learning_rate': 1.7325572029808552e-05, 'epoch': 10.57}\n",
      "{'loss': 0.6631, 'learning_rate': 1.7209293022897085e-05, 'epoch': 10.63}\n",
      "{'loss': 0.6567, 'learning_rate': 1.7093014015985618e-05, 'epoch': 10.7}\n",
      "{'loss': 0.6492, 'learning_rate': 1.697673500907415e-05, 'epoch': 10.76}\n",
      "{'loss': 0.6732, 'learning_rate': 1.6860456002162684e-05, 'epoch': 10.82}\n",
      "{'loss': 0.6428, 'learning_rate': 1.674417699525122e-05, 'epoch': 10.89}\n",
      "{'loss': 0.6589, 'learning_rate': 1.662789798833975e-05, 'epoch': 10.95}\n",
      "{'eval_loss': 1.1356523036956787, 'eval_runtime': 3.4776, 'eval_samples_per_second': 644.691, 'eval_steps_per_second': 2.588, 'epoch': 11.0}\n",
      "{'loss': 0.7001, 'learning_rate': 1.6511618981428286e-05, 'epoch': 11.01}\n",
      "{'loss': 0.6325, 'learning_rate': 1.639533997451682e-05, 'epoch': 11.08}\n",
      "{'loss': 0.5987, 'learning_rate': 1.627906096760535e-05, 'epoch': 11.14}\n",
      "{'loss': 0.6033, 'learning_rate': 1.6162781960693885e-05, 'epoch': 11.2}\n",
      "{'loss': 0.5905, 'learning_rate': 1.6046502953782417e-05, 'epoch': 11.27}\n",
      "{'loss': 0.5687, 'learning_rate': 1.593022394687095e-05, 'epoch': 11.33}\n",
      "{'loss': 0.5506, 'learning_rate': 1.5813944939959483e-05, 'epoch': 11.39}\n",
      "{'loss': 0.6077, 'learning_rate': 1.5697665933048016e-05, 'epoch': 11.46}\n",
      "{'loss': 0.6106, 'learning_rate': 1.5581386926136553e-05, 'epoch': 11.52}\n",
      "{'loss': 0.6073, 'learning_rate': 1.5465107919225082e-05, 'epoch': 11.58}\n",
      "{'loss': 0.6114, 'learning_rate': 1.534882891231362e-05, 'epoch': 11.65}\n",
      "{'loss': 0.6099, 'learning_rate': 1.523254990540215e-05, 'epoch': 11.71}\n",
      "{'loss': 0.6432, 'learning_rate': 1.5116270898490684e-05, 'epoch': 11.77}\n",
      "{'loss': 0.5818, 'learning_rate': 1.4999991891579215e-05, 'epoch': 11.84}\n",
      "{'loss': 0.6022, 'learning_rate': 1.488371288466775e-05, 'epoch': 11.9}\n",
      "{'loss': 0.5865, 'learning_rate': 1.4767433877756283e-05, 'epoch': 11.96}\n",
      "{'eval_loss': 1.0572065114974976, 'eval_runtime': 3.4802, 'eval_samples_per_second': 644.22, 'eval_steps_per_second': 2.586, 'epoch': 12.0}\n",
      "{'loss': 0.6336, 'learning_rate': 1.4651154870844816e-05, 'epoch': 12.03}\n",
      "{'loss': 0.5762, 'learning_rate': 1.453487586393335e-05, 'epoch': 12.09}\n",
      "{'loss': 0.5517, 'learning_rate': 1.4418596857021882e-05, 'epoch': 12.15}\n",
      "{'loss': 0.5269, 'learning_rate': 1.4302317850110416e-05, 'epoch': 12.22}\n",
      "{'loss': 0.5419, 'learning_rate': 1.4186038843198947e-05, 'epoch': 12.28}\n",
      "{'loss': 0.5414, 'learning_rate': 1.4069759836287482e-05, 'epoch': 12.34}\n",
      "{'loss': 0.5523, 'learning_rate': 1.3953480829376017e-05, 'epoch': 12.41}\n",
      "{'loss': 0.563, 'learning_rate': 1.3837201822464548e-05, 'epoch': 12.47}\n",
      "{'loss': 0.5194, 'learning_rate': 1.3720922815553083e-05, 'epoch': 12.53}\n",
      "{'loss': 0.5504, 'learning_rate': 1.3604643808641614e-05, 'epoch': 12.59}\n",
      "{'loss': 0.5816, 'learning_rate': 1.3488364801730148e-05, 'epoch': 12.66}\n",
      "{'loss': 0.5358, 'learning_rate': 1.337208579481868e-05, 'epoch': 12.72}\n",
      "{'loss': 0.5809, 'learning_rate': 1.3255806787907214e-05, 'epoch': 12.78}\n",
      "{'loss': 0.5688, 'learning_rate': 1.3139527780995749e-05, 'epoch': 12.85}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5463, 'learning_rate': 1.302324877408428e-05, 'epoch': 12.91}\n",
      "{'loss': 0.5297, 'learning_rate': 1.2906969767172815e-05, 'epoch': 12.97}\n",
      "{'eval_loss': 1.1631795167922974, 'eval_runtime': 3.4735, 'eval_samples_per_second': 645.457, 'eval_steps_per_second': 2.591, 'epoch': 13.0}\n",
      "{'loss': 0.5349, 'learning_rate': 1.2790690760261346e-05, 'epoch': 13.04}\n",
      "{'loss': 0.5112, 'learning_rate': 1.267441175334988e-05, 'epoch': 13.1}\n",
      "{'loss': 0.5211, 'learning_rate': 1.2558132746438413e-05, 'epoch': 13.16}\n",
      "{'loss': 0.4813, 'learning_rate': 1.2441853739526946e-05, 'epoch': 13.23}\n",
      "{'loss': 0.5165, 'learning_rate': 1.232557473261548e-05, 'epoch': 13.29}\n",
      "{'loss': 0.4921, 'learning_rate': 1.2209295725704014e-05, 'epoch': 13.35}\n",
      "{'loss': 0.5101, 'learning_rate': 1.2093016718792547e-05, 'epoch': 13.42}\n",
      "{'loss': 0.4926, 'learning_rate': 1.197673771188108e-05, 'epoch': 13.48}\n",
      "{'loss': 0.5218, 'learning_rate': 1.1860458704969612e-05, 'epoch': 13.54}\n",
      "{'loss': 0.4868, 'learning_rate': 1.1744179698058145e-05, 'epoch': 13.61}\n",
      "{'loss': 0.4898, 'learning_rate': 1.162790069114668e-05, 'epoch': 13.67}\n",
      "{'loss': 0.4995, 'learning_rate': 1.1511621684235213e-05, 'epoch': 13.73}\n",
      "{'loss': 0.5215, 'learning_rate': 1.1395342677323746e-05, 'epoch': 13.8}\n",
      "{'loss': 0.5059, 'learning_rate': 1.127906367041228e-05, 'epoch': 13.86}\n",
      "{'loss': 0.5238, 'learning_rate': 1.1162784663500812e-05, 'epoch': 13.92}\n",
      "{'loss': 0.5228, 'learning_rate': 1.1046505656589346e-05, 'epoch': 13.99}\n",
      "{'eval_loss': 1.188353419303894, 'eval_runtime': 3.4798, 'eval_samples_per_second': 644.295, 'eval_steps_per_second': 2.586, 'epoch': 14.0}\n",
      "{'loss': 0.4697, 'learning_rate': 1.0930226649677877e-05, 'epoch': 14.05}\n",
      "{'loss': 0.4825, 'learning_rate': 1.0813947642766412e-05, 'epoch': 14.11}\n",
      "{'loss': 0.4446, 'learning_rate': 1.0697668635854947e-05, 'epoch': 14.18}\n",
      "{'loss': 0.4717, 'learning_rate': 1.0581389628943478e-05, 'epoch': 14.24}\n",
      "{'loss': 0.425, 'learning_rate': 1.0465110622032013e-05, 'epoch': 14.3}\n",
      "{'loss': 0.4506, 'learning_rate': 1.0348831615120544e-05, 'epoch': 14.37}\n",
      "{'loss': 0.4671, 'learning_rate': 1.0232552608209078e-05, 'epoch': 14.43}\n",
      "{'loss': 0.4866, 'learning_rate': 1.011627360129761e-05, 'epoch': 14.49}\n",
      "{'loss': 0.456, 'learning_rate': 9.999994594386144e-06, 'epoch': 14.56}\n",
      "{'loss': 0.4453, 'learning_rate': 9.883715587474677e-06, 'epoch': 14.62}\n",
      "{'loss': 0.4681, 'learning_rate': 9.76743658056321e-06, 'epoch': 14.68}\n",
      "{'loss': 0.4605, 'learning_rate': 9.651157573651743e-06, 'epoch': 14.75}\n",
      "{'loss': 0.4492, 'learning_rate': 9.534878566740276e-06, 'epoch': 14.81}\n",
      "{'loss': 0.4523, 'learning_rate': 9.41859955982881e-06, 'epoch': 14.87}\n",
      "{'loss': 0.463, 'learning_rate': 9.302320552917343e-06, 'epoch': 14.94}\n",
      "{'loss': 0.4495, 'learning_rate': 9.186041546005876e-06, 'epoch': 15.0}\n",
      "{'eval_loss': 1.3566409349441528, 'eval_runtime': 3.4803, 'eval_samples_per_second': 644.194, 'eval_steps_per_second': 2.586, 'epoch': 15.0}\n",
      "{'loss': 0.416, 'learning_rate': 9.06976253909441e-06, 'epoch': 15.06}\n",
      "{'loss': 0.4264, 'learning_rate': 8.953483532182942e-06, 'epoch': 15.13}\n",
      "{'loss': 0.4378, 'learning_rate': 8.837204525271477e-06, 'epoch': 15.19}\n",
      "{'loss': 0.4345, 'learning_rate': 8.72092551836001e-06, 'epoch': 15.25}\n",
      "{'loss': 0.438, 'learning_rate': 8.604646511448542e-06, 'epoch': 15.32}\n",
      "{'loss': 0.443, 'learning_rate': 8.488367504537075e-06, 'epoch': 15.38}\n",
      "{'loss': 0.4009, 'learning_rate': 8.37208849762561e-06, 'epoch': 15.44}\n",
      "{'loss': 0.4197, 'learning_rate': 8.255809490714143e-06, 'epoch': 15.51}\n",
      "{'loss': 0.4413, 'learning_rate': 8.139530483802676e-06, 'epoch': 15.57}\n",
      "{'loss': 0.4188, 'learning_rate': 8.023251476891209e-06, 'epoch': 15.63}\n",
      "{'loss': 0.4149, 'learning_rate': 7.906972469979742e-06, 'epoch': 15.7}\n",
      "{'loss': 0.4385, 'learning_rate': 7.790693463068276e-06, 'epoch': 15.76}\n",
      "{'loss': 0.4061, 'learning_rate': 7.67441445615681e-06, 'epoch': 15.82}\n",
      "{'loss': 0.4199, 'learning_rate': 7.558135449245342e-06, 'epoch': 15.89}\n",
      "{'loss': 0.388, 'learning_rate': 7.441856442333875e-06, 'epoch': 15.95}\n",
      "{'eval_loss': 1.295198917388916, 'eval_runtime': 3.4808, 'eval_samples_per_second': 644.107, 'eval_steps_per_second': 2.586, 'epoch': 16.0}\n",
      "{'loss': 0.4043, 'learning_rate': 7.325577435422408e-06, 'epoch': 16.01}\n",
      "{'loss': 0.3947, 'learning_rate': 7.209298428510941e-06, 'epoch': 16.08}\n",
      "{'loss': 0.3821, 'learning_rate': 7.093019421599474e-06, 'epoch': 16.14}\n",
      "{'loss': 0.4083, 'learning_rate': 6.976740414688008e-06, 'epoch': 16.2}\n",
      "{'loss': 0.3807, 'learning_rate': 6.860461407776541e-06, 'epoch': 16.27}\n",
      "{'loss': 0.3883, 'learning_rate': 6.744182400865074e-06, 'epoch': 16.33}\n",
      "{'loss': 0.3842, 'learning_rate': 6.627903393953607e-06, 'epoch': 16.39}\n",
      "{'loss': 0.3742, 'learning_rate': 6.51162438704214e-06, 'epoch': 16.46}\n",
      "{'loss': 0.3971, 'learning_rate': 6.395345380130673e-06, 'epoch': 16.52}\n",
      "{'loss': 0.3972, 'learning_rate': 6.279066373219207e-06, 'epoch': 16.58}\n",
      "{'loss': 0.3899, 'learning_rate': 6.16278736630774e-06, 'epoch': 16.65}\n",
      "{'loss': 0.3979, 'learning_rate': 6.046508359396273e-06, 'epoch': 16.71}\n",
      "{'loss': 0.4075, 'learning_rate': 5.930229352484806e-06, 'epoch': 16.77}\n",
      "{'loss': 0.3901, 'learning_rate': 5.81395034557334e-06, 'epoch': 16.84}\n",
      "{'loss': 0.3981, 'learning_rate': 5.697671338661873e-06, 'epoch': 16.9}\n",
      "{'loss': 0.4207, 'learning_rate': 5.581392331750406e-06, 'epoch': 16.96}\n",
      "{'eval_loss': 1.3925620317459106, 'eval_runtime': 3.4798, 'eval_samples_per_second': 644.298, 'eval_steps_per_second': 2.586, 'epoch': 17.0}\n",
      "{'loss': 0.3871, 'learning_rate': 5.465113324838939e-06, 'epoch': 17.03}\n",
      "{'loss': 0.3765, 'learning_rate': 5.348834317927473e-06, 'epoch': 17.09}\n",
      "{'loss': 0.3462, 'learning_rate': 5.232555311016006e-06, 'epoch': 17.15}\n",
      "{'loss': 0.3688, 'learning_rate': 5.116276304104539e-06, 'epoch': 17.22}\n",
      "{'loss': 0.3602, 'learning_rate': 4.999997297193072e-06, 'epoch': 17.28}\n",
      "{'loss': 0.3688, 'learning_rate': 4.883718290281605e-06, 'epoch': 17.34}\n",
      "{'loss': 0.3437, 'learning_rate': 4.767439283370138e-06, 'epoch': 17.41}\n",
      "{'loss': 0.3896, 'learning_rate': 4.651160276458672e-06, 'epoch': 17.47}\n",
      "{'loss': 0.3595, 'learning_rate': 4.534881269547205e-06, 'epoch': 17.53}\n",
      "{'loss': 0.3922, 'learning_rate': 4.418602262635738e-06, 'epoch': 17.59}\n",
      "{'loss': 0.3778, 'learning_rate': 4.302323255724271e-06, 'epoch': 17.66}\n",
      "{'loss': 0.3874, 'learning_rate': 4.186044248812805e-06, 'epoch': 17.72}\n",
      "{'loss': 0.3702, 'learning_rate': 4.069765241901338e-06, 'epoch': 17.78}\n",
      "{'loss': 0.3668, 'learning_rate': 3.953486234989871e-06, 'epoch': 17.85}\n",
      "{'loss': 0.3665, 'learning_rate': 3.837207228078405e-06, 'epoch': 17.91}\n",
      "{'loss': 0.3748, 'learning_rate': 3.7209282211669375e-06, 'epoch': 17.97}\n",
      "{'eval_loss': 1.3959392309188843, 'eval_runtime': 3.4809, 'eval_samples_per_second': 644.088, 'eval_steps_per_second': 2.586, 'epoch': 18.0}\n",
      "{'loss': 0.3468, 'learning_rate': 3.6046492142554704e-06, 'epoch': 18.04}\n",
      "{'loss': 0.3554, 'learning_rate': 3.488370207344004e-06, 'epoch': 18.1}\n",
      "{'loss': 0.3897, 'learning_rate': 3.372091200432537e-06, 'epoch': 18.16}\n",
      "{'loss': 0.3437, 'learning_rate': 3.25581219352107e-06, 'epoch': 18.23}\n",
      "{'loss': 0.3426, 'learning_rate': 3.1395331866096033e-06, 'epoch': 18.29}\n",
      "{'loss': 0.3757, 'learning_rate': 3.0232541796981367e-06, 'epoch': 18.35}\n",
      "{'loss': 0.3408, 'learning_rate': 2.90697517278667e-06, 'epoch': 18.42}\n",
      "{'loss': 0.3399, 'learning_rate': 2.790696165875203e-06, 'epoch': 18.48}\n",
      "{'loss': 0.3624, 'learning_rate': 2.6744171589637367e-06, 'epoch': 18.54}\n",
      "{'loss': 0.34, 'learning_rate': 2.5581381520522696e-06, 'epoch': 18.61}\n",
      "{'loss': 0.3478, 'learning_rate': 2.4418591451408025e-06, 'epoch': 18.67}\n",
      "{'loss': 0.346, 'learning_rate': 2.325580138229336e-06, 'epoch': 18.73}\n",
      "{'loss': 0.3529, 'learning_rate': 2.209301131317869e-06, 'epoch': 18.8}\n",
      "{'loss': 0.3667, 'learning_rate': 2.0930221244064025e-06, 'epoch': 18.86}\n",
      "{'loss': 0.3261, 'learning_rate': 1.9767431174949354e-06, 'epoch': 18.92}\n",
      "{'loss': 0.3573, 'learning_rate': 1.8604641105834688e-06, 'epoch': 18.99}\n",
      "{'eval_loss': 1.4451243877410889, 'eval_runtime': 3.4642, 'eval_samples_per_second': 647.2, 'eval_steps_per_second': 2.598, 'epoch': 19.0}\n",
      "{'loss': 0.3426, 'learning_rate': 1.744185103672002e-06, 'epoch': 19.05}\n",
      "{'loss': 0.333, 'learning_rate': 1.627906096760535e-06, 'epoch': 19.11}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3412, 'learning_rate': 1.5116270898490683e-06, 'epoch': 19.18}\n",
      "{'loss': 0.3279, 'learning_rate': 1.3953480829376015e-06, 'epoch': 19.24}\n",
      "{'loss': 0.3463, 'learning_rate': 1.2790690760261348e-06, 'epoch': 19.3}\n",
      "{'loss': 0.3499, 'learning_rate': 1.162790069114668e-06, 'epoch': 19.37}\n",
      "{'loss': 0.3514, 'learning_rate': 1.0465110622032013e-06, 'epoch': 19.43}\n",
      "{'loss': 0.328, 'learning_rate': 9.302320552917344e-07, 'epoch': 19.49}\n",
      "{'loss': 0.3673, 'learning_rate': 8.139530483802675e-07, 'epoch': 19.56}\n",
      "{'loss': 0.3206, 'learning_rate': 6.976740414688007e-07, 'epoch': 19.62}\n",
      "{'loss': 0.3244, 'learning_rate': 5.81395034557334e-07, 'epoch': 19.68}\n",
      "{'loss': 0.3361, 'learning_rate': 4.651160276458672e-07, 'epoch': 19.75}\n",
      "{'loss': 0.3426, 'learning_rate': 3.4883702073440036e-07, 'epoch': 19.81}\n",
      "{'loss': 0.3648, 'learning_rate': 2.325580138229336e-07, 'epoch': 19.87}\n",
      "{'loss': 0.3278, 'learning_rate': 1.162790069114668e-07, 'epoch': 19.94}\n",
      "{'loss': 0.351, 'learning_rate': 0.0, 'epoch': 20.0}\n",
      "{'eval_loss': 1.4439458847045898, 'eval_runtime': 3.4713, 'eval_samples_per_second': 645.859, 'eval_steps_per_second': 2.593, 'epoch': 20.0}\n",
      "{'train_runtime': 1843.5318, 'train_samples_per_second': 218.863, 'train_steps_per_second': 0.857, 'train_loss': 0.8295712381224088, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-06 12:53:52,069]\u001b[0m Trial 3 finished with value: 1.4439458847045898 and parameters: {'learning_rate': 2.0023244990154582e-05, 'weight_decay': 1.1078244049305734e-05, 'num_train_epochs': 20, 'eval_steps': 397, 'warmup_steps': 719}. Best is trial 2 with value: 1.0825443267822266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4439458847045898, 'eval_runtime': 3.4709, 'eval_samples_per_second': 645.937, 'eval_steps_per_second': 2.593, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103616/2041105136.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", low=1e-6, high=1e-4)\n",
      "/tmp/ipykernel_103616/2041105136.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", low=1e-6, high=1e-4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/wifo3tp01/miniconda3/envs/authentication/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8466, 'learning_rate': 9.155602676790721e-08, 'epoch': 0.06}\n",
      "{'loss': 1.8404, 'learning_rate': 1.8311205353581442e-07, 'epoch': 0.13}\n",
      "{'loss': 1.8385, 'learning_rate': 2.7466808030372164e-07, 'epoch': 0.19}\n",
      "{'loss': 1.845, 'learning_rate': 3.6622410707162884e-07, 'epoch': 0.25}\n",
      "{'loss': 1.8392, 'learning_rate': 4.577801338395361e-07, 'epoch': 0.32}\n",
      "{'loss': 1.8532, 'learning_rate': 5.493361606074433e-07, 'epoch': 0.38}\n",
      "{'loss': 1.8231, 'learning_rate': 6.408921873753505e-07, 'epoch': 0.44}\n",
      "{'loss': 1.8403, 'learning_rate': 7.324482141432577e-07, 'epoch': 0.51}\n",
      "{'loss': 1.8291, 'learning_rate': 8.24004240911165e-07, 'epoch': 0.57}\n",
      "{'loss': 1.8401, 'learning_rate': 9.155602676790722e-07, 'epoch': 0.63}\n",
      "{'loss': 1.8305, 'learning_rate': 1.0071162944469794e-06, 'epoch': 0.7}\n",
      "{'loss': 1.8303, 'learning_rate': 1.0986723212148866e-06, 'epoch': 0.76}\n",
      "{'loss': 1.8099, 'learning_rate': 1.1902283479827938e-06, 'epoch': 0.82}\n",
      "{'loss': 1.8193, 'learning_rate': 1.281784374750701e-06, 'epoch': 0.89}\n",
      "{'loss': 1.8104, 'learning_rate': 1.3733404015186082e-06, 'epoch': 0.95}\n",
      "{'eval_loss': 1.7992459535598755, 'eval_runtime': 3.4845, 'eval_samples_per_second': 643.428, 'eval_steps_per_second': 2.583, 'epoch': 1.0}\n",
      "{'loss': 1.8087, 'learning_rate': 1.4648964282865154e-06, 'epoch': 1.01}\n",
      "{'loss': 1.8046, 'learning_rate': 1.5564524550544226e-06, 'epoch': 1.08}\n",
      "{'loss': 1.7926, 'learning_rate': 1.64800848182233e-06, 'epoch': 1.14}\n",
      "{'loss': 1.8054, 'learning_rate': 1.739564508590237e-06, 'epoch': 1.2}\n",
      "{'loss': 1.7924, 'learning_rate': 1.8311205353581444e-06, 'epoch': 1.27}\n",
      "{'loss': 1.782, 'learning_rate': 1.9226765621260513e-06, 'epoch': 1.33}\n",
      "{'loss': 1.7698, 'learning_rate': 2.0142325888939588e-06, 'epoch': 1.39}\n",
      "{'loss': 1.7809, 'learning_rate': 2.105788615661866e-06, 'epoch': 1.46}\n",
      "{'loss': 1.7754, 'learning_rate': 2.197344642429773e-06, 'epoch': 1.52}\n",
      "{'loss': 1.7714, 'learning_rate': 2.28890066919768e-06, 'epoch': 1.58}\n",
      "{'loss': 1.7728, 'learning_rate': 2.3804566959655875e-06, 'epoch': 1.65}\n",
      "{'loss': 1.7651, 'learning_rate': 2.4720127227334945e-06, 'epoch': 1.71}\n",
      "{'loss': 1.7588, 'learning_rate': 2.563568749501402e-06, 'epoch': 1.77}\n",
      "{'loss': 1.7544, 'learning_rate': 2.6551247762693093e-06, 'epoch': 1.84}\n",
      "{'loss': 1.7423, 'learning_rate': 2.7466808030372163e-06, 'epoch': 1.9}\n",
      "{'loss': 1.7433, 'learning_rate': 2.8382368298051233e-06, 'epoch': 1.96}\n",
      "{'eval_loss': 1.7212202548980713, 'eval_runtime': 3.4843, 'eval_samples_per_second': 643.464, 'eval_steps_per_second': 2.583, 'epoch': 2.0}\n",
      "{'loss': 1.74, 'learning_rate': 2.9297928565730307e-06, 'epoch': 2.03}\n",
      "{'loss': 1.7343, 'learning_rate': 3.021348883340938e-06, 'epoch': 2.09}\n",
      "{'loss': 1.7077, 'learning_rate': 3.112904910108845e-06, 'epoch': 2.15}\n",
      "{'loss': 1.7062, 'learning_rate': 3.204460936876752e-06, 'epoch': 2.22}\n",
      "{'loss': 1.7024, 'learning_rate': 3.29601696364466e-06, 'epoch': 2.28}\n",
      "{'loss': 1.7028, 'learning_rate': 3.387572990412567e-06, 'epoch': 2.34}\n",
      "{'loss': 1.6863, 'learning_rate': 3.479129017180474e-06, 'epoch': 2.41}\n",
      "{'loss': 1.6784, 'learning_rate': 3.5706850439483813e-06, 'epoch': 2.47}\n",
      "{'loss': 1.6689, 'learning_rate': 3.6622410707162887e-06, 'epoch': 2.53}\n",
      "{'loss': 1.6598, 'learning_rate': 3.7537970974841957e-06, 'epoch': 2.59}\n",
      "{'loss': 1.6454, 'learning_rate': 3.845353124252103e-06, 'epoch': 2.66}\n",
      "{'loss': 1.6401, 'learning_rate': 3.9369091510200105e-06, 'epoch': 2.72}\n",
      "{'loss': 1.617, 'learning_rate': 4.0284651777879175e-06, 'epoch': 2.78}\n",
      "{'loss': 1.6091, 'learning_rate': 4.1200212045558245e-06, 'epoch': 2.85}\n",
      "{'loss': 1.6018, 'learning_rate': 4.211577231323732e-06, 'epoch': 2.91}\n",
      "{'loss': 1.5944, 'learning_rate': 4.303133258091639e-06, 'epoch': 2.97}\n",
      "{'eval_loss': 1.5742709636688232, 'eval_runtime': 3.4827, 'eval_samples_per_second': 643.75, 'eval_steps_per_second': 2.584, 'epoch': 3.0}\n",
      "{'loss': 1.574, 'learning_rate': 4.394689284859546e-06, 'epoch': 3.04}\n",
      "{'loss': 1.5566, 'learning_rate': 4.486245311627453e-06, 'epoch': 3.1}\n",
      "{'loss': 1.5457, 'learning_rate': 4.57780133839536e-06, 'epoch': 3.16}\n",
      "{'loss': 1.5291, 'learning_rate': 4.669357365163268e-06, 'epoch': 3.23}\n",
      "{'loss': 1.5121, 'learning_rate': 4.760913391931175e-06, 'epoch': 3.29}\n",
      "{'loss': 1.4948, 'learning_rate': 4.852469418699082e-06, 'epoch': 3.35}\n",
      "{'loss': 1.4677, 'learning_rate': 4.944025445466989e-06, 'epoch': 3.42}\n",
      "{'loss': 1.4597, 'learning_rate': 5.035581472234897e-06, 'epoch': 3.48}\n",
      "{'loss': 1.4625, 'learning_rate': 5.127137499002804e-06, 'epoch': 3.54}\n",
      "{'loss': 1.435, 'learning_rate': 5.218693525770711e-06, 'epoch': 3.61}\n",
      "{'loss': 1.4131, 'learning_rate': 5.310249552538619e-06, 'epoch': 3.67}\n",
      "{'loss': 1.4196, 'learning_rate': 5.401805579306526e-06, 'epoch': 3.73}\n",
      "{'loss': 1.4177, 'learning_rate': 5.493361606074433e-06, 'epoch': 3.8}\n",
      "{'loss': 1.4012, 'learning_rate': 5.58491763284234e-06, 'epoch': 3.86}\n",
      "{'loss': 1.3664, 'learning_rate': 5.676473659610247e-06, 'epoch': 3.92}\n",
      "{'loss': 1.3537, 'learning_rate': 5.768029686378154e-06, 'epoch': 3.99}\n",
      "{'eval_loss': 1.3441394567489624, 'eval_runtime': 3.4848, 'eval_samples_per_second': 643.37, 'eval_steps_per_second': 2.583, 'epoch': 4.0}\n",
      "{'loss': 1.3618, 'learning_rate': 5.8595857131460614e-06, 'epoch': 4.05}\n",
      "{'loss': 1.3144, 'learning_rate': 5.951141739913969e-06, 'epoch': 4.11}\n",
      "{'loss': 1.3083, 'learning_rate': 6.042697766681876e-06, 'epoch': 4.18}\n",
      "{'loss': 1.3226, 'learning_rate': 6.134253793449783e-06, 'epoch': 4.24}\n",
      "{'loss': 1.2798, 'learning_rate': 6.22580982021769e-06, 'epoch': 4.3}\n",
      "{'loss': 1.3033, 'learning_rate': 6.317365846985597e-06, 'epoch': 4.37}\n",
      "{'loss': 1.2774, 'learning_rate': 6.408921873753504e-06, 'epoch': 4.43}\n",
      "{'loss': 1.254, 'learning_rate': 6.500477900521411e-06, 'epoch': 4.49}\n",
      "{'loss': 1.2543, 'learning_rate': 6.59203392728932e-06, 'epoch': 4.56}\n",
      "{'loss': 1.2119, 'learning_rate': 6.683589954057227e-06, 'epoch': 4.62}\n",
      "{'loss': 1.2314, 'learning_rate': 6.775145980825134e-06, 'epoch': 4.68}\n",
      "{'loss': 1.2083, 'learning_rate': 6.866702007593041e-06, 'epoch': 4.75}\n",
      "{'loss': 1.2078, 'learning_rate': 6.958258034360948e-06, 'epoch': 4.81}\n",
      "{'loss': 1.2109, 'learning_rate': 7.049814061128855e-06, 'epoch': 4.87}\n",
      "{'loss': 1.1874, 'learning_rate': 7.141370087896763e-06, 'epoch': 4.94}\n",
      "{'loss': 1.1817, 'learning_rate': 7.23292611466467e-06, 'epoch': 5.0}\n",
      "{'eval_loss': 1.2102340459823608, 'eval_runtime': 3.4817, 'eval_samples_per_second': 643.934, 'eval_steps_per_second': 2.585, 'epoch': 5.0}\n",
      "{'loss': 1.1647, 'learning_rate': 7.3244821414325774e-06, 'epoch': 5.06}\n",
      "{'loss': 1.1237, 'learning_rate': 7.4160381682004844e-06, 'epoch': 5.13}\n",
      "{'loss': 1.1412, 'learning_rate': 7.507594194968391e-06, 'epoch': 5.19}\n",
      "{'loss': 1.1576, 'learning_rate': 7.599150221736298e-06, 'epoch': 5.25}\n",
      "{'loss': 1.0882, 'learning_rate': 7.690706248504205e-06, 'epoch': 5.32}\n",
      "{'loss': 1.1116, 'learning_rate': 7.782262275272114e-06, 'epoch': 5.38}\n",
      "{'loss': 1.0944, 'learning_rate': 7.873818302040021e-06, 'epoch': 5.44}\n",
      "{'loss': 1.1455, 'learning_rate': 7.965374328807928e-06, 'epoch': 5.51}\n",
      "{'loss': 1.0823, 'learning_rate': 8.056930355575835e-06, 'epoch': 5.57}\n",
      "{'loss': 1.1068, 'learning_rate': 8.148486382343742e-06, 'epoch': 5.63}\n",
      "{'loss': 1.1085, 'learning_rate': 8.240042409111649e-06, 'epoch': 5.7}\n",
      "{'loss': 1.101, 'learning_rate': 8.331598435879556e-06, 'epoch': 5.76}\n",
      "{'loss': 1.0793, 'learning_rate': 8.423154462647465e-06, 'epoch': 5.82}\n",
      "{'loss': 1.1073, 'learning_rate': 8.514710489415372e-06, 'epoch': 5.89}\n",
      "{'loss': 1.0666, 'learning_rate': 8.606266516183279e-06, 'epoch': 5.95}\n",
      "{'eval_loss': 1.1228041648864746, 'eval_runtime': 3.4809, 'eval_samples_per_second': 644.091, 'eval_steps_per_second': 2.586, 'epoch': 6.0}\n",
      "{'loss': 1.0658, 'learning_rate': 8.697822542951186e-06, 'epoch': 6.01}\n",
      "{'loss': 1.0221, 'learning_rate': 8.789378569719093e-06, 'epoch': 6.08}\n",
      "{'loss': 1.048, 'learning_rate': 8.880934596487e-06, 'epoch': 6.14}\n",
      "{'loss': 1.0059, 'learning_rate': 8.919502153550404e-06, 'epoch': 6.2}\n",
      "{'loss': 1.051, 'learning_rate': 8.878587006057054e-06, 'epoch': 6.27}\n",
      "{'loss': 1.0147, 'learning_rate': 8.837671858563702e-06, 'epoch': 6.33}\n",
      "{'loss': 1.0651, 'learning_rate': 8.796756711070352e-06, 'epoch': 6.39}\n",
      "{'loss': 1.0217, 'learning_rate': 8.755841563577e-06, 'epoch': 6.46}\n",
      "{'loss': 1.0259, 'learning_rate': 8.71492641608365e-06, 'epoch': 6.52}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9938, 'learning_rate': 8.6740112685903e-06, 'epoch': 6.58}\n",
      "{'loss': 1.0202, 'learning_rate': 8.63309612109695e-06, 'epoch': 6.65}\n",
      "{'loss': 0.9922, 'learning_rate': 8.5921809736036e-06, 'epoch': 6.71}\n",
      "{'loss': 1.0043, 'learning_rate': 8.551265826110249e-06, 'epoch': 6.77}\n",
      "{'loss': 0.9846, 'learning_rate': 8.510350678616899e-06, 'epoch': 6.84}\n",
      "{'loss': 1.0083, 'learning_rate': 8.469435531123547e-06, 'epoch': 6.9}\n",
      "{'loss': 0.9704, 'learning_rate': 8.428520383630197e-06, 'epoch': 6.96}\n",
      "{'eval_loss': 1.1382741928100586, 'eval_runtime': 3.4787, 'eval_samples_per_second': 644.5, 'eval_steps_per_second': 2.587, 'epoch': 7.0}\n",
      "{'loss': 1.0097, 'learning_rate': 8.387605236136847e-06, 'epoch': 7.03}\n",
      "{'loss': 0.9845, 'learning_rate': 8.346690088643497e-06, 'epoch': 7.09}\n",
      "{'loss': 0.9542, 'learning_rate': 8.305774941150147e-06, 'epoch': 7.15}\n",
      "{'loss': 0.9334, 'learning_rate': 8.264859793656796e-06, 'epoch': 7.22}\n",
      "{'loss': 0.9569, 'learning_rate': 8.223944646163446e-06, 'epoch': 7.28}\n",
      "{'loss': 0.9551, 'learning_rate': 8.183029498670094e-06, 'epoch': 7.34}\n",
      "{'loss': 0.9148, 'learning_rate': 8.142114351176744e-06, 'epoch': 7.41}\n",
      "{'loss': 0.9546, 'learning_rate': 8.101199203683394e-06, 'epoch': 7.47}\n",
      "{'loss': 0.9252, 'learning_rate': 8.060284056190044e-06, 'epoch': 7.53}\n",
      "{'loss': 0.9209, 'learning_rate': 8.019368908696694e-06, 'epoch': 7.59}\n",
      "{'loss': 0.8971, 'learning_rate': 7.978453761203342e-06, 'epoch': 7.66}\n",
      "{'loss': 0.9275, 'learning_rate': 7.937538613709992e-06, 'epoch': 7.72}\n",
      "{'loss': 0.9319, 'learning_rate': 7.89662346621664e-06, 'epoch': 7.78}\n",
      "{'loss': 0.9538, 'learning_rate': 7.85570831872329e-06, 'epoch': 7.85}\n",
      "{'loss': 0.9312, 'learning_rate': 7.81479317122994e-06, 'epoch': 7.91}\n",
      "{'loss': 0.8951, 'learning_rate': 7.77387802373659e-06, 'epoch': 7.97}\n",
      "{'eval_loss': 1.0797336101531982, 'eval_runtime': 3.4794, 'eval_samples_per_second': 644.365, 'eval_steps_per_second': 2.587, 'epoch': 8.0}\n",
      "{'loss': 0.8893, 'learning_rate': 7.73296287624324e-06, 'epoch': 8.04}\n",
      "{'loss': 0.8741, 'learning_rate': 7.692047728749889e-06, 'epoch': 8.1}\n",
      "{'loss': 0.887, 'learning_rate': 7.651132581256539e-06, 'epoch': 8.16}\n",
      "{'loss': 0.8692, 'learning_rate': 7.610217433763188e-06, 'epoch': 8.23}\n",
      "{'loss': 0.8864, 'learning_rate': 7.569302286269838e-06, 'epoch': 8.29}\n",
      "{'loss': 0.9022, 'learning_rate': 7.528387138776487e-06, 'epoch': 8.35}\n",
      "{'loss': 0.9145, 'learning_rate': 7.487471991283137e-06, 'epoch': 8.42}\n",
      "{'loss': 0.8902, 'learning_rate': 7.4465568437897865e-06, 'epoch': 8.48}\n",
      "{'loss': 0.8885, 'learning_rate': 7.4056416962964365e-06, 'epoch': 8.54}\n",
      "{'loss': 0.8625, 'learning_rate': 7.364726548803085e-06, 'epoch': 8.61}\n",
      "{'loss': 0.871, 'learning_rate': 7.323811401309735e-06, 'epoch': 8.67}\n",
      "{'loss': 0.8925, 'learning_rate': 7.282896253816385e-06, 'epoch': 8.73}\n",
      "{'loss': 0.8612, 'learning_rate': 7.241981106323034e-06, 'epoch': 8.8}\n",
      "{'loss': 0.8529, 'learning_rate': 7.201065958829684e-06, 'epoch': 8.86}\n",
      "{'loss': 0.9059, 'learning_rate': 7.160150811336333e-06, 'epoch': 8.92}\n",
      "{'loss': 0.8673, 'learning_rate': 7.119235663842982e-06, 'epoch': 8.99}\n",
      "{'eval_loss': 1.0614347457885742, 'eval_runtime': 3.4809, 'eval_samples_per_second': 644.084, 'eval_steps_per_second': 2.586, 'epoch': 9.0}\n",
      "{'loss': 0.8505, 'learning_rate': 7.0783205163496314e-06, 'epoch': 9.05}\n",
      "{'loss': 0.8467, 'learning_rate': 7.0374053688562814e-06, 'epoch': 9.11}\n",
      "{'loss': 0.82, 'learning_rate': 6.9964902213629314e-06, 'epoch': 9.18}\n",
      "{'loss': 0.8367, 'learning_rate': 6.955575073869581e-06, 'epoch': 9.24}\n",
      "{'loss': 0.8477, 'learning_rate': 6.914659926376231e-06, 'epoch': 9.3}\n",
      "{'loss': 0.8696, 'learning_rate': 6.873744778882881e-06, 'epoch': 9.37}\n",
      "{'loss': 0.8505, 'learning_rate': 6.832829631389529e-06, 'epoch': 9.43}\n",
      "{'loss': 0.8439, 'learning_rate': 6.791914483896179e-06, 'epoch': 9.49}\n",
      "{'loss': 0.8142, 'learning_rate': 6.750999336402828e-06, 'epoch': 9.56}\n",
      "{'loss': 0.8469, 'learning_rate': 6.710084188909478e-06, 'epoch': 9.62}\n",
      "{'loss': 0.836, 'learning_rate': 6.669169041416127e-06, 'epoch': 9.68}\n",
      "{'loss': 0.7886, 'learning_rate': 6.628253893922777e-06, 'epoch': 9.75}\n",
      "{'loss': 0.8472, 'learning_rate': 6.587338746429427e-06, 'epoch': 9.81}\n",
      "{'loss': 0.814, 'learning_rate': 6.5464235989360756e-06, 'epoch': 9.87}\n",
      "{'loss': 0.8132, 'learning_rate': 6.5055084514427256e-06, 'epoch': 9.94}\n",
      "{'loss': 0.8416, 'learning_rate': 6.464593303949375e-06, 'epoch': 10.0}\n",
      "{'eval_loss': 1.1145915985107422, 'eval_runtime': 3.4805, 'eval_samples_per_second': 644.163, 'eval_steps_per_second': 2.586, 'epoch': 10.0}\n",
      "{'loss': 0.8134, 'learning_rate': 6.423678156456025e-06, 'epoch': 10.06}\n",
      "{'loss': 0.792, 'learning_rate': 6.382763008962674e-06, 'epoch': 10.13}\n",
      "{'loss': 0.7703, 'learning_rate': 6.341847861469324e-06, 'epoch': 10.19}\n",
      "{'loss': 0.7574, 'learning_rate': 6.300932713975974e-06, 'epoch': 10.25}\n",
      "{'loss': 0.7872, 'learning_rate': 6.260017566482622e-06, 'epoch': 10.32}\n",
      "{'loss': 0.8354, 'learning_rate': 6.219102418989272e-06, 'epoch': 10.38}\n",
      "{'loss': 0.8028, 'learning_rate': 6.178187271495921e-06, 'epoch': 10.44}\n",
      "{'loss': 0.8029, 'learning_rate': 6.137272124002571e-06, 'epoch': 10.51}\n",
      "{'loss': 0.8145, 'learning_rate': 6.096356976509221e-06, 'epoch': 10.57}\n",
      "{'loss': 0.8099, 'learning_rate': 6.0554418290158705e-06, 'epoch': 10.63}\n",
      "{'loss': 0.783, 'learning_rate': 6.0145266815225205e-06, 'epoch': 10.7}\n",
      "{'loss': 0.7905, 'learning_rate': 5.973611534029169e-06, 'epoch': 10.76}\n",
      "{'loss': 0.8232, 'learning_rate': 5.932696386535819e-06, 'epoch': 10.82}\n",
      "{'loss': 0.789, 'learning_rate': 5.891781239042468e-06, 'epoch': 10.89}\n",
      "{'loss': 0.7922, 'learning_rate': 5.850866091549118e-06, 'epoch': 10.95}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", low=1e-6, high=1e-4)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", low=1e-6, high=1e-4)\n",
    "    num_train_epochs = trial.suggest_categorical(\"num_train_epochs\", [15, 18, 20])\n",
    "    eval_steps = trial.suggest_int(\"eval_steps\", low=10, high=1000)\n",
    "    warmup_steps = trial.suggest_int(\"warmup_steps\", low=10, high=1000)\n",
    "\n",
    "    # Load BERT model and tokenizer\n",
    "    model = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels = 6)\n",
    "\n",
    "    # Load train and validation datasets\n",
    "    train_dataset = train\n",
    "    val_dataset = val\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=256,\n",
    "        per_device_eval_batch_size=256,\n",
    "        warmup_steps=warmup_steps,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=5,\n",
    "        evaluation_strategy='epoch',\n",
    "        eval_steps=eval_steps,\n",
    "        disable_tqdm=True\n",
    "    )\n",
    "\n",
    "    # Define trainer and train model\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Return validation loss as the objective to minimize\n",
    "    return trainer.evaluate(val_dataset)['eval_loss']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=15)\n",
    "    print(f\"Best trial: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0461087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'learning_rate': 5.743251747122259e-06, 'weight_decay': 5.586384316928891e-06, 'num_train_epochs': 20, 'eval_steps': 985, 'warmup_steps': 779}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best trial: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1CCIUulVnIKn",
   "metadata": {
    "id": "1CCIUulVnIKn"
   },
   "source": [
    "# Fine-Tune Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "zWdgf1QpraV8",
   "metadata": {
    "id": "zWdgf1QpraV8"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "#This class is used to execute the preprocessing purpose\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def convert_emoticons(self, text):\n",
    "      for emot in EMOTICONS_EMO:\n",
    "          text = text.replace(emot, EMOTICONS_EMO[emot].replace(\" \",\"_\"))\n",
    "      return text\n",
    "\n",
    "    #For tokenize the sentence by using encode_plus() function, it could generate the input_ids and attention_mask which are needed to fit into BERT pre-trained model for fine-tuning.\n",
    "    #In addition, encode_plus() is more flexible than encode() as able to setting more parameters\n",
    "    def __getitem__(self, item):\n",
    "      text = str(self.text[item])\n",
    "      label = self.labels[item]\n",
    "      #text = [emoji.demojize(sentences) for sentences in text]\n",
    "      #text = [self.convert_emoticons(sentences) for sentences in text]\n",
    "      encoding = self.tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_len,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=False, #Segmentation embedding\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "      )\n",
    "\n",
    "    #After executing this preprocessing class, it will return the original text, input_ids, attention_mask, and the label of the text\n",
    "      return {\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'labels': torch.tensor(label, dtype=torch.long)\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5deaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario for preprocessing \n",
    "\"\"\"\n",
    "import emoji\n",
    "from nltk import pos_tag\n",
    "from torch import nn, optim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from emot.emo_unicode import EMOTICONS_EMO\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "#This class is used to execute the preprocessing purpose\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    tk = WordPunctTokenizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def convert_emoticons(self, text):\n",
    "      for emot in EMOTICONS_EMO:\n",
    "          text = text.replace(emot, EMOTICONS_EMO[emot].replace(\" \",\"_\"))\n",
    "      return text\n",
    "\n",
    "    def get_wordnet_pos(self, treebank_tag):\n",
    "      if treebank_tag.startswith('J'): # Adjective (JJ)\n",
    "          return wordnet.ADJ\n",
    "      elif treebank_tag.startswith('V'): # Verb (VB)\n",
    "          return wordnet.VERB\n",
    "      elif treebank_tag.startswith('N'): # Noun (NN)\n",
    "          return wordnet.NOUN\n",
    "      elif treebank_tag.startswith('R'): # Adverb (RB) \n",
    "          return wordnet.ADV\n",
    "      elif treebank_tag.startswith('C'): # Conjunction (CC)\n",
    "          return wordnet.NOUN\n",
    "      elif treebank_tag.startswith('M'):\n",
    "          return 'v'\n",
    "      elif treebank_tag.startswith('I'): # Preposition (IN)\n",
    "          return wordnet.ADV\n",
    "      else:\n",
    "          return None\n",
    "\n",
    "    #For tokenize the sentence by using encode_plus() function, it could generate the input_ids and attention_mask which are needed to fit into BERT pre-trained model for fine-tuning.\n",
    "    #In addition, encode_plus() is more flexible than encode() as able to setting more parameters\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.text[item])\n",
    "        label = self.labels[item]\n",
    "        text = [emoji.demojize(sentences) for sentences in text]\n",
    "        text = [self.convert_emoticons(sentences) for sentences in text]\n",
    "        text = [self.tk.tokenize(sentences) for sentences in text]\n",
    "        text = [[token for token in sentence if token not in self.stop_words] for sentence in text]\n",
    "        text = [[token for token in sentence if token.isalnum()] for sentence in text]\n",
    "        text = [[token for token in sentence if not isinstance(token, str) or not token.isnumeric()] for sentence in text]\n",
    "        text = [pos_tag(sentence) for sentence in text]\n",
    "        text = [[self.lemmatizer.lemmatize(token, pos=get_wordnet_pos(tag)) if get_wordnet_pos(tag) is not None else token for token, tag in sentence] for sentence in text]        \n",
    "        text = [' '.join(sentence) for sentence in text]\n",
    "        text = ' '.join(text)\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          truncation=True,\n",
    "          padding='max_length',\n",
    "          return_token_type_ids=False, #Segmentation embedding\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        #After executing this preprocessing class, it will return the input_ids, attention_mask, and the label of the text\n",
    "        return {\n",
    "          #'text': text,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "984R_2F_Q6yR",
   "metadata": {
    "id": "984R_2F_Q6yR"
   },
   "outputs": [],
   "source": [
    "#For executing the Neural Network, the input data should be using the DataLoader() function to split them into multiple batches\n",
    "def create_data_loader(X, Y, tokenizer, max_len, batch_size, num_workers=2, sampler = None):\n",
    "    ds = TextDataset(\n",
    "    text = np.array(X),\n",
    "    labels = np.array(Y),\n",
    "    tokenizer = tokenizer,\n",
    "    max_len = max_len\n",
    "  )\n",
    "    if sampler != None:\n",
    "        sampler = sampler(ds)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        sampler = sampler,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wbzP6-JuRMw9",
   "metadata": {
    "id": "wbzP6-JuRMw9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "#Since the input data is too large that consisted by 33845 rows of sentences then we could set the batch size with small value as 16\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_data_loader = create_data_loader(train_text, train_label, tokenizer=tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE, sampler=RandomSampler)\n",
    "val_data_loader = create_data_loader(val_text, val_label, tokenizer=tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE, sampler=SequentialSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "QnD8S76nBwVw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919,
     "referenced_widgets": [
      "4c688a19101a44f2b4f2dc2ee9a2c9a1",
      "ad20757f226441b7b3c8db7a47838931",
      "6dea9c4e55e544219c1e83a7da4d2acb",
      "991778275ea34e1abcbb9962aba2df7f",
      "ea69e3a8d0d24abda36611e9008aee21",
      "eab450cb369348549f46afd8fb45a7d0",
      "8c8af303b30c44318878473a7eded7e8",
      "3646df9e2faf488b916ea540a09c7e80",
      "85206e70dcf64e66a0a46ac4cb64600e",
      "fc1d2120afa248f5bf8842d834614469",
      "6a56fd2699704c09a9d24951e4903ea9"
     ]
    },
    "executionInfo": {
     "elapsed": 14640,
     "status": "ok",
     "timestamp": 1682455206318,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "06944301600455144405"
     },
     "user_tz": -120
    },
    "id": "QnD8S76nBwVw",
    "outputId": "e34cf362-6b08-407f-f652-de525646c043",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up the BERT model configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    PRE_TRAINED_MODEL_NAME,\n",
    "    num_labels = 6,  \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "Aq8eNfkpIDVK",
   "metadata": {
    "id": "Aq8eNfkpIDVK"
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "#Executing Stochastic Gradient Descent for adjusting the weight based on the error that calculated by using the actual label and predicted label\n",
    "#The learning rate for Stochastic Gradient Descent is 0.000001\n",
    "optimizer = AdamW(model.parameters(), lr = 5.743251747122259e-06, weight_decay = 5.586384316928891e-06,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "t2-MYKmRIDXs",
   "metadata": {
    "id": "t2-MYKmRIDXs"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4 (depend on the usage, you can also set it larger)\n",
    "# We chose to run for 1 epoch first\n",
    "EPOCHS = 20\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler, here we use a linear scheduler with no warmup steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 779,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# Define our loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6mAGeiqxIDZ_",
   "metadata": {
    "id": "6mAGeiqxIDZ_"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model.train()\n",
    "    total_train_accuracy = 0\n",
    "    total_train_loss = 0\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for step, batch in enumerate(data_loader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            print('Batch: {}  of  {}'.format(step, len(data_loader)))\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(\n",
    "          input_ids=input_ids,\n",
    "          token_type_ids=None,\n",
    "          attention_mask=attention_mask,\n",
    "          labels=labels\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
    "  # Calculate the average loss over all of the batches.\n",
    "    avg_train_accuracy = total_train_accuracy / len(data_loader)\n",
    "    avg_train_loss = total_train_loss / len(data_loader) \n",
    "    return avg_train_accuracy, avg_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "If0-dyOiIDcV",
   "metadata": {
    "id": "If0-dyOiIDcV"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cG2nCQR7IDeu",
   "metadata": {
    "id": "cG2nCQR7IDeu"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 985\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "            )\n",
    "            total_eval_loss += outputs[0].item()\n",
    "            logits = outputs[1].detach().cpu().numpy()\n",
    "            label_ids = labels.to('cpu').numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(data_loader)\n",
    "    avg_val_loss = total_eval_loss / len(data_loader)\n",
    "    return avg_val_accuracy, avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7-yGaf8SSRKm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 821491,
     "status": "ok",
     "timestamp": 1682456031983,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "06944301600455144405"
     },
     "user_tz": -120
    },
    "id": "7-yGaf8SSRKm",
    "outputId": "dc117892-40c5-4cd1-8070-2f52e2e485b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.8418347079988937, Accuracy: 0.17490469831702077\n",
      "Validation loss: 1.8218490332365036, Accuracy: 0.17752696349557523\n",
      "\n",
      "Epoch: 2/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.7925179105409434, Accuracy: 0.19856226873955599\n",
      "Validation loss: 1.7626065164804459, Accuracy: 0.2119659153761062\n",
      "\n",
      "Epoch: 3/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.752777010622159, Accuracy: 0.23905149647887325\n",
      "Validation loss: 1.7223335653543472, Accuracy: 0.25063519773230086\n",
      "\n",
      "Epoch: 4/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.7053040215666866, Accuracy: 0.28394772767963716\n",
      "Validation loss: 1.6595298647880554, Accuracy: 0.3374455544800885\n",
      "\n",
      "Epoch: 5/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.6359185769524374, Accuracy: 0.33085443274051085\n",
      "Validation loss: 1.579737901687622, Accuracy: 0.3652775857300885\n",
      "\n",
      "Epoch: 6/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.534264452020887, Accuracy: 0.3693910017307233\n",
      "Validation loss: 1.470609501004219, Accuracy: 0.41293037887168144\n",
      "\n",
      "Epoch: 7/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.4205545875388133, Accuracy: 0.41130509220577705\n",
      "Validation loss: 1.36705282330513, Accuracy: 0.4530299363938053\n",
      "\n",
      "Epoch: 8/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.3158641465952698, Accuracy: 0.43149748597517307\n",
      "Validation loss: 1.273202806711197, Accuracy: 0.47285501935840707\n",
      "\n",
      "Epoch: 9/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.2282437287585837, Accuracy: 0.46952490898782523\n",
      "Validation loss: 1.1946060955524445, Accuracy: 0.5002635854535398\n",
      "\n",
      "Epoch: 10/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.152760107752303, Accuracy: 0.4954615137861064\n",
      "Validation loss: 1.1476635932922363, Accuracy: 0.5115243017146017\n",
      "\n",
      "Epoch: 11/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.0773560371197446, Accuracy: 0.5349510996061112\n",
      "Validation loss: 1.1063658595085144, Accuracy: 0.51953125\n",
      "\n",
      "Epoch: 12/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.0129510600801925, Accuracy: 0.5505667745882072\n",
      "Validation loss: 1.0948243290185928, Accuracy: 0.509506360619469\n",
      "\n",
      "Epoch: 13/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.9569606663475574, Accuracy: 0.5734373134996419\n",
      "Validation loss: 1.0384974107146263, Accuracy: 0.5450817547013275\n",
      "\n",
      "Epoch: 14/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.9163264732965282, Accuracy: 0.5904871762353784\n",
      "Validation loss: 1.0298046916723251, Accuracy: 0.5470348797013275\n",
      "\n",
      "Epoch: 15/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8871268067561405, Accuracy: 0.5985346666865601\n",
      "Validation loss: 1.0188506618142128, Accuracy: 0.5503534637721239\n",
      "\n",
      "Epoch: 16/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8620278062954755, Accuracy: 0.610244091668656\n",
      "Validation loss: 1.028638444840908, Accuracy: 0.5482058904867256\n",
      "\n",
      "Epoch: 17/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8376654075904632, Accuracy: 0.619124306218668\n",
      "Validation loss: 1.0216127708554268, Accuracy: 0.5484997234513275\n",
      "\n",
      "Epoch: 18/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8261024179592938, Accuracy: 0.623328956791597\n",
      "Validation loss: 1.0126998573541641, Accuracy: 0.5528294386061947\n",
      "\n",
      "Epoch: 19/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8154174156591926, Accuracy: 0.6296000313320601\n",
      "Validation loss: 1.0349185392260551, Accuracy: 0.5470996957964602\n",
      "\n",
      "Epoch: 20/20\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8065255242334285, Accuracy: 0.6314715624253999\n",
      "Validation loss: 1.0121782422065735, Accuracy: 0.5542942823561947\n",
      "\n",
      "CPU times: user 26min 48s, sys: 8.51 s, total: 26min 57s\n",
      "Wall time: 27min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch: {}/{}'.format(epoch+1, EPOCHS))\n",
    "    print('-' * 10)\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_text)\n",
    "    )\n",
    "    print('Train loss: {}, Accuracy: {}'.format(train_loss, train_acc))\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_text)\n",
    "    )\n",
    "    print('Validation loss: {}, Accuracy: {}'.format(val_loss, val_acc))\n",
    "    print()\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['validation_acc'].append(val_acc)\n",
    "    history['validation_loss'].append(val_loss)\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f493def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('bert model (subtask 2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a22d155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert model (subtask 2)')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcb69d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_label = test.copy()\n",
    "\n",
    "extract_label.drop(['text'], axis = 1, inplace = True)\n",
    "extract_label.loc[extract_label['label'] == 0, 'label'] = 'A'\n",
    "extract_label.loc[extract_label['label'] == 1, 'label'] = 'B'\n",
    "extract_label.loc[extract_label['label'] == 2, 'label'] = 'C'\n",
    "extract_label.loc[extract_label['label'] == 3, 'label'] = 'D'\n",
    "extract_label.loc[extract_label['label'] == 4, 'label'] = 'E'\n",
    "extract_label.loc[extract_label['label'] == 5, 'label'] = 'F'\n",
    "extract_label.set_index('id', inplace = True)\n",
    "extract_label.to_csv('AuTexTificationEval/task_submissions/ground_truth/subtask_2/en/truth.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72284c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test = test.copy()\n",
    "\n",
    "# Tokenize test data\n",
    "test_inputs = tokenizer(\n",
    "    bert_test[\"text\"].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=128,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "batch_size = 256\n",
    "num_samples = len(test_inputs[\"input_ids\"])\n",
    "test_preds = []\n",
    "\n",
    "# iterate through batches and make predictions\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch_inputs = {\n",
    "        \"input_ids\": test_inputs[\"input_ids\"][i:i+batch_size].to(device),\n",
    "        \"attention_mask\": test_inputs[\"attention_mask\"][i:i+batch_size].to(device)\n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        batch_outputs = model(batch_inputs[\"input_ids\"], batch_inputs[\"attention_mask\"])\n",
    "        batch_preds = torch.argmax(batch_outputs.logits, dim=1)\n",
    "        test_preds.extend(batch_preds.cpu().tolist())\n",
    "\n",
    "# concatenate predictions from all batches\n",
    "bert_test[\"label\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c550fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test.drop(['text'], axis = 1, inplace = True)\n",
    "bert_test.loc[bert_test['label'] == 0, 'label'] = 'A'\n",
    "bert_test.loc[bert_test['label'] == 1, 'label'] = 'B'\n",
    "bert_test.loc[bert_test['label'] == 2, 'label'] = 'C'\n",
    "bert_test.loc[bert_test['label'] == 3, 'label'] = 'D'\n",
    "bert_test.loc[bert_test['label'] == 4, 'label'] = 'E'\n",
    "bert_test.loc[bert_test['label'] == 5, 'label'] = 'F'\n",
    "bert_test.set_index('id', inplace = True)\n",
    "bert_test.to_csv('AuTexTificationEval/task_submissions/submissions/my_team/subtask_2/en/pred (bert subtask 2).tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pE9wNxy_K8cS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1682456033819,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "06944301600455144405"
     },
     "user_tz": -120
    },
    "id": "pE9wNxy_K8cS",
    "outputId": "94389a7b-fe1c-427c-c40c-a0e33017c730"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1099</td>\n",
       "      <td>Love it! It cooks anything from broccoli to me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>I would like to know more about the background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>936</td>\n",
       "      <td>It has a very good texture and looks like it w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6198</td>\n",
       "      <td>We dont know for sure if they will win it all,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14765</td>\n",
       "      <td>This is a decision that your friend will have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text\n",
       "0   1099  Love it! It cooks anything from broccoli to me...\n",
       "1   1950  I would like to know more about the background...\n",
       "2    936  It has a very good texture and looks like it w...\n",
       "3   6198  We dont know for sure if they will win it all,...\n",
       "4  14765  This is a decision that your friend will have ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_2_test = pd.read_csv('test_sub_2.tsv', sep = '\\t')\n",
    "display(sub_2_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "L63zAzmcIYzn",
   "metadata": {
    "id": "L63zAzmcIYzn"
   },
   "outputs": [],
   "source": [
    "# Tokenize test data\n",
    "test_inputs = tokenizer(\n",
    "    sub_2_test[\"text\"].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=128,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "batch_size = 256\n",
    "num_samples = len(test_inputs[\"input_ids\"])\n",
    "test_preds = []\n",
    "\n",
    "# iterate through batches and make predictions\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch_inputs = {\n",
    "        \"input_ids\": test_inputs[\"input_ids\"][i:i+batch_size].to(device),\n",
    "        \"attention_mask\": test_inputs[\"attention_mask\"][i:i+batch_size].to(device)\n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        batch_outputs = model(batch_inputs[\"input_ids\"], batch_inputs[\"attention_mask\"])\n",
    "        batch_preds = torch.argmax(batch_outputs.logits, dim=1)\n",
    "        test_preds.extend(batch_preds.cpu().tolist())\n",
    "\n",
    "# concatenate predictions from all batches\n",
    "sub_2_test[\"label\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76b28586",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_2_test.drop(['text'], axis = 1, inplace = True)\n",
    "sub_2_test.loc[sub_2_test['label'] == 0, 'label'] = 'A'\n",
    "sub_2_test.loc[sub_2_test['label'] == 1, 'label'] = 'B'\n",
    "sub_2_test.loc[sub_2_test['label'] == 2, 'label'] = 'C'\n",
    "sub_2_test.loc[sub_2_test['label'] == 3, 'label'] = 'D'\n",
    "sub_2_test.loc[sub_2_test['label'] == 4, 'label'] = 'E'\n",
    "sub_2_test.loc[sub_2_test['label'] == 5, 'label'] = 'F'\n",
    "sub_2_test.set_index('id', inplace = True)\n",
    "sub_2_test.to_csv('AuTexTificationEval/task_submissions/submissions/my_team/subtask_2/en/run1 (subtask 2).tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DJoTx8GcpWxh",
   "metadata": {
    "id": "DJoTx8GcpWxh"
   },
   "source": [
    "# Searching Hyperparameter for XLM-R Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hFV6FeVHpaFB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "1c6e0f7004d54fe394ca0afb85a35383",
      "263214a51f0e485fa8c8ea593e0ac76a",
      "b473a2b03ecf422881d04ac476e92573",
      "7a75ff77a75f45208674285b0eee9485",
      "89a59a27e4cb4509a086181edfcdbcf1",
      "7a7756b2e8044da7bb4061d0f80eb5ae",
      "6911acceff924d98bb401626acb272e7",
      "49ef9f5a74cd41d09192e5752a4c4f21",
      "1fb417ca34dc45159aa389e439fbf76e",
      "b0547766af2b4bd9b64f358d5039177c",
      "20434d509bd04840bc04fac21a78b7af",
      "775ddbf71fae4ad3b5d1258401ad706e",
      "88b10b31cfc948ce9087841b71066e8e",
      "a9429551fb9c43ff9ab32ba7948e3891",
      "c68286244b354d47b7d673e781ecf420",
      "ae17f8e3c2d546aab05238a6501606ac",
      "7c7deaf37ba34db0993794e9a43b39bb",
      "5db031a1c6c34bbda3e1aa56125a5419",
      "02443501a5934919a8b8b4f73baae800",
      "2585279f2fc74e72ac6b00b89dfa2d85",
      "de670ae3e4794034867dbf3dc50357ce",
      "decda58037af462da53bef20ff395f07"
     ]
    },
    "executionInfo": {
     "elapsed": 44713,
     "status": "ok",
     "timestamp": 1682280015832,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "06944301600455144405"
     },
     "user_tz": -120
    },
    "id": "hFV6FeVHpaFB",
    "outputId": "e1c8c8f9-c135-4be2-ac1e-89314312e83f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2018 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, AdamW\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'xlm-roberta-base'\n",
    "\n",
    "train = pd.DataFrame({'text': train_text, 'label': train_label})\n",
    "val = pd.DataFrame({'text': val_text, 'label': val_label})\n",
    "\n",
    "train = datasets.Dataset.from_pandas(train)\n",
    "val = datasets.Dataset.from_pandas(val)\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME) \n",
    "\n",
    "def preprocess(examples):   \n",
    "# This will tokenize the text, add padding or truncate the text to the max length of 128     \n",
    "    return tokenizer(examples['text'],truncation=True,   padding='max_length',max_length=128)   \n",
    "\n",
    "train = train.map(preprocess, batched=True)\n",
    "val = val.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64368ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", low=1e-6, high=1e-4)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", low=1e-6, high=1e-4)\n",
    "    num_train_epochs = trial.suggest_categorical(\"num_train_epochs\", [15, 18, 21])\n",
    "    eval_steps = trial.suggest_int(\"eval_steps\", low=10, high=1000)\n",
    "    warmup_steps = trial.suggest_int(\"warmup_steps\", low=10, high=1000)\n",
    "    \n",
    "    # Load BERT model and tokenizer\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels = 6)\n",
    "\n",
    "    # Load train and validation datasets\n",
    "    train_dataset = train\n",
    "    val_dataset = val\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=256,\n",
    "        per_device_eval_batch_size=256,\n",
    "        warmup_steps=warmup_steps,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=5,\n",
    "        evaluation_strategy='epoch',\n",
    "        eval_steps=eval_steps,\n",
    "        disable_tqdm=True\n",
    "    )\n",
    "    \n",
    "    # Define trainer and train model\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Return validation loss as the objective to minimize\n",
    "    return trainer.evaluate(val_dataset)['eval_loss']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=15)\n",
    "    print(f\"Best trial: {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69f5d9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'learning_rate': 8.392416726908706e-06, 'weight_decay': 9.254647643242819e-06, 'num_train_epochs': 15, 'eval_steps': 730, 'warmup_steps': 330}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best trial: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W_wS0RMVnou6",
   "metadata": {
    "id": "W_wS0RMVnou6"
   },
   "source": [
    "# XLM-Roberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "FiJJKl7IYLH5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9982,
     "status": "ok",
     "timestamp": 1682280769423,
     "user": {
      "displayName": "NG KOK TENG",
      "userId": "06944301600455144405"
     },
     "user_tz": -120
    },
    "id": "FiJJKl7IYLH5",
    "outputId": "a6f05890-73a1-48e9-961c-a64b222c3e5e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained XLM-RoBERTa model and tokenizer\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8342f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "#Since the input data is too large that consisted by 33845 rows of sentences then we could set the batch size with small value as 16\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_data_loader = create_data_loader(train_text, train_label, tokenizer=tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE, sampler=RandomSampler)\n",
    "val_data_loader = create_data_loader(val_text, val_label, tokenizer=tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE, sampler=SequentialSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2d69dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "#Executing Stochastic Gradient Descent for adjusting the weight based on the error that calculated by using the actual label and predicted label\n",
    "#The learning rate for Stochastic Gradient Descent is 1.5793779201582996e-05\n",
    "optimizer = AdamW(model.parameters(), lr = 8.392416726908706e-06, weight_decay = 9.254647643242819e-06,)\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4 (depend on the usage, you can also set it larger)\n",
    "# We chose to run for 1 epoch first\n",
    "EPOCHS = 15\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler, here we use a linear scheduler with no warmup steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 330,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# Define our loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Evaluation\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 730\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "            )\n",
    "            total_eval_loss += outputs[0].item()\n",
    "            logits = outputs[1].detach().cpu().numpy()\n",
    "            label_ids = labels.to('cpu').numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(data_loader)\n",
    "    avg_val_loss = total_eval_loss / len(data_loader)\n",
    "    #print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    #print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    return avg_val_accuracy, avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acbFk5D7lm34",
   "metadata": {
    "id": "acbFk5D7lm34",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.8102380843229697, Accuracy: 0.16811888278825496\n",
      "Test loss: 1.8012012243270874, Accuracy: 0.1680206028761062\n",
      "\n",
      "Epoch: 2/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.7749992525073843, Accuracy: 0.19403310754356648\n",
      "Test loss: 1.683886557817459, Accuracy: 0.29425210868362833\n",
      "\n",
      "Epoch: 3/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.6565239211203346, Accuracy: 0.26111075883265694\n",
      "Test loss: 1.5396881699562073, Accuracy: 0.3354924294800885\n",
      "\n",
      "Epoch: 4/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.5201821125728983, Accuracy: 0.33781555860587253\n",
      "Test loss: 1.3691502809524536, Accuracy: 0.4159551299778761\n",
      "\n",
      "Epoch: 5/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.2759727961580518, Accuracy: 0.43906380550250657\n",
      "Test loss: 1.1684436202049255, Accuracy: 0.48675159015486724\n",
      "\n",
      "Epoch: 6/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.11255758916828, Accuracy: 0.5055744957030317\n",
      "Test loss: 1.09280164539814, Accuracy: 0.5197256982853983\n",
      "\n",
      "Epoch: 7/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 1.0331922240660225, Accuracy: 0.5425854917641442\n",
      "Test loss: 1.0048532709479332, Accuracy: 0.5536115528207964\n",
      "\n",
      "Epoch: 8/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.9720175971447582, Accuracy: 0.557155832239198\n",
      "Test loss: 1.0284197479486465, Accuracy: 0.5509108821902655\n",
      "\n",
      "Epoch: 9/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.9357837069202477, Accuracy: 0.5738112467175938\n",
      "Test loss: 1.0192878767848015, Accuracy: 0.5570943376659292\n",
      "\n",
      "Epoch: 10/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.9071413228209589, Accuracy: 0.584338259429458\n",
      "Test loss: 0.9720669761300087, Accuracy: 0.574248997511062\n",
      "\n",
      "Epoch: 11/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8806363755548504, Accuracy: 0.5870024170446407\n",
      "Test loss: 0.9940727800130844, Accuracy: 0.5693013689159292\n",
      "\n",
      "Epoch: 12/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8658745649834754, Accuracy: 0.593155996359513\n",
      "Test loss: 1.0028192028403282, Accuracy: 0.5629537126659292\n",
      "\n",
      "Epoch: 13/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8427433892035149, Accuracy: 0.6037464191931248\n",
      "Test loss: 0.9860134795308113, Accuracy: 0.5814738315818584\n",
      "\n",
      "Epoch: 14/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8349646220744495, Accuracy: 0.6033342534017666\n",
      "Test loss: 1.003929615020752, Accuracy: 0.5745730779867256\n",
      "\n",
      "Epoch: 15/15\n",
      "----------\n",
      "Batch: 40  of  71\n",
      "Train loss: 0.8233246643778304, Accuracy: 0.6133614451539746\n",
      "Test loss: 1.0040940642356873, Accuracy: 0.5710254770464602\n",
      "\n",
      "CPU times: user 26min 51s, sys: 10.1 s, total: 27min 2s\n",
      "Wall time: 27min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "loss_fn.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch: {}/{}'.format(epoch+1, EPOCHS))\n",
    "    print('-' * 10)\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_text)\n",
    "    )\n",
    "    print('Train loss: {}, Accuracy: {}'.format(train_loss, train_acc))\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_text)\n",
    "    )\n",
    "    print('Validation loss: {}, Accuracy: {}'.format(val_loss, val_acc))\n",
    "    print()\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f121b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('xlm-r model (subtask 2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65bfbe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-r model (subtask 2)')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9faf3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlm_test = test.copy()\n",
    "\n",
    "# Tokenize test data\n",
    "test_inputs = tokenizer(\n",
    "    xlm_test[\"text\"].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=128,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "batch_size = 256\n",
    "num_samples = len(test_inputs[\"input_ids\"])\n",
    "test_preds = []\n",
    "\n",
    "# iterate through batches and make predictions\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch_inputs = {\n",
    "        \"input_ids\": test_inputs[\"input_ids\"][i:i+batch_size].to(device),\n",
    "        \"attention_mask\": test_inputs[\"attention_mask\"][i:i+batch_size].to(device)\n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        batch_outputs = model(batch_inputs[\"input_ids\"], batch_inputs[\"attention_mask\"])\n",
    "        batch_preds = torch.argmax(batch_outputs.logits, dim=1)\n",
    "        test_preds.extend(batch_preds.cpu().tolist())\n",
    "\n",
    "# concatenate predictions from all batches\n",
    "xlm_test[\"label\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3debcf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlm_test.drop(['text'], axis = 1, inplace = True)\n",
    "xlm_test.loc[xlm_test['label'] == 0, 'label'] = 'A'\n",
    "xlm_test.loc[xlm_test['label'] == 1, 'label'] = 'B'\n",
    "xlm_test.loc[xlm_test['label'] == 2, 'label'] = 'C'\n",
    "xlm_test.loc[xlm_test['label'] == 3, 'label'] = 'D'\n",
    "xlm_test.loc[xlm_test['label'] == 4, 'label'] = 'E'\n",
    "xlm_test.loc[xlm_test['label'] == 5, 'label'] = 'F'\n",
    "xlm_test.set_index('id', inplace = True)\n",
    "xlm_test.to_csv('AuTexTificationEval/task_submissions/submissions/my_team/subtask_2/en/pred (xlm-r subtask 2).tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a93a3d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1099</td>\n",
       "      <td>Love it! It cooks anything from broccoli to me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>I would like to know more about the background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>936</td>\n",
       "      <td>It has a very good texture and looks like it w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6198</td>\n",
       "      <td>We dont know for sure if they will win it all,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14765</td>\n",
       "      <td>This is a decision that your friend will have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text\n",
       "0   1099  Love it! It cooks anything from broccoli to me...\n",
       "1   1950  I would like to know more about the background...\n",
       "2    936  It has a very good texture and looks like it w...\n",
       "3   6198  We dont know for sure if they will win it all,...\n",
       "4  14765  This is a decision that your friend will have ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_2_test = pd.read_csv('test_sub_2.tsv', sep = '\\t')\n",
    "display(sub_2_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "jcUo0a4Mlm6g",
   "metadata": {
    "id": "jcUo0a4Mlm6g"
   },
   "outputs": [],
   "source": [
    "# Tokenize test data\n",
    "test_inputs = tokenizer(\n",
    "    sub_2_test[\"text\"].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=128,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "batch_size = 256\n",
    "num_samples = len(test_inputs[\"input_ids\"])\n",
    "test_preds = []\n",
    "\n",
    "# iterate through batches and make predictions\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch_inputs = {\n",
    "        \"input_ids\": test_inputs[\"input_ids\"][i:i+batch_size].to(device),\n",
    "        \"attention_mask\": test_inputs[\"attention_mask\"][i:i+batch_size].to(device)\n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        batch_outputs = model(batch_inputs[\"input_ids\"], batch_inputs[\"attention_mask\"])\n",
    "        batch_preds = torch.argmax(batch_outputs.logits, dim=1)\n",
    "        test_preds.extend(batch_preds.cpu().tolist())\n",
    "\n",
    "# concatenate predictions from all batches\n",
    "sub_2_test[\"label\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "xc47mkXFlm_k",
   "metadata": {
    "id": "xc47mkXFlm_k"
   },
   "outputs": [],
   "source": [
    "sub_2_test.drop(['text'], axis = 1, inplace = True)\n",
    "sub_2_test.loc[sub_2_test['label'] == 0, 'label'] = 'A'\n",
    "sub_2_test.loc[sub_2_test['label'] == 1, 'label'] = 'B'\n",
    "sub_2_test.loc[sub_2_test['label'] == 2, 'label'] = 'C'\n",
    "sub_2_test.loc[sub_2_test['label'] == 3, 'label'] = 'D'\n",
    "sub_2_test.loc[sub_2_test['label'] == 4, 'label'] = 'E'\n",
    "sub_2_test.loc[sub_2_test['label'] == 5, 'label'] = 'F'\n",
    "sub_2_test.set_index('id', inplace = True)\n",
    "sub_2_test.to_csv('AuTexTificationEval/task_submissions/submissions/my_team/subtask_2/en/run1.tsv', sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02443501a5934919a8b8b4f73baae800": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03275844145244bab9918034dd18eb99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "046aed4bce304c208d5453d85fd490a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "049cf58ced7d4de3b91fb560068484e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3e3af727ce5c4ba9bf6eee2eb15b4554",
       "IPY_MODEL_e515a63d375f43c7bad13cf895c852ea",
       "IPY_MODEL_551145663e114a568b52a6f8f3570f5a"
      ],
      "layout": "IPY_MODEL_c716528474d447f9922325bcff07cd76"
     }
    },
    "06bbb6066cca406093bba34c46ec8579": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4555b7a0be314476820bdf220470aa48",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31b12bc7db8e4ebe8b3648416d4699e6",
      "value": 570
     }
    },
    "0ba831affe7848c790320e49a4dfc62d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53733cb797f3462bac57fae1d04d6d9b",
      "placeholder": "​",
      "style": "IPY_MODEL_8875fba0741f48a5a6b5b10f20db4948",
      "value": "Map: 100%"
     }
    },
    "13d46ce151bf4c3aa8c163e30e7c8e90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1513d7b20d1b422fb12d1b60e6139893": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bf3aecdcdf040af9bc2d018c27afd83",
       "IPY_MODEL_791b73691f4341e3b441f9eab848cbea",
       "IPY_MODEL_3117a1108e114bae83974abaa5a5a4e1"
      ],
      "layout": "IPY_MODEL_a7c12e557b2b462e8ae8dda33286e237"
     }
    },
    "168a127492554c538c728f509377c3b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b5ee47ae268452baa976457bf0f2a10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a1bd77f96e14c33954f5f161d073d2a",
      "max": 3385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db770085c2b84369a8e03b181e1ec8eb",
      "value": 3385
     }
    },
    "1c6e0f7004d54fe394ca0afb85a35383": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_263214a51f0e485fa8c8ea593e0ac76a",
       "IPY_MODEL_b473a2b03ecf422881d04ac476e92573",
       "IPY_MODEL_7a75ff77a75f45208674285b0eee9485"
      ],
      "layout": "IPY_MODEL_89a59a27e4cb4509a086181edfcdbcf1"
     }
    },
    "1fb417ca34dc45159aa389e439fbf76e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "20434d509bd04840bc04fac21a78b7af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24bb0a38d6bb4e83b5efdb48094b3a90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ed6b192b1b24bb99c8639ccfdbc4cbd",
       "IPY_MODEL_06bbb6066cca406093bba34c46ec8579",
       "IPY_MODEL_a2c8e1542a6a4eb09e21b63623acd8ce"
      ],
      "layout": "IPY_MODEL_cf1a476b77bf4bedaa60612863e29fc1"
     }
    },
    "2585279f2fc74e72ac6b00b89dfa2d85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "263214a51f0e485fa8c8ea593e0ac76a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a7756b2e8044da7bb4061d0f80eb5ae",
      "placeholder": "​",
      "style": "IPY_MODEL_6911acceff924d98bb401626acb272e7",
      "value": "Map: 100%"
     }
    },
    "26d2a2a7b0f142bbb26da7d93a229f75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2a4b6f41161e4b0389bba755d378a0ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bf3aecdcdf040af9bc2d018c27afd83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ab2c7d8e77141efb4bc2a7fca25213c",
      "placeholder": "​",
      "style": "IPY_MODEL_68be652c886343a3b687fb46e55f0a91",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "2cb25f576a35480ea6e8bc44b7ddf2a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d034bcd36c94d6494dfa7d2193c1fd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ed6b192b1b24bb99c8639ccfdbc4cbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_510115d67e6d4ea091b22349327d3fcc",
      "placeholder": "​",
      "style": "IPY_MODEL_e6c67861c4d8459387a538684da5349c",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "2f9cda80f9904af1b31a738c68c51b35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "3117a1108e114bae83974abaa5a5a4e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb28334bb7c841c688b7579e197f371b",
      "placeholder": "​",
      "style": "IPY_MODEL_03275844145244bab9918034dd18eb99",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.01kB/s]"
     }
    },
    "31b12bc7db8e4ebe8b3648416d4699e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3646df9e2faf488b916ea540a09c7e80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37010ac369264c569a980d17ee8b3abc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65f72a9418404351a2fc648ac34a1362",
      "max": 30460,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26d2a2a7b0f142bbb26da7d93a229f75",
      "value": 30460
     }
    },
    "39a09b66d84043de9b534a86f384888b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13d46ce151bf4c3aa8c163e30e7c8e90",
      "placeholder": "​",
      "style": "IPY_MODEL_9297a4d93689473bb67fe0aa40a4f9b9",
      "value": "Map: 100%"
     }
    },
    "3b5831c1b5f84831929efe84bc552a1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_39a09b66d84043de9b534a86f384888b",
       "IPY_MODEL_37010ac369264c569a980d17ee8b3abc",
       "IPY_MODEL_5753178222f247adb47282d02036220f"
      ],
      "layout": "IPY_MODEL_046aed4bce304c208d5453d85fd490a1"
     }
    },
    "3b7ef163b0454bec862383beaf5f934b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3db92071880f4138a273f0af3624e96c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_168a127492554c538c728f509377c3b7",
      "placeholder": "​",
      "style": "IPY_MODEL_a91db20dca334177b3757ceb7bdb3ed7",
      "value": " 3385/3385 [00:04&lt;00:00, 785.60 examples/s]"
     }
    },
    "3e3af727ce5c4ba9bf6eee2eb15b4554": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52a5f0a6af714eeb8a03a1660343b4ba",
      "placeholder": "​",
      "style": "IPY_MODEL_f877df11d8cd487c9749bed49d610be6",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "4555b7a0be314476820bdf220470aa48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f8329a1ef947ca83225d51e6be94d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49ef9f5a74cd41d09192e5752a4c4f21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a1bd77f96e14c33954f5f161d073d2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c688a19101a44f2b4f2dc2ee9a2c9a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad20757f226441b7b3c8db7a47838931",
       "IPY_MODEL_6dea9c4e55e544219c1e83a7da4d2acb",
       "IPY_MODEL_991778275ea34e1abcbb9962aba2df7f"
      ],
      "layout": "IPY_MODEL_ea69e3a8d0d24abda36611e9008aee21"
     }
    },
    "510115d67e6d4ea091b22349327d3fcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52a5f0a6af714eeb8a03a1660343b4ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53733cb797f3462bac57fae1d04d6d9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "551145663e114a568b52a6f8f3570f5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a4b6f41161e4b0389bba755d378a0ca",
      "placeholder": "​",
      "style": "IPY_MODEL_e81842ec994747ae94177f7148a40bd3",
      "value": " 232k/232k [00:00&lt;00:00, 3.63MB/s]"
     }
    },
    "5753178222f247adb47282d02036220f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccd4d4a8e9654d35a5a9860fc342b023",
      "placeholder": "​",
      "style": "IPY_MODEL_2cb25f576a35480ea6e8bc44b7ddf2a3",
      "value": " 30460/30460 [01:03&lt;00:00, 567.90 examples/s]"
     }
    },
    "5db031a1c6c34bbda3e1aa56125a5419": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65f72a9418404351a2fc648ac34a1362": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68be652c886343a3b687fb46e55f0a91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6911acceff924d98bb401626acb272e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a56fd2699704c09a9d24951e4903ea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6dea9c4e55e544219c1e83a7da4d2acb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3646df9e2faf488b916ea540a09c7e80",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_85206e70dcf64e66a0a46ac4cb64600e",
      "value": 440473133
     }
    },
    "734924846d6b40b8b908ea4f39bcf6c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "775ddbf71fae4ad3b5d1258401ad706e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88b10b31cfc948ce9087841b71066e8e",
       "IPY_MODEL_a9429551fb9c43ff9ab32ba7948e3891",
       "IPY_MODEL_c68286244b354d47b7d673e781ecf420"
      ],
      "layout": "IPY_MODEL_ae17f8e3c2d546aab05238a6501606ac"
     }
    },
    "791b73691f4341e3b441f9eab848cbea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d034bcd36c94d6494dfa7d2193c1fd2",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_734924846d6b40b8b908ea4f39bcf6c5",
      "value": 28
     }
    },
    "7a75ff77a75f45208674285b0eee9485": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0547766af2b4bd9b64f358d5039177c",
      "placeholder": "​",
      "style": "IPY_MODEL_20434d509bd04840bc04fac21a78b7af",
      "value": " 30460/30460 [00:39&lt;00:00, 1339.22 examples/s]"
     }
    },
    "7a7756b2e8044da7bb4061d0f80eb5ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ab2c7d8e77141efb4bc2a7fca25213c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c7deaf37ba34db0993794e9a43b39bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85206e70dcf64e66a0a46ac4cb64600e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "860e3ee2ce7a46da94cb1309f284c91a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87f0f368fc5847c6b2ef716e95e2c2ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8875fba0741f48a5a6b5b10f20db4948": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88b10b31cfc948ce9087841b71066e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c7deaf37ba34db0993794e9a43b39bb",
      "placeholder": "​",
      "style": "IPY_MODEL_5db031a1c6c34bbda3e1aa56125a5419",
      "value": "Map: 100%"
     }
    },
    "89a59a27e4cb4509a086181edfcdbcf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "8c8af303b30c44318878473a7eded7e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9111adee7545499e86abed22cf5bf2a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ba831affe7848c790320e49a4dfc62d",
       "IPY_MODEL_1b5ee47ae268452baa976457bf0f2a10",
       "IPY_MODEL_3db92071880f4138a273f0af3624e96c"
      ],
      "layout": "IPY_MODEL_2f9cda80f9904af1b31a738c68c51b35"
     }
    },
    "9297a4d93689473bb67fe0aa40a4f9b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "991778275ea34e1abcbb9962aba2df7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc1d2120afa248f5bf8842d834614469",
      "placeholder": "​",
      "style": "IPY_MODEL_6a56fd2699704c09a9d24951e4903ea9",
      "value": " 440M/440M [00:02&lt;00:00, 187MB/s]"
     }
    },
    "a2c8e1542a6a4eb09e21b63623acd8ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_860e3ee2ce7a46da94cb1309f284c91a",
      "placeholder": "​",
      "style": "IPY_MODEL_45f8329a1ef947ca83225d51e6be94d4",
      "value": " 570/570 [00:00&lt;00:00, 18.4kB/s]"
     }
    },
    "a7c12e557b2b462e8ae8dda33286e237": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a91db20dca334177b3757ceb7bdb3ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9429551fb9c43ff9ab32ba7948e3891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02443501a5934919a8b8b4f73baae800",
      "max": 3385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2585279f2fc74e72ac6b00b89dfa2d85",
      "value": 3385
     }
    },
    "ad20757f226441b7b3c8db7a47838931": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eab450cb369348549f46afd8fb45a7d0",
      "placeholder": "​",
      "style": "IPY_MODEL_8c8af303b30c44318878473a7eded7e8",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "ae17f8e3c2d546aab05238a6501606ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "b0547766af2b4bd9b64f358d5039177c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b473a2b03ecf422881d04ac476e92573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49ef9f5a74cd41d09192e5752a4c4f21",
      "max": 30460,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fb417ca34dc45159aa389e439fbf76e",
      "value": 30460
     }
    },
    "c68286244b354d47b7d673e781ecf420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de670ae3e4794034867dbf3dc50357ce",
      "placeholder": "​",
      "style": "IPY_MODEL_decda58037af462da53bef20ff395f07",
      "value": " 3385/3385 [00:02&lt;00:00, 1214.52 examples/s]"
     }
    },
    "c716528474d447f9922325bcff07cd76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb28334bb7c841c688b7579e197f371b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccd4d4a8e9654d35a5a9860fc342b023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf1a476b77bf4bedaa60612863e29fc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db770085c2b84369a8e03b181e1ec8eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de670ae3e4794034867dbf3dc50357ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "decda58037af462da53bef20ff395f07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e515a63d375f43c7bad13cf895c852ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87f0f368fc5847c6b2ef716e95e2c2ec",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b7ef163b0454bec862383beaf5f934b",
      "value": 231508
     }
    },
    "e6c67861c4d8459387a538684da5349c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e81842ec994747ae94177f7148a40bd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea69e3a8d0d24abda36611e9008aee21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eab450cb369348549f46afd8fb45a7d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f877df11d8cd487c9749bed49d610be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc1d2120afa248f5bf8842d834614469": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
